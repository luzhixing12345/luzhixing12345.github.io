{"meta":{"title":"kamilu的博客","subtitle":"个人博客,用于记录和分享计算机知识","description":"个人博客,用于记录和分享计算机知识","author":"luzhixing12345","url":"https://luzhixing12345.github.io","root":"/"},"pages":[{"title":"404","date":"2022-04-23T22:11:34.000Z","updated":"2022-04-23T22:11:45.309Z","comments":false,"path":"/404.html","permalink":"https://luzhixing12345.github.io/404.html","excerpt":"","text":""},{"title":"标签","date":"2022-04-23T22:03:59.000Z","updated":"2022-04-23T22:09:14.525Z","comments":false,"path":"tags/index.html","permalink":"https://luzhixing12345.github.io/tags/index.html","excerpt":"","text":""},{"title":"about","date":"2022-04-27T09:47:29.000Z","updated":"2022-04-27T09:47:45.141Z","comments":false,"path":"about/index.html","permalink":"https://luzhixing12345.github.io/about/index.html","excerpt":"","text":""},{"title":"Slides","date":"2022-04-23T22:11:04.000Z","updated":"2022-04-23T22:11:20.524Z","comments":false,"path":"slides/index.html","permalink":"https://luzhixing12345.github.io/slides/index.html","excerpt":"","text":""}],"posts":[{"title":"generic-sqed-demo","slug":"generic-sqed-demo","date":"2023-07-20T01:10:14.000Z","updated":"2023-07-20T03:33:01.563Z","comments":true,"path":"2023/07/20/generic-sqed-demo/","link":"","permalink":"https://luzhixing12345.github.io/2023/07/20/generic-sqed-demo/","excerpt":"","text":"generic-sqed-demo 复现踩坑 前言 本文是针对 generic-sqed-demo 的复现过程记录, 作者提供了docker快捷部署方式, 这里采用直接复现的方式, 工作环境: WSL2(Ubuntu22.04) 执行过程中存在诸多 git clone, curl 等需要下载外部资源的情况, 请确保网络通畅 Github 仓库地址: generic-sqed-demo git clone git@github.com:upscale-project/generic-sqed-demo.git cd generic-sqed-demo 本项目需要两个依赖, 分别是 yosys 和 pono 直接所在位置为当前根目录下 ├── generic-sqed-demo │ ├── SQED-Generator │ ├── cadical │ ├── docker │ ├── libpoly │ ├── pono # pono │ ├── qed-wireup-patches │ ├── ridecore-bugfix-patch │ ├── ridecore-src-buggy │ ├── sqed-generator │ └── yosys # yosys yosys 作者提供了 ./setup-yosys.sh 用于直接下载安装, 读者可先尝试执行此过程 sudo apt-get install build-essential clang bison flex \\ libreadline-dev gawk tcl-dev libffi-dev git \\ graphviz xdot pkg-config python3 libboost-system-dev \\ libboost-python-dev libboost-filesystem-dev zlib1g-dev 运行 # generic-sqed-demo/$ ./setup-yosys.sh 如果出现问题, 可以克隆 yosys, 安装下面的依赖 选择编译器然后编译安装 make config-gcc make sudo make install 如果仍然存在问题可以选择直接采用包管理工具安装预编译的二进制文件 sudo apt install yosys pono 作者同样提供了 ./setup-pono.sh 笔者没有运行, 采用了直接下载编译 pono 的方式 pono 内部本身又需要了一些依赖, 不过好在作者也提供了一些快捷脚本, 首先安装一下 bison 和 flex # generic-sqed-demo/pono/$ ./contrib/setup-bison.sh ./contrib/setup-flex.sh smt-switch 作者提供了安装脚本 ./contrib/setup-smt-switch.sh 但 smt-switch 本身也需要一些以来, 尤其是其中 cvc5, 再执行之前需要先安装一下必须的依赖 pono/deps/smt-switch/cvc5/CMakeLists.txt 首先需要安装 GMP 参考 Could NOT find GMP (missing: GMP_LIBRARIES GMP_INCLUDE_DIR) sudo apt-get install libmpfr-dev libgmp-dev libboost-all-dev 接着安装 poly 的预编译版本 sudo add-apt-repository ppa:sri-csl/formal-methods sudo apt-get update sudo apt-get install libpoly-dev 或从源码编译 libpoly mkdir build cmake .. -DCMAKE_BUILD_TYPE=Release make sudo make install 接着安装 cadical, 只能从源码编译, 然后将其直接复制到系统路径下 ./configure &amp;&amp; make cp libcadical.a /usr/lib/x86_64-linux-gnu/ 最后检查一下环境中是否有 java javac -version 如果没有安装 JDK JRE sudo apt install default-jre sudo apt install default-jdk 最后可以执行了 # generic-sqed-demo/pono/$ ./contrib/setup-smt-switch.sh ./contrib/setup-btor2tools.sh ./configure.sh &amp;&amp; cd build &amp;&amp; make 结尾 如果至此, 那么恭喜你已经克服种种依赖难关 # generic-sqed-demo/$ ./setup-sqed-generator.sh ./generate-qed-files.sh ./wire-up-qed-module.sh ./run-pono.sh 笔者这里的 yosys 运行会出现奇怪的报错, 问题是关于 qed-generator, 您也可以下载此处 sqed.tar.gz 替换","categories":[],"tags":[{"name":"形式化验证","slug":"形式化验证","permalink":"https://luzhixing12345.github.io/tags/%E5%BD%A2%E5%BC%8F%E5%8C%96%E9%AA%8C%E8%AF%81/"}]},{"title":"","slug":"处理器体系结构","date":"2023-06-06T15:06:04.267Z","updated":"2023-07-05T06:36:28.544Z","comments":true,"path":"2023/06/06/处理器体系结构/","link":"","permalink":"https://luzhixing12345.github.io/2023/06/06/%E5%A4%84%E7%90%86%E5%99%A8%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"关于我的博客","slug":"关于我的博客","date":"2023-06-05T07:47:36.000Z","updated":"2023-06-05T08:14:52.901Z","comments":true,"path":"2023/06/05/关于我的博客/","link":"","permalink":"https://luzhixing12345.github.io/2023/06/05/%E5%85%B3%E4%BA%8E%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"这是一篇置顶的博客, 希望来此博客的朋友可以注意一下 在大三的时候第一次接触到了个人博客这个概念, 那段时间在疯狂吸取一些知识, 为了记录下来所以写了很多博客 到后面发现写博客是需要知识的产出的, 而知识的产出必然伴随着知识的积累, 这需要时间和精力, 因而后面也没更新什么文章 再后来我发现个人博客存在一些弊病, 比如说如果我正在进行一个项目或者完成了一次实验, 单开一个 tag 有点太大了, 因为可能这个 tag 只有一篇文章, 日后也不会再更新, 又不好合并到哪一个大 tag 下. 很多时候文章和代码又是息息相关的, 光看代码看不懂, 光看文章不过瘾. 在看到 github pages 可以做到在一个 github repo 里面支持网页预览之后, 诞生了 zood 这个工具, 我选择同时保存 code 和 note, 而不是分开记录. 所以我把很多技术相关的文章都迁移出去了, 它们会和代码一起保存在一个仓库里, 在这里只会剩下一些环境配置, 纯科普或者阅读笔记之类的文章. 这里现在还会剩下一些文章, 这是因为这些文章里使用到了 Latex 的数学公式, 目前我还没有办法解析它们, 一旦 latex数学公式解析也被解决了他们也就不在了… 当然这种方式有好有坏, 一个 github 仓库从文章解释到代码实现有一个完整的流程, 对于只通过 github repo 找到的人来说也会有更佳的阅读体验, 不然我可能还需要在 blog 里引流 repo, 在 repo 里引流 blog, 有点麻烦… 对于偶然间点进来的朋友来说又会觉得这个 blog 很水也没记录什么, 这是正常的, 因为确实也没写什么, 总而言之这里大概只会剩下一些技术无关经验相关的文章了, 以上","categories":[],"tags":[]},{"title":"测试覆盖率","slug":"python/测试覆盖率","date":"2023-04-27T06:53:46.000Z","updated":"2023-04-27T11:07:25.606Z","comments":true,"path":"2023/04/27/python/测试覆盖率/","link":"","permalink":"https://luzhixing12345.github.io/2023/04/27/python/%E6%B5%8B%E8%AF%95%E8%A6%86%E7%9B%96%E7%8E%87/","excerpt":"","text":"coverage视频介绍 本地先做些测试, 其中 MarkdownParser 是我的python库的名字 创建一个如下的类, 写一些测试程序 import MarkdownParser import unittest class TestMyMdParser(unittest.TestCase): def test_parse_heading(self): MarkdownParser.parse(&quot;&quot;) MarkdownParser.parse(&quot;# Heading&quot;) MarkdownParser.parseFile(&quot;./testfiles/test1.md&quot;) MarkdownParser.parseFile(&quot;./testfiles/test2.md&quot;) MarkdownParser.parseFile(&quot;./testfiles/test3.md&quot;) MarkdownParser.parseFile(&quot;./testfiles/test4.md&quot;) MarkdownParser.parseFile(&quot;./testfiles/test5.md&quot;) MarkdownParser.parseFile(&quot;./testfiles/test6.md&quot;) MarkdownParser.parseFile(&quot;./testfiles/test7.md&quot;) 安装 covergae pip install coverage 运行, 得到 .coverage 这里省略了 ommit source 之类的, 见视频 coverage run -m unittest 查看代码覆盖率 coverage html Codecov 官网: https://about.codecov.io/ 通过 github 登录进去之后点进对应的仓库可以看到如下的 TOKEN 根据它的提示, step1 添加你的密钥 step2 安装 codecov step3, 本地新建一个 .github/workflows/test.yml name: Test with Coverage on: push: branches: [ main ] pull_request: branches: [ main ] jobs: test: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v2 - name: Set up Python uses: actions/setup-python@v2 with: python-version: 3.9 - name: Install dependencies run: | python -m pip install --upgrade pip pip install coverage - name: Run tests with coverage run: | coverage run -m unittest coverage xml -i env: COVERAGE_RUN: True - name: Upload coverage report to Codecov uses: codecov/codecov-action@v3 with: file: ./coverage.xml 其中 pip install coverage 如果你还需要别的库的依赖, 写一个 requirements.txt, 我这个库没有其他依赖. 关键步骤是 coverage run -m unittest 和 coverage xml -i, 最后将 ./coverage.xml 上传到 codecov push 上去就可以了, 然后可以在 README 里面加一个 badge, 名字对着改一下就行了 [![codecov](https://codecov.io/gh/luzhixing12345/MarkdownParser/branch/main/graph/badge.svg?)](https://codecov.io/gh/luzhixing12345/MarkdownParser)","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://luzhixing12345.github.io/tags/python/"}]},{"title":"动态内存分配","slug":"体系结构/动态内存分配","date":"2023-03-30T07:35:21.000Z","updated":"2023-05-21T08:40:28.683Z","comments":true,"path":"2023/03/30/体系结构/动态内存分配/","link":"","permalink":"https://luzhixing12345.github.io/2023/03/30/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/%E5%8A%A8%E6%80%81%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/","excerpt":"","text":"前言 本节继续前文虚拟内存的内容, 深入的讨论一下内存分配的相关技术细节 动态内存分配 我们可以使用较为低级的 mmap 和 munmap 函数来创建和删除虚拟内存区域, 但是 C 程序员还是会觉得当需要额外虚拟内存的时候, 使用动态内存分配器更加方便 动态内存分配器维护着一个进程的虚拟内存区域, 称为堆 (heap). 堆是一个区域, 它紧接着在未初始化的数据区域后开始, 并向高地址处生长. 对于每一个进程, 内核维护着一个变量 brk 指向堆的顶部, 整个虚拟内存的视图如下所示 分配器将堆视为一组不同大小的块, 每个块就是一段连续的虚拟内存片, 要么是已分配的要么是空闲的. 已分配的块显式的为保留为供应用程序使用, 空闲的块可以用来分配. 一个已分配的块保持已分配的状态直到它被释放. 这种释放要么是应用程序显式执行的(free), 要么是内存分配器自身隐式执行的 分配器有两种风格, 这两种风格都要求应用显式的分配块, 但区别在于 显式分配器: 要求应用显式的释放任何已分配的块, 例如 C 程序通过 malloc 分配一个块并通过 free 释放 隐式分配器: 要求分配器检测一个已分配的块何时不再被应用程序使用, 那么就释放这个块. 这种隐式分配器也叫做 垃圾收集(garbage collection), 诸如 java python js等高级语言就依赖垃圾收集释放已分配的块 显式分配器 #include &lt;stdlib.h&gt; void *malloc(size_t size); void free(void *ptr); malloc 函数返回一个指针, 指向大小至少为 size 字节的内存块, 这个块的地址会根据操作系统模式32(8)/64(16)做对齐以方便访存 free 函数释放指针指向的堆块, 如果它合法 #include &lt;unistd.h&gt; void *sbrk(intptr_t incr); sbrk 函数将内核的 brk 指针增加 incr 来扩展/收缩堆, 成功返回 brk 的旧值, 否则返回 -1 (void * 强转 int), incr 可正可负可0 下图展示了一个简单的动态内存分配的过程 这里有两点需要说明: b 中虽然只申请了 5 字节的堆大小, 由于整个堆空间需要双字节补齐, 所以填补了一个字节的空间, 实际上分配的是一个 6 字节的块 d 中虽然释放了 p2 指针指向的堆块, 但是 p2 指针仍然指向这个位置, 应用有责任不再使用 p2 指针访问一个已经被释放的堆空间 使用动态内存分配的最主要原因就是我们并不清楚某些数据结构的大小, 或者数量等等. 比如拆分一个字符串保存在一个数组中, 诸如此类的问题我相信不必赘述 要求和目标 显式分配器必须在一些相当严格的约束条件下工作 处理任意请求序列: 一个引用可以以任意的顺序发送分配请求和释放请求, 分配器不可以假设分配和释放请求的顺序, 例如分配器不能假设所有分配请求都有相匹配的释放请求 立即响应请求: 分配器必须立即响应分配请求, 因此不允许分配器为了提高性能重排序或者缓冲请求 只使用堆: 为了使分配器可扩展, 分配器使用的任何非标量数据结构必须保存在堆中 对齐块 不修改已分配的块: 分配器只能操作或者改变空闲块, 特别的是一旦块被分配了, 就不允许修改或者移动它了. 因此诸如压缩已分配块这样的技术是不允许使用的 非标量数据例如数组、结构体、类、对象等。这些数据类型通常需要在堆内存中动态分配内存空间，并且它们的大小和形状在编译时通常是未知的. 相对应的，标量数据指的是只包含单一值的数据类型，例如整型、浮点型、字符型等。这些数据类型的大小和形状在编译时通常是已知的，并且它们可以在栈内存中被直接分配和访问 在计算机系统中，数据存储时需要遵循一定的对齐规则。对齐是指将数据的起始地址与某个固定的值对齐，通常为2的整数次幂。例如，对于4字节的数据类型，通常需要将其对齐到4字节的边界。这样可以提高数据访问的效率，避免不必要的内存访问操作。 对于内存分配器而言，它需要对分配的内存块进行对齐，以保证内存块能够存储任何类型的数据结构。例如，如果内存分配器分配的内存块不满足对齐要求，那么当程序员试图将一个需要对齐的数据类型存储在这个内存块中时，就可能会发生数据对齐错误的问题，导致程序出错或崩溃。 因此，内存分配器需要对齐分配的内存块，以保证内存块能够存储任何类型的数据结构，并且程序能够正常地访问和操作这些数据结构 内存分配器的目标有如下两个 最大化吞吐率: 吞吐率定义为单位时间内完成的请求数, 比如 1s 内完成 500 次分配请求和 500 次释放请求那么吞吐率是 1000 最大化内存利用率 分配器设计中的一个有趣的挑战就是在两个目标之间找到一个适当的平衡 造成堆利用率很低的主要原因是一种被称为 碎片 的现象: 内部碎片: 一个已分配块比有效载荷大 很多情况可能导致这个情况, 例如一个分配器的实现对分配块强加一个最小值, 这个值比实际申请的要大. 或者为了满足对齐要求而补齐 外部碎片: 如下图, 由于多次的分配和释放, 现在堆中已分配的块被划分为一块一块的, 此时如果希望申请一个 40MB 的堆块, 虽然空闲块的总量足够但是没有一块连续的空间. 注意到分配器的要求不可以修改已分配的块, 即 压缩排列块 是不合法的. 这种情况只能使用 sbrk 向操作系统申请扩大堆 隐式空闲链表 为了更好的组织已分配的块和空闲块, 我们可以使用隐式空闲链表来串联整个堆, 下图为隐式链表的每个节点的数据结构图 其中开头使用 4 字节(32位) 来表示整个块的相关数据, 开头的 32 位用于表示整个块实际分配了多大. 需要注意的是, 每一个分配的块必须要是8字节对齐, 所以实际上分配块一定的 8 的整数倍, 所以最后 3 位一定全为 0, 这样最后三位就空闲了出来, 我们将最后一位设置为标记位用于区分该块是已分配的还是空闲的 举个例子: 对于 malloc(1) 的分配请求, 虽然只请求了 1 个字节, 但是我们需要先加 4 字节的头部信息, 所以目前是 4+1 = 5 字节, 但是为了满足 8 字节(64位)对齐以提高数据访问的效率，避免不必要的内存访问操作, 实际分配的块大小是 8 字节, 对应的实际块情况如下所示 图中字节的面积比例有点不对,应该是 4:1:3 , 大家理解我的意思就好… 开头的 4 字节是 0x00 00 00 09, 由于分配块一定是 8 位对齐, 所以最后 3 位空出来, 0x1000 表示分配块的实际大小, 最后一位表示分配(1)还是未分配(0), 最后填充3B对齐 再举一个例子: 如果是 malloc(13) 的话, 分配块的结构如下所示 接下来我们来看一下堆中隐式链表的块是如何组织起来的, 以书上这张图为例 其中每一个正方形块代表 4 字节, 这里的 8/0 16/1 表示的意思是 分配块的大小/已分配位, 红色块为链表头, 蓝色块为实际申请的内存大小, 灰色块为填充位. 所以整个堆被划分为了几部分, 4字节空闲 + 8字节已分配 + 24字节空闲 + 12字节已分配, 中间穿插着一些头部信息块和填充块. 再创建一个链表结构保存头节点的相关信息, 以实现后续的分配释放 分割 对于一个 k 字节的内存申请, 分配器搜索空闲链表块找到一个足够大的可以放置请求块的空闲块. 分配器执行这种搜索的方式是由放置策略决定的, 一些常见的策略是: 首次适配(first fit): 选择第一个合适的空闲块 下一次适配(next fit): 从上一次查询结束的地方开始首次适配 最佳适配(best fit): 检查每个空闲块, 选择适合所需请求大小的最小空闲块 如果分配器不能找到合适的空闲块, 那么一个选择是合并哪些在物理上相邻的空闲块, 把他们合并为一个大块. 如果依然不可以, 那么分配器会调用 sbrk 函数向内核申请额外的堆内存. 分配器将额外的内存转化为一个大的空闲块, 将这个块插入到空闲链表中, 然后将被申请的块放置在这个新的空闲块中 合并 当分配器释放一个已分配的块, 这时候如果有其他空闲块和这个新释放的空闲块相邻, 这些相邻的空闲块会造成一种现象 “假碎片”: 有许多可用的空闲块被切割成小的, 无法使用的空闲块 为了解决这个问题, 分配器必须考虑合并相邻的空闲块, 但这时候存在一个重要的策略决定就是 何时执行合并? 立即合并: 这种方式简单明了, 可以在常数时间内完成, 但是对于某些请求模式, 这种方式会产生一种形式的抖动, 块会反复的合并, 然后再次分割, 如下图所示 推迟合并: 直到某个分配请求失败, 扫描整个堆, 合并所有的空闲块 我们假设会使用立即合并, 但是同时也应该清楚快速的分配器通常会选择某种形式的推迟合并 如果当前被释放的块的链表指针指向的下一个块是空闲块, 那么我们很容易将其合并, 只需要修改当前块的头中的块大小, 加上后面块的大小即可 但是如果当前被释放的块的前一个块是空闲块, 那么情况稍微有些棘手. 因为我们使用的是一个单链表, 无法在常数时间内找到前一个块. 一个非常聪明且通用的技术叫做 “边界标记”, 如下图所示, 我们修改之前的分配块结构, 在结尾补充一个四字节, 与头完全相同, 这样分配器就可以通过检查它的尾部来判断前一个块的起始位置和状态了 这里可能有人会有一些疑惑 第一: 为什么使用的是单链表呢? 正常来说如果我们改成双链表的话就可以在常数时间内找到前一个块了, 主要是因为单链表相对于双链表来说，具有更小的存储开销和更快的插入和删除操作。在单链表中每个节点只包含一个指针，而双链表每个节点包含两个指针。因此，使用单链表可以节省存储空间，并且在插入和删除节点时具有更高的效率. 但实际上我们使用的这种 “边界标记” 相当于把这部分开销放到了堆块上了, 有舍有得 第二: 加一个尾部怎么就能判断了呢? 如果没有尾部, 我们无法找到前一个块的主要原因就是因为我们不知道前一个块是不是空闲的, 或者分配了多少, 但是如果有了尾部的四字节, 我们就可以向前读四个字节来查看前一个块的信息, (块大小 - 8)就是块的空间, 由于分配块的结构固定所以相对位置都是固定的 当分配器释放一个块的时候有如上四种情况, 其中中间空白处+前后的头/尾组成了一个完整的分配块, m1 m2为块大小, a/f 表示这个块是已分配的还是空闲的. 蓝色的块是当前分配器考虑释放的块 前后都是已分配的 前是已分配的, 后是空闲的 前是空闲的, 后是已分配的 前后都是空闲的 当释放当前块的时候, 分配器只需要检查当前块的前一个块的尾部, 和后一个块的头部, 就可以判断当前块所处的状态, 以右侧的状态完成合并 虽然边界标记的设计简单优雅, 但是它要求每个块都保持一个头部和尾部, 所以在应用程序操作许多个小块的时候会产生显著的内存开销. 例如当一个图形节点反复的调用 malloc free 来动态的创建和销毁节点, 如果每个节点都只 malloc(8), 那么头部和尾部将占据已分配块一半的空间 brk sbrk brk 的全称是 “break”，而 sbrk 的全称是 “set break”。这两个函数的名称都与操作系统的内存管理机制中的 “break” 概念有关。 在早期的操作系统中，堆空间被划分为低地址区域（Low Memory）和高地址区域（High Memory），两者之间的边界被称为 “break”。这个边界指示了堆空间的结束位置，也就是可用内存的末尾。通过调整 “break” 的位置，操作系统可以动态分配和释放堆空间。 因此，“break” 在这里表示堆空间的边界或结束地址。brk 和 sbrk 这两个函数提供了在用户程序中直接操作 “break” 的接口，以动态分配和释放堆内存。 #include &lt;unistd.h&gt; int brk(void *addr); void *sbrk(intptr_t increment); 通常不直接使用, 高级语言和标准库提供了更方便和安全的内存管理机制比如 malloc, new","categories":[],"tags":[{"name":"体系结构","slug":"体系结构","permalink":"https://luzhixing12345.github.io/tags/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"}]},{"title":"虚拟内存","slug":"体系结构/虚拟内存","date":"2023-03-26T10:05:47.000Z","updated":"2023-04-23T06:57:42.334Z","comments":true,"path":"2023/03/26/体系结构/虚拟内存/","link":"","permalink":"https://luzhixing12345.github.io/2023/03/26/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/","excerpt":"","text":"简介 一个系统中的进程与其他进程共享CPU和主存资源, 然而共享主存会形成一些特殊的挑战, 例如如果太多的进程需要太多的内存, 那么它们中有一些就根本无法运行; 如果某个进程不小心写入了另一个进程使用的内存, 就可能导致另一个进程以某种完全和程序逻辑无关的方式失败 因此为了更加有效的管理内存并且减少出错情况, 现代操作系统提供了一种对主存的抽象概念: 虚拟内存(Virtual Memory) 虚拟内存提供了三个重要的能力 将主存看作一个高速缓存, 只保存活动区域, 根据需要在磁盘和主存之间来回传输数据 为每个进程提供一致的地址空间, 简化内存管理 保护每个进程的地址空间不被其他进程破坏 虚拟内存赋予应用程序强大的能力, 可以创建和销毁内存片(chunk), 将内存片映射到磁盘文件的某个部分, 以及与其他进程共享内存. 比如我们可以通过读写内存位置读或者修改一个磁盘文件的内容, 或者可以加载一个文件的内容到内存中, 而不需要进行显式的复制 同时虚拟内存也是危险的, 当应用程序引用一个变量, 间接引用一个指针, 或者调用一个诸如 malloc 这样的动态分配程序时, 就会与虚拟内存交互, 如果使用不当可能遇到复杂危险的错误, 例如 “段错误” 或者 “保护错误” 物理地址和虚拟地址 主存被组织成一个有 M 个连续的字节大小的单元组成的数组, 每一个字节都有唯一的物理地址 CPU访问内存的最自然的方式就是使用物理地址, 这种方式被称为 物理寻址 上图表示 CPU 读取从物理地址 4 开始的连续 4 个字节, 当 CPU 执行这条加载指令的时候会生成一个有效的物理地址, 和取址长度, 通过内存总线传递给主存; 主存根据地址找到物理地址为 4 的单元, 取出连续的 4 个字节, 并将其返回给 CPU, CPU 将其存放在一个寄存器之中 在早期 PC 上使用的是物理地址, 现代 CPU 使用的虚拟地址的寻址方式 CPU 通过生成一个虚拟地址(VA)来访问主存, 这个虚拟地址在被送到内存总线之前先传递到 CPU 芯片上的 MMU (Memoryy Management Unit)单元, 将一个虚拟地址转换成物理地址, 在传输给内存. 这一步需要 CPU 硬件和操作系统紧密结合 系统中实际存在的内存空间是物理地址空间, 一共有 M 字节, 其中 M = 2^m, 物理地址空间范围是 {0, 1, …, M - 1} CPU 从一个 n 位地址空间中构建虚拟地址空间, 一共 N 字节, 其中 N = 2^n, 虚拟地址空间的范围是 {0, 1, …, N-1} 值得注意的是, 虚拟地址空间和物理地址的空间没有什么关系, 物理内存实际上就是电脑上的内存,一般是 8GB 16GB(2^34)那样; 虚拟地址空间则可以很大, 如果是 64 位的虚拟地址空间, 则可以表示大约 2^64 = 16384P 大小的虚拟地址空间 另外并不是 64 位机器所用的是 64 位的虚拟地址空间, 这对于虚拟内存来说实在是太大了, linux目前使用的是48位的虚拟地址空间, 即256TB. windows 使用的是47位, 即128TB 虚拟内存可以被看作一个存放在磁盘上的数组, 大小为 N, 每字节都有一个唯一的虚拟地址, 作为到数组的索引. VM 系统通过将虚拟内存分割称为虚拟页(Virtual Page, VP)的大小固定块, 每个虚拟页的大小是 P = 2^p 字节, 类似的物理内存也被分割为物理页(Physical Page, PP), 物理页大小和虚拟页一样都是P字节 , 物理页也可以称为页帧 Linux 与 Windows 都是采用 4kb作为 在任意时刻, 虚拟页面的集合都可以分为三个不相交的子集 未分配的(unallocated): 没有任何数据和该虚拟页面相关联, 不占用任何磁盘空间 缓存的(cached): 当前虚拟页面已被分配数据, 并且缓存在物理内存中 未缓存的(uncached): 当前虚拟页面已被分配数据, 但未被缓存在物理内存中 上图中 VP0 VP4 是未分配的页面, VP2 5 7 是已分配并且缓存的, 剩下的是已分配未缓存的 这里有几个小问题需要解释一下, 上文说虚拟内存可以被看作一个存放在磁盘上的数组, 大小为 N, 也就是按理来说我们希望 N 刚好为磁盘大小, 但实际上计算机组成的磁盘空间是不确定的, 而操作系统 linux 48位, windows 47位, 也就是说实际上虚拟内存已经在操作系统初始化完成之后确定下来了, 256/128TB, 正常来说这个空间对于我的磁盘是足够大的, 假设我有 1TB 的磁盘, 那么多出来的 255/127TB, 也就是最高位并没有用到, 1TB的磁盘根据虚拟页划分, 映射到虚拟内存, 这没有问题 但是当磁盘空间大于256TB时, 48位的虚拟地址空间就不足了, Linux中如果需要访问大于256TB的磁盘空间，可以使用LVM（逻辑卷管理器）等技术来扩展磁盘空间, 这种特殊情况并不在本文讨论范围之内 也并不是说磁盘空间大于 256TB 就一定要一次性全部映射到虚拟地址空间, 分段映射也是合理的 在早期的系统比如 DEC PDP-11上, 虚拟地址空间甚至比物理地址空间还要小, 但使用虚拟地址空间仍然是一个非常有用的机制, 可以大大简化内存管理, 通常来说在现代操作系统上 物理内存空间 M &lt;&lt; 虚拟内存空间 N 下面会涉及到几个概念, SRAM缓存表示 CPU 内部的 L1 L2 L3 高速缓存, 用于缓存主存来的页帧 DRAM缓存是指内存中对于虚拟页的缓存, 也就是上文提到的 “缓存的虚拟页” 在存储层级结构中, DRAM 比 SRAM 大约慢 10 倍, 磁盘要比 DRAM 大约慢 100000 倍, 所以 DRAM 缓存不命中带来的惩罚要比 SRAM 缓存不命中多得多, 主要是因为 DRAM 缓存不命中要由磁盘来服务, 而 SRAM 不命中则基于 DRAM 服务, 磁盘扇区的读写速度要比内存慢很多很多 所以我们希望磁盘和 DRAM 之间可以有很好的替换策略, 尽可能地减少 DRAM 缓存不命中的情况 页表 与缓存类似, 虚拟内存系统需要有办法可以判断一个虚拟页是否缓存在 DRAM 中, 并且确定存放在哪一个物理页中. 如果缓存不命中, 那么还需要判断虚拟页应该对应磁盘的哪个位置, 并且需要从物理内存中选择一个牺牲页, 将虚拟页从磁盘复制到 DRAM 替换掉牺牲页 虚拟内存系统的功能是由软硬件联合提供的, 包裹操作系统, MMU(内存管理单元) 中的地址翻译硬件和一个存放在物理内存中的页表(page table)的数据结构, 页表负责保存虚拟内存到物理内存的映射关系, 操作系统负责维护页表的内容, 当地址翻译硬件试图将一个虚拟地址转换到物理地址的时候会读取页表, 然后根据页表中的信息找到对应的物理地址 上图是一个页表的基本结构, 页表是常驻内存的, 它是一个页表条目(PTE, Page Table Entry)的数组, 每一个页表条目有一个有效位(valid bit)和 m 位的磁盘地址组成 这里的 m 是上文提到过的物理地址空间的大小, M = 2^m 上图中左侧是页表, 我们可以根据其中的索引找到对应的 PTE. 如果有效位为1则说明该 PTE 构建了一个从 VP 到 PP 的映射, PTE 中的 n 位地址是主存中的物理页号 如果有效位为0 如果 n 位地址不空, 则该 PTE 没有使用, 但已经与一个 VP 绑定了, 即未缓存虚拟页 如果 n 位地址为空, 则该 PTE 还没有被分配 这里注意要与之前的虚拟页和物理页区分开, 虚拟页是在磁盘中的, 物理页是在 DRAM 中, 页表也是在 DRAM 中, 下图中的映射关系没有改变, 只是借助页表这一数据结构实现了一种映射关系 页命中与缺页 当 CPU 想要读 VP2 虚拟内存中的一个字的时候, CPU 将虚拟地址发送给 MMU, MMU 查找页表进行地址转换, 通过某种技术通过虚拟地址定位到索引, 找到页表中的 PTE2, 发现其有效位为 1, 说明该 PTE 有效, 则取出其中保存的物理内存地址, 找到物理内存中的数据, 如下图所示 但如果 CPU 发出一条指令希望读取 VP3, 此时发现有效位为0, 说明 VP3 并未被缓存, 操作系统触发一个缺页异常, 调用内核的缺页异常处理程序, 选择 DRAM 中的一个物理页作为牺牲页, 假设选中的是位于 PP3 的 VP4, 则内核从磁盘复制 VP3 到内存 PP3, 更新 PTE3, 如下图所示 当异常处理程序返回的时候, CPU会重新启动导致缺页的指令, 把之前导致缺页的虚拟地址重新发送到 MMU, 此时VP3 已经缓存在 DRAM 中了, 所以正常处理执行 关于虚拟内存有如下的一些相关名词, 磁盘和内存之间传送页被叫做 交换 或者 页面调度, 当有不命中发生的时候才换入页面的调度策略叫做 按需页面调度, 这也是现代所有系统都使用的页面调度策略 实际上操作系统为每一个进程都提供了独立的页表, 也就是每一个进程都会对应以一个独立的地址空间, 上图中只展示了 VP 和 PP的部分, 地址翻译的过程对应页表, 我们注意到进程i的 VP2 和进程j的 VP1对应的都是 PP7 的物理页面, 说明多个虚拟页面可以映射到同一个物理页面当中 简化链接 独立的虚拟地址空间允许每个进程的内存映像使用相同的基本格式, 比如 64 位地址空间中所有代码拗断都是 0x400000 开始的, 数据段在代码短之后, 栈段从用户进程的最高地址空间向下生长 这样的一致性的地址空间大大简化了链接器的设计和实现, 不再需要去关系实际物理内存中的地址映射关系, 而是在一个统一的地址视图中执行程序 简化加载 当我们运行一个可执行文件的时候, 我们希望将其加载到内存中, Linux 加载器只需要简单的为代码段和数据段分配虚拟页, 然后将其标志位置 0, 加载器实际上并不从磁盘复制任何数据到内存, 只是创建一个未缓存的虚拟页, 该进程分配到时间片开始执行之后再通过缺页中断完成加载 将一组连续的虚拟页映射到任意一个文件的任意位置称为 内存映射, Linux 提供了一个 mmap 的系统调用, 允许应用程序自己做内存映射 简化共享 每个进程有自己的代码, 数据, 堆, 栈, 不与其他进程共享. 但通常来说我们会需要进程共享代码和数据, 比如每个进程都可能需要调用系统调用以及一些 C 标准库的程序, 比如 printf; 操作系统只需要将这部分经常使用的程序加载到内存一次, 让其他所有进程在使用的时候映射到相同的物理页面即可, 而不是为每个进程都创建一份副本 简化内存分配 当程序调用 malloc 希望分配在堆空间分配一块内存的时候, 操作系统只需要分配 k 个连续的虚拟内存页面, 然后将其映射到物理内存中的任意k 个物理页面即可, 虚拟内存页面需要连续, 但是物理内存的页面没有必要连续, 可以由操作系统的内存分配器寻找最合适的位置 改进 一个现代操作系统应该可以做到对内存系统的完全控制, 包括不允许一个用户进程修改它的只读代码段, 不允许读写其他进程的私有内存, 不允许修改与其他进程共享的虚拟页面(除非共享者都显示的允许) 就像我们上文提到过的, 操作系统通过虚拟内存提供了独立的地址空间, 而虚拟内存地址到物理内存地址的映射由操作系统和 MMU 控制, 我们可以在 PTE 页表项中添加一些标志位, 可以在地址翻译阶段更加容易的判断权限和合法性 上图中添加了三个权限标志位 SUP: 进程是否必须运行在内核态的进程才可以访问, 用户态进程只允许访问 SUP=0 的页面 READ: 读权限 WRITE: 写权限 如果进程执行的过程中发出了一条指令, 希望读取一个页面, 但是操作系统发现该进程没有这个页面的写权限(比如修改 const 变量) 或者不是内核态进程, 则 CPU 触发异常, 并将控制传递给内核中的异常处理程序, 也就是我们编程过程中很常见的, Linux shell 一般将这种异常报告称为 “段错误(segmentation fault)” 当然,上图中原先的有效位被隐藏了, 页表中依然保留了这一位用于判断 PTE 是否有效 地址翻译 开始本节内容之前我们先列举一下所需的所有符号简写, 希望读者预览一下有一个大致的印象, 如果后文出现了对应的符号可以到这里对照 符号 描述 N = 2^n 虚拟地址空间中的地址数量 M=2^m 物理地址空间中的地址数量 P=2^p 页的大小 PTBR Page Table Base Register, CPU中的一个控制寄存器, 指向当前页表 VPO 虚拟页面偏移量 offset VPN 虚拟页号 number TLB Translation Lookaside Buffer 快表 TLBI 快表索引 index TLBT 块表标记 tag PPO 物理页面偏移量 PPN 物理页号 CO 缓冲块内字节偏移量 cache offset CI 高速缓冲索引 CT 高速缓冲标记 上图展示了 MMU 是如何利用页表实现这种映射的 首先每个进程中保留着页表的基地址, 需要访存的时候传送给 PTBR, 指向页表的起始地址 整个虚拟地址跟据业内偏移量(p, 通常4kb, 12位)被分割为 VPN VPO 两部分 VPN 对应该页表的索引值, VPN = 13, 则对应页表的索引值也是13, 找到与虚拟页面对应的 PTE MMU 判断有效位是否为 1 如果为 1 则说明该 PTE 已经和物理地址完成映射, 直接取其中地址 如果为 0 则说明该 PTE 无效, 产生缺页中断, 从磁盘中将 VP 读入 DRAM, 并完成 PTE, 再将有效位置 1, 重新执行该指令 将 PTE 中的 PPN 取出, 与 VPO 结合得到实际的物理地址. 由于虚拟页和物理页都是 P 字节的, 所以实际上 PPO 就是 VPO, 只是完成了 VPN -&gt; PPN 的替换 当页面命中时, 上图中的12345流程分别对应 处理器生成一个虚拟地址, 并将其传给 MMU MMU 生成 PTE 地址, 从高速缓存/主存中请求该 PTE 高速缓存/主存向 MMU 返回 PTE MMU 构造物理地址, 将其传送给高速缓存/主存已请求数据所在的物理地址 高速缓存/主存返回所请求的数据字交给处理器 这个过程完全是由硬件来处理的 上图中的 PTEA 是 PTE address的缩写 当页面不命中的时候, 即有效位为 0, 情况稍微复杂一点 处理器生成一个虚拟地址, 并将其传给 MMU MMU 生成 PTE 地址, 从高速缓存/主存中请求该 PTE 高速缓存/主存向 MMU 返回 PTE PTE 有效位为 0, MMU 触发异常, 传递给 CPU, 由操作系统内核的缺页异常处理程序 缺页处理程序通过算法确定出物理内存的牺牲页, 如果这个页面已经被修改了则将其换出到磁盘 缺页处理程序将该虚拟页面调入到物理内存, 替换牺牲页, 并更新 PTE 缺页处理程序返回到原来的进程, 再次实行导致缺页的指令 此时 CPU 再次将之前引起缺页异常的虚拟地址发送给 MMU, 由于对应的 PTE 已经被更新了, 所以就可以正常执行了 实际上在既使用高速缓存, 也是用虚拟内存的系统中, 还有一步关于高速缓存是否命中的情况的讨论, 如下图所示 TLB 前面我们讨论的页表命中的情况, 如下图, 此时 CPU 产生一个虚拟地址, 需要先由 MMU 根据 PTBR 和 VPN 索引访问一次内存找到对应的 PTE, 在根据 PTE 中的地址找到对应的物理地址访存一次得到数据, 这个过程经历了两次访问内存 许多系统都希望可以消除这种开销, 所以在 MMU 中包含了一个关于 PTE 的小型缓存 TLB 快表 当虚拟地址发送到 MMU 之后, 先根据 P 分离出后 p 位得到 VPO, 这部分是页内偏移量与页表匹配的过程无关, 高位的 VPN 在被 TLB 分为高位和低位, TLB 中有 T=2^t个组, 高位为 TLBT, 低位为 TLBI 先根据 TLBI 找到 TLB 的对应索引, 如果该 TLB 表项的 TLBT 和这里的 TLBT 相同, 则认为 TLB 命中, 否则不命中; 如果命中那么就不需要访问内存直接将命中的 TLB 表项发送给 MMU 作为 PTE 即可 如果没有命中则走之前的流程, 再更新的过程还需要再更新一下 TLB, 类似的根据算法选择一个牺牲页 多级页表 对于一个 32 位的地址空间来说, 4KB 的页大小意味着 p = 12, 所以 VPO 是12位, VPN是20位. 页表也要保存在虚拟页中, 即使每一个 PTE 表项只保存物理地址也需要 4B(即不考虑有效位, SUB READ WRITE), 所以一页中最多可以保存的 PTE 数量是 4KB/4B = 1K = 2^10, 一共 VPN 是20位, 所以为了保存所有的虚拟页面, 至少需要 220/210 = 2^10 个虚拟页, 这些虚拟页只是用来保存页表. 这些虚拟页一共是 1K x 4KB = 4MB, 所以这 4MB 的内存空间没有用来保存任何程序相关的数据, 只是用来保存页表. 对于每一个进程来说都需要一个 4MB 内存空间来存储其需要的页表, 这未免有些太占空间了 而对于一个 64 位的系统来说(地址8B), 每个进程页表占用内存的大小达到了惊人的 2^43 x 4KB, 即使只使用 48 位的虚拟地址空间, 也需要 2^27 x 4KB, 这显然是无法接受的 但事实上, 对于一个 64 位程序来说, 虽然虚拟地址空间很大(256TB), 但实际上我们编写的程序并不需要那么多内存, 也就是说除去虚拟页4KB的12位, 虽然还剩下 52 位, 也就是 2^52 个虚拟页需要保存, 但没有必要都把这么多虚拟页同时存在内存中, 最理想的情况是我们只把用到的那几个虚拟页保存在 DRAM 中, 剩下的都不存, 即使突然又要访问另一个虚拟页中的数据, 那么使用缺页中断再将这个页面调入内存即可 那么很容易想到的一个办法就是, 52 位的虚拟页表索引项太多了, 我们可以将其分割开来, 使用多级页表 如上图所示, 假设对于一个 48 位的虚拟地址空间, 我们对于高 32 位每隔 p(12位) 做一个划分, 原先的 VPN 被划分为三段(下文简称 VPN1 VPN2 VPN3), 对应三级页表 其中 VPN1 对应 VPN 的最高12位, 其中索引项是 2^12 个, 为了保存这么多索引项我们只需要付出的内存代价是 32KB 64位系统地址 8B, 虚拟页 4KB, 假设每个 PTE 只保留地址(需要8B), 每个虚拟页可以保存 4KB/8B = 2^9 个 PTE, 所以一共需要 212/29 = 8 个虚拟页, 8 x 4KB = 32KB 由于虚拟地址的使用是接近连续的, 低地址会连续使用到但是高 12 位几乎不会连续使用, 因为高 12 位的加 1 相当于加了 2&lt;&lt;24 的地址空间 所以一级页表的 PTE 被使用的极少, 基本上一两个 PTE. 这是一种巨大的潜在节约, 这意味着我们只需要存有限的必要的一些页表即可 以上图为例, 其中一级页表中只有 1 个 PTE 是有效的, 我们根据 PTBR0 找到一级页表的位置, 再根据 VPN1 的索引找到对应的 PTE, 这个 PTE 中保存的地址是其指向的二级页表的 PTBR1, 再重复这个过程, 通过 PTBR1 定位到了这个二级页表, 再根据二级页表索引 VPN2 找到其中三个有效的 PTE, 这三个 PTE 分别保存着其指向的三级页表的 PTBR2/3/4, 再定位到三级页表, 再根据三级页表索引 VPN3 定位到 PTE, 这个 PTE 联系了这个虚拟地址代表的虚拟页和物理页的映射, 这个虚拟页实际上才是我们需要使用的. 我们最后再通过这个 PTE 的地址找到物理页 PPN, 然后通过偏移量 VPO 读取到对应的数据. 完整过程如下图所示 Linux 虚拟内存系统 相信你一定已经多次看到下面这张图了 整个虚拟内存空间分为上下两部分, 最高地址是内核虚拟内存, 下面是进程的虚拟内存; 内核虚拟内存包含内核的代码和全局数据结构 Linux 将一组连续的虚拟页面(大小等同于 DRAM 的总理)映射到相应的一组连续的物理页面, 这就为内核提供了一种变量你的方法来访问物理内存中任何特定的位置. 这就为内核提供了一种便利的方法来访问物理内存中的特定位置; 换句话说, 在虚拟地址空间中如果要访问页表, 页表保存在内核虚拟内存中, 始终处于一个相对固定的虚拟地址位置 上图记录了 Linux 虚拟内存的相关数据结构, 内核为系统每个继承维护一个单独的任务结构 task_struct, 其中 task_struct 中的元素包含指向内核运行该进程所需的所有信息(比如 PID 指向用户栈的指针 可执行目标文件名 程序计数器等等) task_struct 中的一个元素指向 mm_struct, 它描述了虚拟内存的当前状态, 其中比较重要的是 pgd mmap 字段, pgd 指向一级页表的基地址, 当内核运行这个进程的时候就将 pgd 放入 PTBR; mmap 指向一个 vm_area_structs 的链表, 每个 vm_area_structs 都描述了当前虚拟地址空间的一个区域, 你可以在上图中看到每一个 vm_area_struct 都指向虚拟内存空间中的一段地址, 其中 vm_start: 区域起始 vm_end: 区域结束 vm_prot: 区域内所有页的读写许可权限 vm_flags: 区域内页面的一个标记位(与其他进程共享还是私有的) vm_next: 指向下一个 vm_area_struct 结构 注意下面是低地址, 上面是高地址, 所以 vm_start 指向下面 相关的元素会在 mmap 函数中再次看到 当 MMU 试图翻译某个虚拟地址 A 但是发现缺页了, 这时候可能会有如上三种情况 虚拟地址 A 不合法, A 不在任何一个 vm_area_struct 区域之内, 缺页处理程序触发一个段错误 虚拟地址 A 合法, 但 A 的内存访问不合法, 比如进程的只读区域中进行写操作(修改 const 变量), 试图从内核虚拟内存中读取字, 缺页处理程序会触发一个段错误 虚拟地址 A 合法, 那么就选择一个牺牲页, 如果牺牲页被修改过则将其交换出去, 将新的页面换入并更新页表. 缺页处理程序返回之后 CPU 重新启动引起缺页的指令 这里的第一点要说明一下, 因为一个进程可以创建任意数量的新虚拟内存区域, 所以顺序搜索区域结构的链表花销会很大, 因此在实际中 Linux 在链表中构建一个一棵树并在这个树上进行查找 内存映射 Linux 通过将一个虚拟内存区域于一个磁盘上的对象关联起来, 以初始化这个虚拟内存区域的内容, 这个过程被称为内存映射 内存映射的概念来源于一个聪明的发现, 如果虚拟内存系统可集成到传统文件系统当中, 那么就能提供一种简单而高效的把程序和数据加载到内存中的方法. 每个运行着 Linux shell程序的bash进程都有相同的代码区域, 每个C程序都需要来自标准C库的诸如 printf 这样的函数, 如果每个进程内都在物理内存中保存相同的代码副本, 那就是极端的浪费了. 幸运的是内存映射给我们提供了一种清晰的机制, 用来控制多个进程如何共享对象 内存映射的对象有两种 Linux 文件系统中的普通文件: 我们可以创建一块虚拟内存区域用于映射, 包含多个虚拟内存页. 在内存映射的环节将这些虚拟页与文件区的片进行一个对应. 值得注意的是这些虚拟页实际上并没有交换到物理内存中, 直到 CPU 第一次引用到这样一个区域内的虚拟页面才会被通过缺页中断换入物理内存 匿名文件 一旦一个虚拟页面被初始化了, 他就在一个由内核维护的专门交换文件之间换来换去, 交换文件也叫做交换空间(swap area). 在任何时刻, 交换空间都限制着当前运行中的进程能够分配的虚拟页面的总数 一个对象可以被映射到虚拟内存的一个区域, 要么作为 共享对象, 要么作为 私有对象 对于共享对象: 该虚拟内存区域为共享区域, 这个进程对共享对象的任何写操作, 对于其他使用共享对象的进程也是可见的, 这些变化也会反映到磁盘上的原始对象 对于私有对象: 该虚拟内存区域为私有区域, 对于其他进程来说是不可见的, 并且进程对私有对象的写操作并不会反映到磁盘上的对象 上图中假设进程 1 将一个共享对象映射到它的虚拟内存的一个区域中, CPU 引用这个页面之后会在物理内存中创建一份副本 当进程 2 页将同一个共享对象映射到虚拟内存的时候, 由于每个对象都有唯一的一个文件名, 内核可以迅速的判断进程 1 已经影射了这个对象, 并且可以使进程 2 的页表条目指向相应的物理页面. 关键点在于即使对象被映射到了多个共享区域, 物理内存中也只需要存放共享对象的一个副本 当进程 1 修改其虚拟页面的数据的时候, 这个修改会同步到物理内存, 磁盘, 物理内存的修改会影响到其他引用共享对象的进程 对于私有对象来说, 采用一种十分巧妙的写时复制(copy on write)的技术, 其生命周期的方式基本上与共享对象一样, 在物理内存中只保存私有对象的一份副本 对于每个映射私有对象的进程, 相应私有区域的页表条目都被标记为只读, 并且区域结构被标记为 私有的写时复制, 只有没有进程试图写自己的私有区域他们就可以继续共享物理内存中的对象的一份副本, 但是只要有一个进程试图写私有区域的某个页面, 那么这个写操作就会触发一个保护故障 当故障处理程序注意到保护异常是由于进程试图写 “私有的写时复制” 区域中的一个页面的副本, 他就会在物理内存中创建这个页面的一个新副本, 更新页表条目指向这个新的副本, 然后修改这个页面的可写权限, 如上图所示 故障处理程序返回的时候 CPU 重新执行写操作, 现在在新的页面进行写操作就可以进行正常执行了 我们可以看到通过延迟四有对象中的副本直到最后可能的时刻, 写时复制最充分的使用了稀有的物理内存 fork 当 fork 函数被当前进程调用的时候, 内核为新进程创建各种数据结构, 并分配给他一个唯一的PID, 为了给这个新进程创建虚拟内存, 内核复制当前进程的 mm_struct, 区域结构 页表的原样副本, 将两个进程的每个页面都标记为 只读, 将两个进程中的每个区域结构都标记为 私有的写时复制 当fork的新进程中返回时, 新进程现在的虚拟内存和调用fork时存在的虚拟内存相同. 当这两个进程中的任何一个后来进行写操作时, 写时复制机制就会创建新页面, 也就为每个进程都保持了私有地址空间的抽象概念 当新进程现在的虚拟内存和调用fork时存在的虚拟内存相同时，这意味着新进程可以立即开始执行父进程的代码，不需要额外的内存开销和数据拷贝。这是因为在fork函数被调用时，操作系统会通过写时复制技术为新进程创建一个独立的虚拟内存空间，并将父进程的内存映射信息复制到新的虚拟内存空间中，但是并没有为新进程实际分配物理内存空间，只有在新进程试图修改内存内容时，才会为新进程分配独立的物理内存空间。 因此，在新进程返回之前，新进程和父进程共享同一份虚拟内存空间，这可以保证子进程在执行过程中，与父进程使用同样的代码和数据，从而可以有效地节省内存使用和提高程序执行的效率。另外，由于写时复制技术的存在，子进程和父进程之间的内存空间是互相独立的，这意味着它们之间的数据操作不会互相影响 execve execve(&quot;a.out&quot;,NULL,NULL); execve 函数在当前进程中加载并运行包含在可执行目标文件中的程序, 用 a.out 替换当前程序 加载并运行 a.out 需要如下几个步骤 删除已存在的用户区域, 删除当前进程的用户部分已存在的区域结构 映射私有区域, 将 a.out 的 data bss text映射到对应的位置 映射共享区域, 如果有 a.out 程序与共享对象的链接, 比如 libc.so, 将共享对象映射到共享区域中 设置程序计数器, 将 PC 指向当前代码区域的入口","categories":[],"tags":[{"name":"体系结构","slug":"体系结构","permalink":"https://luzhixing12345.github.io/tags/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"}]},{"title":"gcc版本切换","slug":"环境配置/gcc版本切换","date":"2023-03-14T06:55:15.000Z","updated":"2023-03-14T06:56:09.378Z","comments":true,"path":"2023/03/14/环境配置/gcc版本切换/","link":"","permalink":"https://luzhixing12345.github.io/2023/03/14/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/gcc%E7%89%88%E6%9C%AC%E5%88%87%E6%8D%A2/","excerpt":"","text":"本文简单记录一下gcc版本的选择 在编译qemu的过程中提示gcc版本至少是7, 我个人的ubuntu使用的是16.04, 默认gcc5.4, 所以还需要更换一下gcc版本 sudo add-apt-repository ppa:ubuntu-toolchain-r/test sudo apt-get update sudo apt-get install gcc-8 安装完成之后可以看到已经有两个gcc版本了 ll /usr/bin/gcc* 接着设置各个gcc版本的优先级, 这里将gcc-8设置为最高优先级,即gcc默认调用的是gcc-8 sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-8 80 sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-5 50 sudo update-alternatives --config gcc # 手动切换gcc版本","categories":[],"tags":[{"name":"环境配置","slug":"环境配置","permalink":"https://luzhixing12345.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"}]},{"title":"zsh配置","slug":"环境配置/zsh配置","date":"2023-02-28T09:58:23.000Z","updated":"2023-03-13T15:30:06.678Z","comments":true,"path":"2023/02/28/环境配置/zsh配置/","link":"","permalink":"https://luzhixing12345.github.io/2023/02/28/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/zsh%E9%85%8D%E7%BD%AE/","excerpt":"","text":"安装 emmm 说实话我个人还是习惯bash了, 不建议 sudo apt install zsh 第一步 → 把 oh-my-zsh 项目 Clone 下来： git clone https://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh 第二步 → 复制 .zshrc cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc 第三步 → 更改你的默认 Shell chsh -s /bin/zsh 重启terminal,看到修改 修改配置 需要修改 ~/.zshrc 历史补全 git clone --depth=1 https://github.com/zsh-users/zsh-autosuggestions.git $&#123;ZSH_CUSTOM:-$&#123;ZSH:-~/.oh-my-zsh&#125;/custom&#125;/plugins/zsh-autosuggestions vim ~/.zshrc # 找到下面这一行,添加 zsh-autosuggestions plugins=(git zsh-autosuggestions) source ~/.zshrc 实时自动补全 mkdir $ZSH_CUSTOM/plugins/incr curl -fsSL https://mimosa-pudica.net/src/incr-0.2.zsh -o $ZSH_CUSTOM/plugins/incr/incr.zsh echo &#x27;source $ZSH_CUSTOM/plugins/incr/incr.zsh&#x27; &gt;&gt; ~/.zshrc source ~/.zshrc 语法高亮插件 git clone --depth=1 https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting vim ~/.zshrc # 添加 zsh-syntax-highlighting plugins (git zsh-autosuggestions zsh-syntax-highlighting) 参考 ohmyzsh theme zsh + oh-my-zsh Linux Zsh 使用 oh-my-zsh 打造高效便捷的 shell 环境","categories":[],"tags":[{"name":"环境配置","slug":"环境配置","permalink":"https://luzhixing12345.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"}]},{"title":"Windows PowerShell美化以及 Vscode 终端美化配置","slug":"环境配置/pws","date":"2023-02-28T09:12:12.000Z","updated":"2023-02-28T09:56:40.041Z","comments":true,"path":"2023/02/28/环境配置/pws/","link":"","permalink":"https://luzhixing12345.github.io/2023/02/28/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/pws/","excerpt":"","text":"Windows Powershell美化以及 Vscode 终端美化配置 效果展示 下载 首先我们配置 Powershell, windows本身的Windows powershell(蓝色的)操作系统自带的并不是我们需要的 微软推出了一个新的终端terminal,是一个跨平台的应用程序,界面与之前的terminal相同但是增加了一些功能 点进去之后有两种下载方式,一种是官方推荐的使用 microsoft store 下载, 另一种就是通过 releases 下载 我个人在microsoft store下载速度很慢,所以安装的最新的realses的版本,注意区分不同操作系统的版本,我是win11 安装之后就可以查看到一个终端预览,打开之后就是基本的界面,明显可以看出做了圆滑,在设置里面也多了许多功能 这里的windows powershell也并不是我们需要的,我们需要格外单独下载一个powershell 之后根据操作系统选择最新的版本就可以了,通常来说都是64位windows所以选择LTS版本的就可以了. 当然你也可以翻阅找到所有releases版本下载 安装之后就可以在开始界面看到多出了一个powershell7,这个就是我们今天的主角 点开之后还是熟悉的界面,没什么变化. 依次执行以下三条命令,他会为你安装 oh-my-posh 和 posh-git 两个模块 安装过程中全部选择 Y Install-Module oh-my-posh -Scope CurrentUser -SkipPublisherCheck Install-Module posh-git -Scope CurrentUser Install-Module -Name PSReadLine -AllowPrerelease -Scope CurrentUser -Force -SkipPublisherCheck 之后导入模块 Import-Module posh-git Import-Module oh-my-posh 在导入 oh-my-posh 中会弹出一段话, 大致意思是目前 oh-my-posh 更新了一个版本,不使用Import-Module oh-my-posh 来安装了,并提供了一个网址 点击进入之后我们看到这是powershell的网址,说明了模块的更新和修改 阅读说明之后按照它的提示首先移除模块的缓存 Remove-Item $env:POSH_PATH -Force -Recurse 然后进入windows的页面,提示我们使用之前下载过的 windows terminal 接着执行 winget install JanDeDobbeleer.OhMyPosh -s winget 短暂的等待之后就安装完成了,本次更新为我们带来了oh-my-posh.exe 和旗下的所有主题 themes 主题选择 现在的powershell还是看起来没什么区别,我们可以选择一款喜爱的主题,执行命令查看所有主题 Get-PoshThemes 看花了眼的话可以在官网的主题页面查看所有主题,选择一个比较喜欢的主题吧,我个人选择的是marcduiker 接着配置主题,命令行中提示了我们如何设置 执行命令 oh-my-posh init pwsh --config C:\\Users\\luzhi\\AppData\\Local\\Programs\\oh-my-posh\\themes/jandedobbeleer.omp.json | Invoke-Expression 当前使用的就是jandedobbeleer主题了,当然你可以选择你的主题名字,注意luzhi变成你的名字就好了 配置文件 看样子可以了,但是你会发现退出再重进又变成最开始的状态了,这时候我们需要设置一个配置文件让每一次运行都执行这条命令 notepad.exe $PROFILE 第一次执行会创建一个新的配置文件,之后在执行就是打开这个配置文件,将上面的命令复制到这里,保存. 之后每一次进入都是这个主题啦! 接着我们美化以下图标 Install-Module -Name Terminal-Icons -Repository PSGallery Import-Module -Name Terminal-Icons 通过ls命令可以看到所有文件都根据它的属性有了不同的图标显示 再次使用 notepad.exe $PROFILE 也将 Import-Module -Name Terminal-Icons 加入其中作为默认启动项 最后我们再设置一下命令行的自动补全,执行命令 Import-Module PSReadLine Set-PSReadLineOption -PredictionSource History 将以下内容添加到$profile结尾 # Shows navigable menu of all options when hitting Tab Set-PSReadlineKeyHandler -Key Tab -Function MenuComplete # Autocompletion for arrow keys Set-PSReadlineKeyHandler -Key UpArrow -Function HistorySearchBackward Set-PSReadlineKeyHandler -Key DownArrow -Function HistorySearchForward # auto suggestions Import-Module PSReadLine Set-PSReadLineOption -PredictionSource History 最后你的配置文件应该和我的类似 oh-my-posh init pwsh --config C:\\Users\\luzhi\\AppData\\Local\\Programs\\oh-my-posh\\themes/marcduiker.omp.json | Invoke-Expression Import-Module -Name Terminal-Icons # Shows navigable menu of all options when hitting Tab Set-PSReadlineKeyHandler -Key Tab -Function MenuComplete # Autocompletion for arrow keys Set-PSReadlineKeyHandler -Key UpArrow -Function HistorySearchBackward Set-PSReadlineKeyHandler -Key DownArrow -Function HistorySearchForward # auto suggestions Import-Module PSReadLine Set-PSReadLineOption -PredictionSource History 可以看到补全和自动提示也出现了 我的主题对于不同的git状态的显示还是不错的 字体 这时候我们会发现一个奇怪的问题,我的主题为什么会有一些奇怪的白框框,当然你的主题可能没有. 出现这个问题的原因是你选择的主题使用了特殊的字体库 Nerd Fonts(书呆子字体),你没有安装这个字体库所以会出现乱码.如果主题没有使用这个字体库那么倒也没有问题 你可以在字体库查看所有字体,我个人比较喜欢的是CodeNewRoman Nerd Font这款字体,新罗马字体我一直比较喜欢~ 你可以直接点击下载,解压之后将压缩包里所有的字体文件点击安装. ohmyposh也提供了一键下载,选择你的字体名字就可以下载了 oh-my-posh font install 现在你可以直接点击powershell来启动你的终端,我们也可以配置默认打开powershell, 选择你的字体,保存 重启就可以发现没有问题了 现在使用终端预览就可以直接打开一个带主题的powershell了,但是会需要先执行配置文件,会有一些卡顿. Vscode终端 打开终端选项然后下拉找到默认终端选择powershell 重启终端之后发现又出现了字体的问题 设置 -&gt; font family 找到字体库,这里默认是空的,填入之前字体名字,然后补一个monospace CodeNewRoman Nerd Font, monospace 这时候你会发现你文本编辑器中的字体也变了,没错,font family是所有的字体库,vscode的默认字体是Consolas,如果你想保持原先的字体,那么只需加在font family的最前面 Consolas, CodeNewRoman Nerd Font, monospace 大功告成了","categories":[],"tags":[{"name":"环境配置","slug":"环境配置","permalink":"https://luzhixing12345.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"}]},{"title":"VMware虚拟机配置","slug":"环境配置/VMware虚拟机配置","date":"2023-02-28T03:44:19.000Z","updated":"2023-05-18T09:21:28.323Z","comments":true,"path":"2023/02/28/环境配置/VMware虚拟机配置/","link":"","permalink":"https://luzhixing12345.github.io/2023/02/28/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/VMware%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%85%8D%E7%BD%AE/","excerpt":"","text":"正常来说 VMWARE 提供了虚拟机的图形界面, 笔者个人倾向于使用 Vscode, 刚好 Vscode 有比较好的远程连接的功能, 所以没有必要在 VMware 中写代码, 只需要开启 VMware 的 Linux 主机, 然后远程连接在本地(windows) 中流畅的写代码, 在本地使用ssh连接虚拟机的终端 VMware与主机SSH 首先需要查看一下ip sudo apt update sudo apt install net-tools kamilu@ubuntu:~$ ifconfig 这里显示的是 192.168.179.139 为我的虚拟机的ip地址, 下面的对应ip需要改为你的实际结果 ens33 Link encap:Ethernet HWaddr 00:0c:29:2a:5e:ef inet addr:192.168.179.139 Bcast:192.168.179.255 Mask:255.255.255.0 inet6 addr: fe80::a63f:f3c5:d9cb:1489/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:62 errors:0 dropped:0 overruns:0 frame:0 TX packets:106 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:23047 (23.0 KB) TX bytes:12551 (12.5 KB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:200 errors:0 dropped:0 overruns:0 frame:0 TX packets:200 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:16319 (16.3 KB) TX bytes:16319 (16.3 KB) 安装ssh相关的 client server sudo apt-get install openssh-client sudo apt-get install openssh-server sudo /etc/init.d/ssh restart netstat -tpl 看到ssh成功启动即为成功 root@ubuntu:/home/kamilu# sudo /etc/init.d/ssh restart [ ok ] Restarting ssh (via systemctl): ssh.service. root@ubuntu:/home/kamilu# netstate -tpl No command &#x27;netstate&#x27; found, did you mean: Command &#x27;netstat&#x27; from package &#x27;net-tools&#x27; (main) netstate: command not found root@ubuntu:/home/kamilu# netstat -tpl Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 ubuntu:domain *:* LISTEN 1016/dnsmasq tcp 0 0 *:ssh *:* LISTEN 3174/sshd tcp 0 0 localhost:ipp *:* LISTEN 783/cupsd tcp6 0 0 [::]:ssh [::]:* LISTEN 3174/sshd tcp6 0 0 ip6-localhost:ipp [::]:* LISTEN 783/cupsd 最后检查一下防火墙是不是关闭了 sudo ufw status # inactive 表示关闭 主机的操作 vmware workstation -&gt; 编辑 -&gt; 虚拟网络适配器 -&gt; 更改设置(管理员权限) 选择VMnet8, 点击 NAT设置 点击添加 主机端口22, 虚拟机IP(刚刚ifconfig看到的192.168.179.139), 虚拟机端口22 如果有很多个虚拟机都需要链接的话换一个主机端口,比如500就行了, 主机端口不能冲突 退出, 应用, 确定 主机处终端使用ssh连接 ssh &lt;NAME&gt;@&lt;IP&gt; # ssh kamilu@192.168.179.139 选择yes,连接成功 host 配置 找到 `C:\\Windows\\System32\\drivers\\etc 下的 hosts, 使用记事本打开(需要管理员权限) 然后添加一行是你的 IP 地址, 重命名一下方便我们使用名字而不是 IP 192.168.232.139 ubuntu2204 接下来就可以使用 ssh kamilu@ubuntu2204 连接了 免密码 关于SSH免密只需要把主机处的公钥 即找到你的 ~/.ssh/ 下的 id_rsa.pub, 复制到~/.ssh/authorized_keys文件中即可 Vscode + SSH Vscode的环境就是使用远程资源管理器登录,由于过程比较简单,推荐几个比较详细的配置流程,如果新手小白遇到了一些问题可以参考 https://zhuanlan.zhihu.com/p/68577071 https://www.cnblogs.com/huoyanCC/p/14730244.html 关于SSH免密只需要把主机处的公钥复制到~/.ssh/authorized_keys文件中即可 443端口 这个问题很恶心, 就是会出现443端口被占用导致出现一些问题 如下两个方法并没有解决我的问题 https://blog.csdn.net/bwlab/article/details/46953569 https://zhuanlan.zhihu.com/p/376328486 我的VMware是16.2, 没有 C:\\ProgramData\\VMware\\hostd, 也没有共享虚拟机 一种暂时的解决措施是配置网络代理,然后配置主机的network代理http映射到20171,走代理 这个问题暂时搁置, 等以后学明白了再回来解决 参考 windows宿主机如何SSH连接VMware的Linux虚拟机","categories":[],"tags":[{"name":"环境配置","slug":"环境配置","permalink":"https://luzhixing12345.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"}]},{"title":"SSH","slug":"服务器/SSH","date":"2023-02-28T03:13:39.000Z","updated":"2023-03-06T08:21:46.671Z","comments":true,"path":"2023/02/28/服务器/SSH/","link":"","permalink":"https://luzhixing12345.github.io/2023/02/28/%E6%9C%8D%E5%8A%A1%E5%99%A8/SSH/","excerpt":"","text":"关于git + github 的SSH连接在git ssh中记录了,这里不再赘述 服务器免密SSH 实际开发之中我倾向于使用Vscode远程开发,不得不说Vscode的SSH服务实在是香,很方便,Vscode界面还好看,有插件,真棒 生成 rsa公钥私钥 ssh-keygen -t rsa -C &quot;luzhixing12345@163.com&quot; 如果已经生成过一个rsa密钥了,那么换一个名字比如 id_rsa_server 在本地主机处将id_rsa.pub传入服务器,传入/root/目录下 scp ~/.ssh/id_rsa.pub root@IP:/root 登录远程主机,加入信任列表 ssh root@IP cat /root/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys 在进行本机ssh登录的时候就要求验证,选择yes认证之后就可以免密登录了 ssh root@IP 延长SSH连接时间 vim ~/.ssh/config Host * ServerAliveInterval 60 ServerAliveInterval含义 域名替换 sudo vim /etc/hosts # Windows C:\\Windows\\System32\\drivers\\etc\\hosts 补充一条 IP 域名 即可","categories":[],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://luzhixing12345.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]},{"title":"cache","slug":"体系结构/cache","date":"2022-12-28T12:18:43.000Z","updated":"2023-04-23T06:57:44.987Z","comments":true,"path":"2022/12/28/体系结构/cache/","link":"","permalink":"https://luzhixing12345.github.io/2022/12/28/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/cache/","excerpt":"","text":"局部性 一个编写良好的计算机程序常常具有良好的局部性.他们抢相遇引用林进屿其他最近引用过的数据项的数据项,或者引用最近引用过的数据项本身.这种倾向性被称为局部性原理,是一个持久的概念,对硬件和软件系统的设计和性能都用这极大的影响 局部性通常有两种不同的形式,时间局部性和空间局部性 时间局部性:被引用过一次的内存位置很可能在将来不久的位置再被多次引用 空间局部性:如果一个内存位置被引用了一次,那么程序很可能在不远的将来引用附近的一个内存位置 一个非常好的例子就是对于一个二维数组a[i][j]在两重for循环使用的i,j的顺序 缓存的概念 众所周知,不同存储技术的访问时间差异很大,速度较快的技术每字节成本要比速度较慢的技术高,而且容量小.CPU和主存之间的速度差距在增大 上图是一个经典的计算机存储器结构层次,高层向底层走存储设备变得更慢,更便宜和更大. 早期计算机系统的存储器层次只有三层,CPU寄存器,DRAM主存储器,磁盘存储.由于CPU和主存之间的频率逐渐增大,系统设计者被迫在CPU寄存器文件和主存之间插入了一个小的SRAM高速缓存,被称为L1高速缓存(一级缓存),如下图所示.L1高速缓存的访问速度几乎和寄存器一样快,典型的是4个时钟周期. 但随着CPU和贮存之间的性能差距在不断增大,系统设计者又在L1和DRAM之间加入了一个更大的高速缓存,被称为L2高速缓存,大约在10个周期内可以访问到.有些现代系统还包括一个更大的L3高速缓存. 一般而言,高速缓存(cache)是一个小而快速的存储设备,它的设计思想是:位于k层的更快更小的存储设备作为位于k+1层的更大更慢的存储设备的缓存.换句话说就是层次结构中的每一层缓存都来自较低一层的数据对象. 每层的存储器被划分为连续的数据对象组块,被称为块.每个块都有唯一的地址或名字,区别于其他的块.数据总是以块大小为传送单元在k层和k+1层之间来回复制. 缓存命中 当程序需要k+1层的某个数据对象d时,他首先在当前存储在k层的块中查找d,如果d刚好缓存在k层中,那么就是缓存命中.该程序直接从k层中读取d,根据存储器层次结构的性质,这样比从k+1层读取d更快. 缓存不命中 如果k层中没有缓存数据对象d,那么称为缓存不命中.此时k层缓存从k+1层缓存中取出包含d的那个块,如果k层缓存已满那么就会选择覆盖现存的一个块 只要发生了不命中,k层的缓存就必须执行某个放置策略,确定把它从k+1层中取出的块放在那里,最灵活的放置策略时随机放置块,这种方式速度虽然最优但是定位起来代价很高.因此硬件缓存通常使用更为严格的放置策略,举一个例子 k+1层的块i必须防止在k层的块(i mod 4)中,例如k+1层的0,4,8映射到k层的0. 1,5,9映射到1,以此类推. 但是这种策略会引起另一种不命中:冲突不命中,在这种情况下缓存足够但能够保存被引用的数据对象,但是因为这些对象都会映射到同一个缓存块中,缓存会一直不命中.所以我们可能需要采用一些更为高级的替换策略,例如LRU. 缓存组织结构 一般而言,高速缓存的结构可以用元组(S,E,B,m)来描述 此处的S指一共有S个高速缓存组,每组E行,每一行中有效的缓存块大小为B,m为主存物理地址长度. 其中每一行缓存块大小为B,占b位(B=2^b),每行还有1位有效位用于表示这个行是否包含有意义的信息,还有t位标记位. t = m - (b+s),m为地址总长度,2^s=S 这里的定义表述稍显混乱,我这里重新组织一下语言.首先高速缓存一共S组,一共需要s位(2^s=S)来表示每一组.其次每一组有E行,每一行是一个高速缓存行.其中每一行有1位有效位,t位标记位,和B字节的缓存块大小.这里的t是计算出来的,因为计算机的地址长度m是确定的(一般32或者64),B字节大小的缓存块需要b位的偏移量来表示(2^b=B),注意这里缓存块的单位是字节,组索引占用s位,所以t=m-(b+s) 高速缓存的大小(容量)C是指所有块的大小的和,其中标记位和有效位不包括在内,因为C=S×E×BC=S\\times E\\times BC=S×E×B 根据每个组的高速缓存行数E,高速缓存可以被分为不同的类 直接映射高速缓存 每个组只有一行(E=1)的高速缓存被称为直接映射高速缓存,这种情况是最容易实现和理解的 现在一条加载指令指示CPU从主存地址A中读取一个字,那么此时高速缓存如何判断此时缓存中是否保存着A地址处那个字的副本呢?这个过程被分为三个部分 组选择 给定地址A,我们可以根据之前计算的t,s,b的数据截取其中s的部分,这是组索引,我们将高速缓存看成是一个关于组的移位数据,那么这些组索引位就是一个到这个数组的索引,例如下图中映射到组1 行匹配 上一步中已经选择了某个组i,接下来就是确定这一组中是否存在A地址所在的缓存块,在直接映射高速缓存中这很容易因为只有一行. 首先判断有效位必须为1,如果没有设置有效位那么这个缓存块是没有意义的.接着截取A地址中的标记t,与缓存块中的标记t判断,如果相同则说明缓存命中.否则缓存不命中 字选择 最后一步就是根据b在缓存块B中找到对应的位置,这里的b就是块偏移,如上图所示 我们这里假设有如下的一个高速缓存,(S,E,B,m)=(4,1,2,4),换句话说高速缓存有4个组(S),s=2,每个组一行(E=1),每个块两个字节(b=1),地址4位(m=4).因此我们可以列出如下的表格 这里4位地址所以一共有16个字节单元,t=4-2-1=1,所以标记位1位,索引位2位,偏移量1位.4位的地址被划分成了三份用于后续的匹配.最右侧的块号(Block number)是指去除偏移量的1位,将标记位和索引位连接起来计算得到的结果,一共是3位0-7.这里的每个块包含了两个单元(也可以说因为偏移量是1位,所以是两个单元,看从哪个角度解释). 这里的索引位(Index Bits)就是这个单元会被替换到缓存中保存的位置,一共2位(0-3) 所以对于当前的缓存状态,初始为空.这里的后面块0块1是因为B=2字节,所以每一个缓存行可以保存两个单元的数据 读地址0,地址0对应的索引位为00,所以去缓存中寻找第0组的位置,发现有效位为0,缓存不命中 地址0所在的块号为0,所以将块号0的两个块,0和1单元都存入缓存组0,标记位置为0 读地址1,地址1对应的索引位为00,缓存中0组有效位为1,并且地址1的标记位为1,缓存行的标记位也为1,所以缓存命中! 然后地址1的偏移量为1,所以找到缓存块中的块1即可 读地址13,13对应的索引位为10,缓存组2有效位为0所以缓存不命中,将地址13对应的块6存入缓存组2中,并设置标记位 读地址8,8对应的索引位00,缓存组0有效位为1,但标记位为0与地址8的标记位1不同,所以缓存不命中并且需要替换缓存块中的数据 再次读地址0,标记位再次不匹配,替换 这就是冲突不命中的一个例子,有足够的缓存空间但是交替的引用映射到同一个缓存块 组相联高速缓存 直接映射高速缓存冲突不命中造成的问题源于每个组只有一行,组相联高速缓存中每个组有多行 组选择和字选择阶段都没有变化,唯一的区别就是在行选择的阶段,由于有多行,所以进行有效位和标记位判断的时候需要扫描所有行 全相联高速缓存 与组相联不同的是,全相联中S=1,只有唯一的一个组,此时E=C/B,而组相联中 1&lt;E&lt;C/B1&lt;E&lt;C/B1&lt;E&lt;C/B 因为S=1,所以s=0,所以地址被划分为标记位和偏移量 其他选择方式与组相联完全相同,甚至砍掉了第一步的组选择,也是要搜索所有行 因为高速缓存电路必须并行的所有所有行,匹配所有标记位,所以构造一个又大又快的相联高速缓存困难且昂贵,因此全相联高速缓存指适合做小的高速缓存,例如虚拟内存中的快表TLB 高速缓存的写 高速缓存的读比较容易,但是写的情况就要复杂很多了. 假设我们要写一个已经缓存了的字(写命中,write hit),在告诉缓存更新它的副本w之后应该如何更新w在层次结构中低一层的副本呢? 最简单的办法称为直写(write-through),就是立即将w的高速缓存块写回到低一层中,但是缺点是每次协会都会引起总线流量. 另一种办法称为写回(write back),尽可能地推迟更新,只有当替换算法要驱逐这个更新过的块时才把它写回到低一层中.由于局部性,写回能显著的减少总线流量,但是它的缺点是增加了复杂性,高速缓存必须为每个高速缓冲行维护一个额外的修改位(dirty bit)表明这个高速缓冲块是否被修改过 另一个问题就是如何处理写不命中,一种方法称为写分配(write allocate),加载相应的低一层的块到高速缓冲,然后更新这个高速缓冲块.但是缺点是每次不命中都会导致一个块从低一层传送到高速缓冲. 另一种方法称为非写分配(not write allocate),避开高速缓冲,直接把这个字写到低一层中 为写操作优化高速缓存是一个细致且困难的问题,这里不再展开 真实的高速缓存层次解析 目前我们一直假设高速缓存中只保存程序数据,但事实上高速缓存除了保存数据也保存指令.保存指令的高速缓存称为i-cache,保存程序数据的高速缓存称为d-cache,既保存指令又保存数据的高速缓存称为统一的高速缓存 现代处理器包括独立的i-cache和d-cache,这样做有很多原因,有两个独立的高速缓存,处理器可以同时读一个指令字和一个数据字.i-cache通常是只读的,因此比较简单,并且可以针对不同的访问模式优化这两个高速缓存,可以有不同的块大小,相联度和容量 下图是Intel Core i7处理器的高速缓存层次,每个CPU芯片有四个核,每个核有自己私有的L1 i-cache L1 d-cache和L2统一高速缓存,所有核共享L3统一高速缓存,这里的一个有趣的特性是所有的SRAM高速缓存都在CPU芯片上","categories":[],"tags":[{"name":"体系结构","slug":"体系结构","permalink":"https://luzhixing12345.github.io/tags/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"}]},{"title":"NVM","slug":"体系结构/NVM","date":"2022-12-24T12:10:20.000Z","updated":"2023-04-23T06:57:52.557Z","comments":true,"path":"2022/12/24/体系结构/NVM/","link":"","permalink":"https://luzhixing12345.github.io/2022/12/24/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/NVM/","excerpt":"","text":"非易失性存储器(nonvolatile memory, NVM) 非易失性存储器(NVMe)是一种半导体技术,不需要持续供电来保留存储在计算设备中的数据或程序代码 系统制造商出于各种目的使用不同类型的非易失性存储芯片。例如，一种类型的NVM可能存储诸如硬盘驱动器(HDD)和磁带驱动器等设备的控制器程序代码。另一种类型的NVM通常用于固态驱动器(SSD)、USB驱动器和数码相机、手机和其他设备中的存储卡中的数据存储 如果断电,DRAM SRAM都会丢失他们的数据,在这个意义上它们是易失的.另一方面,非易失性存储器即使是在断电之后仍然保存着他们的信息. 虽然ROM中有些类型既可以读也可以写,但是他们整体上都被称为只读存储器(Read Only Memory,ROM). ROM 是以他们能够被重编程的次数和对他们进行重编程所用的机制来进行区分的 PROM(Programmable ROM, 可编程ROM)只能被编程一次. 可擦写可编程ROM(Erassable Programmable ROM,EPROM)有一个透明的石英窗口,允许光到达存储单元.紫外线光照射过窗口,EPROM单元就被清除为0,对EPROM变成是通过使用一种把1写入EPROM的特殊设备来完成的.RPROM能够被擦除和重编程的次数和数量级可以达到1000次. 电子可擦除PROM(Electrically Erassable PROM,EEPROM)类似EPROM,但是它不需要一个物理上独立的编程设备,因此可以直接印制电路卡上编程,可编程次数道道10^5次 闪存(Flash memory)是一类非易失性存储器,基于EEPROM,它已经成为了一种重要的存储技术 闪存无处不在,为大量的电子设备提供快速而持久的非易失性存储,包括数码相机,手机,音乐播放器,笔记本和台式机和服务器等计算机系统 其中一种新兴的基于闪存的磁盘驱动器,成为固态硬盘(Solid State Disk,SSD)能提供相对于传统旋转磁盘的一种更快速更强健更低能耗的选择 存储在ROM设备中的程序通常被称为 固件(firmware). 当一个计算机系统通电以后,他会运行存储在ROM中的固件,一些系统在固件中提供了少量的基本输入输出函数.例如PC的BIOS.复杂的设备,像图形卡和磁盘驱动控制器,也以来固件来翻译来自CPU的IO请求 非易失性存储器和易失性存储器的区别 企业和客户端计算机系统通常结合使用易失性和非易失性内存技术，每种内存类型都有其优点和缺点 例如，SRAM比DRAM快，非常适合高速缓存。DRAM是SRAM的后继者，与主动模式下的SRAM相比，其生产成本更低且所需的功率更低。DRAM的一个常见用例是存储计算机处理器运行所需的主要程序代码(内存) 非易失性NAND闪存在写入和读取数据方面比DRAM和SRAM慢。然而，NAND闪存的生产成本远低于DRAM和SRAM，这使得该技术更适合企业系统和消费设备中的持久数据存储。 非易失性存储器和非易失性存储器表达(NVMe)听起来相似，但它们的含义不同且不同。 NVM是一种出现于1940年代后期的半导体技术 NVMe是一种主机控制器接口和存储协议，由技术供应商联盟于2009年开始开发 NVM主机控制器接口工作组于2011年3月1日发布了1.0NVMe规范。NVMe旨在通过计算机的PCIe总线加速主机系统和SSD之间的数据传输。NVMe支持使用不同类型的非易失性存储器，例如NAND闪存和英特尔和美光开发的3DXPoint技术。NVMe是分别用于SAS和SATA驱动器的小型计算机系统接口(SCSI)标准和高级技术附件(ATA)标准的替代方案。 NVMe使用的CPU指令数量少于SCSI和ATA命令集的一半 与基于SAS和SATA的SSD相比，基于NVMe的PCIeSSD具有更低的延迟、更高的IOPS和更低的功耗 DIMM 首先讲到内存，许多用户都知道DDR3，DDR4这些但是对于DIMM和SDRAM却不太了解 DIMM（Dual Inline Memory Module，双列直插内存模块），是在单列直插存储器模块(single inline memory module,SIMM)的基础上发展起来的，SIMM提供32位数据通道，而DIMM则提供了64位的数据通道 SDRAM:Synchronous Dynamic Random Access Memory，同步动态随机存储器。 DDR（Double Data Rate）系列，严格意义上讲，应该是Double Data Rate SDRAM内存，也就是和说在SDRAM基础上改进的版本，只不过日常生活中，通常被简略的直接称作DDR内存 而无论是SDRAM还是DDR，实际上都是DIMM内存. DIMM是指针脚插槽，也就是物理结构方面的分类；而SDRAM和DDR都是内部技术方面的分类 新型非易失性存储器 非易失性存储器的例子包括只读存储器(ROM)、闪存、大多数类型的磁性计算机存储设备(例如硬盘、软盘和磁带)、光盘和早期的计算机存储方法，如纸带和打孔卡 近些年来，不论在学术界还是工业界，新型非易失存储技术都是关注的重点且取得了一定的突破。新型非易失存储由于性能相比闪存提升巨大，达到了接近DRAM的水平，一般在学术界被称为Non Volatile Main Memory (NVMM) NVMM是对于多种新型非易失存储介质的统称,目前NVMM包括 相变存储器(Phase-Change Memory, PCM) 通过硫系化合物非晶和多晶之间的快速相变来实现信息存储 忆阻器 Memristor(ReRAM） 基于一种特殊的二氧化钛材料实现纳米级忆阻器实现数据存储 自旋扭矩转换随机存储器 (Spin Transfer Torque - Magnetic Random Access Memory,STT-MRAM) 物理机制是磁致阻变效应 以上新型非易失存储介质所用材料虽然各有不同，但都有着低延迟、高密度、可字节寻址等优异特性。相比基于浮栅晶体管的NAND Flash确实可称得上是革命性创新 NAND Flash可以做成不同接口和不同形式的闪存设备：SATA接口一般用于普通固态硬盘（SSD）产品、PCIe接口则常用于高端服务器闪存产品。NVMM由于可以媲美DRAM的性能，可以做成类似内存条形式直接插在主板的DIMM插槽上。这类产品可以称为持久化内存，Persistent Memory (PM)，或存储级内存，Storage Class Memory (SCM)。PM和SCM基本是相同的含义，个人理解的细微差别是应用场景的区别——PM没有明确指向性，SCM则是倾向于处在存储层次中DRAM和闪存之间。 NVDIMM 与DIMM类似,是基于NAND Flash的非易失型内存条. 通常被做成“电池+NAND Flash+DRAM”的形式：在掉电时用电池电量将DRAM数据刷回NAND Flash实现持久化 新型非易失存储的定位 近两年，英特尔推出了目前唯一的NVMM商用产品——基于3D Xpoint (Cross Point)技术的Optane Memory设备，又称Apache Pass，也可简称为AEP 业界在新型非易失存储上搞的热火朝天，性能到底如何呢？目前Optane Memory的读延迟大约是350 ns，这是一个比较让人“亦可赛艇”的数值了。要知道DRAM的读延迟大约是100 ns，至少已经看到了DRAM的尾灯（在一个数量级上）。参考下图中的存储层次体系，3D Xpoint确实已经一只脚迈进了主存的区间，甩了闪存一大截 存储器件的定位和用途一般要考虑延迟、寿命、成本、容量、可持久化等多方面的因素，主存（Memory）和辅存（Storage）之间有很大的特性差别： 主存要求极低延迟、字节寻址 辅存要求大容量、持久化 主存和辅存是上下层级关系，而新型非易失存储的出现让我们看到了同时满足低时延、字节寻址、持久化、大容量的理想存储形态","categories":[],"tags":[{"name":"体系结构","slug":"体系结构","permalink":"https://luzhixing12345.github.io/tags/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"}]},{"title":"DRAM","slug":"体系结构/DRAM","date":"2022-12-23T12:48:28.000Z","updated":"2023-04-23T06:57:48.476Z","comments":true,"path":"2022/12/23/体系结构/DRAM/","link":"","permalink":"https://luzhixing12345.github.io/2022/12/23/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/DRAM/","excerpt":"","text":"文章开始之前先推荐一个B站的3D科普视频【计算机是如何工作的？探索主内存，以DDR5为例】 https://www.bilibili.com/video/BV1vP411c7pt/?share_source=copy_web&amp;vd_source=33e283fd587efff3f4345e881f063588 随机访问存储器 随机访问存储器(Random Access Memory, RAM)分为两类,静态和动态的.静态RAM(SRAM)比动态RAM(DRAM)更快,也贵得多.SRAM用来作为高速缓冲存储器,既可以在CPU芯片上,也可以在片外.DRAM用来作为贮存一级图形系统的帧缓冲区. 静态RAM SRAM将每个为存储在一个双稳态的存储器单元,每一个单元使用一个六晶体管电路来实现的,这个电路有这样一个属性,它可以无限期的保持在两个不同的电压配置或者状态之一.其他任何状态都是不稳定的. 从不稳定的状态开始,电路会迅速的转移到两个稳定的状态中的一个. 由于SRAM存储器单元的双稳态特性,只要有电就会保持它的值,即使有干扰来扰乱电压,当干扰消除时电路就会恢复到稳定的值. 动态RAM DRAM将每个为存储为一个对电容的充电,这个电容非常小,通常只有大约30x10^-15F. DRAM存储器可以制造的非常密集,每个电源有一个电容和一个访问晶体管组成,但是与SRAM不同,DRAM存储器单元对干扰非常敏感,当电容的的电压被扰乱之后,它基本就永远不会恢复了.暴露在光线下会导致电容电压的改变. 实际上数码照相机和摄影机中的传感器本质就是DRAM单元的阵列 很多原因会导致漏电,值得DRAM单元在10-100毫秒时间内失去电荷,幸运的是计算机运行的时钟周期都是纳秒来衡量的.所以相对而言这个保持时间是比较长的,内存系统必须周期性的通过读出,然后重写来刷新内存的每一位.有些系统也是用纠错码,其中计算机的字会被多编码几个位.这样电路可以发现并且纠正一个字中任何单个的错误位. 下图总结了SRAM和DRAM存储器的特性,只要有点,SRAM就会保持不变,与DRAM不同SRAM不需要刷新.SRAM的存取更快,对光电噪声干扰不敏感.带解释SRAM单元比DRAM单元使用更多的晶体管,因为密集度低,更贵,功耗更大 传统DRAM DRAM芯片中的单元被分为d个超单元(supercell),每一个超单元都有w个DRAM单元组成,一个d x w 的DRAM总共存储了dw位信息,超单元被组织成一个r行c列的长方形阵列,之类的rc=d 上图是一个16x8的DRAM芯片的组织,一共有d=16个超单元,每一个超单元有w=8位 被组织成r=4,c=4的格式. 图中给出了两组引脚,8个data引脚,可以传送一个字节到芯片或者从芯片传出一个字节. 以及两个addr引脚,他们携带两位的行列超单元地址,可以找到相应的超单元 存储领域从来没有为DRAM的阵列元素确定一个标准的名字,计算机架构师倾向于称之为单元.使这个术语具有DRAM存储单元之意.单路设计师倾向于称之为字,使之具有主存一个字之意.这里使用 超单元 为了避免歧义 每个DRAM芯片被连接到一个称为内存控制器的电路,这个电路可以依次传送w位到每个DRAM芯片,或者依次从每个DRAM芯片传出w位.为了读出超单元(i,j)的内容,内存控制器将行地址i发送到DRAM,然后是列地址j. DRAM把超单元(i,j)的内容发挥控制器作为响应. 行地址i称为RAS(Row Access Strobe,行访问选通脉冲)请求. 列地址j称为CAS(Column Access Strobe,列访问选通脉冲)请求. 注意RAS和CAS请求共享相同的DRAM地址引脚 例如,要从上图中的16x8的DRAM中读出超单元(2,1),内存控制器发送行地址2,DRAM的响应是将行2的 整个内容 都复制到一个内部行缓冲区,接下来内存控制器发送列地址1,DRAM的响应是从行缓冲区复制出超单元(2,1)中的8位,并把它们发送到内存控制器中 电路设计设将DRAM组织成二维阵列而不是线性数组的一个原因是降低芯片上的地址引脚数量例如128位DRAM被组织成一个16个超单元的线性数组,地址为0-15,那么芯片会需要四个地址引脚而不是两个,二维阵列组织的确定是必须分成两步发送地址,这增加了访问时间 内存模块 DRAM芯片封装在内存模块,它插到主板的扩展槽上 上图展示了一个内存模块的基本思想,示例模块用了8个8MX9的DRAM芯片,总共存储64MB. 这8个芯片编号分别为0-7,每一个超单元存储主存的一个字节,而用相应的超单元地址为(i,j)的8个超单元来表示主存中的地址A处的64位字. 注意这里的64位字是通过8个DRAM芯片分别存储8个8位字来实现的 要去除内存地址A处的一个字,内存控制器将A转换成一个超单元地址(i,j), 并将它发送到内存模块,燃火内存模块再将i,j广播到每个DRAM,每个DRAM输出他的(i,j)超单元的8位内容,模块中的电路收集这些输出并把它们合并成一个64字,再返回给内存控制器. 增强的DRAM 有许多种DRAM存储器,而生产厂商为了跟上迅速增长的处理器速度,市场上就会定期推出新的种类.每种都是基于传统DRAM单元进行一些优化,提高访问基本DRAM单元的速度 快页模式DRAM(Fast Page Mode DRAM, FPM DRAM) 传统DRAM将超单元的一行复制到它的内部行缓冲区,使用一个然后丢弃剩余的 FPM DRAM允许对同一行连续的访问,可以直接从行缓冲中的得到服务.例如要从一个传统DRAM的行i连续读取四个超单元,内存控制器必须发送四个RAS/CAS请求,即使行地址i在每个情况都是一样的. 而要从一个FPM DRAM的同一行中读取超单元,内从控制器发送第一个RAS/CAS请求,后面跟三个CAS请求,出事的RAS/CAS请求将行i复制到行缓冲区,并返回CAS那个超单元,后面的三个超单元可以直接在行缓冲区中获得,因此返回的更快 扩展数据输出DRAM(Extended Data Out DRAM, EDO DRAM) FPM DRAM的一个增强的形式,它允许各个CAS信号在时间上靠的更近一些 同步DRAM (Synchronous DRAM, SDRAM) 在与内存控制器通信时使用的一组显式控制信号来说,传统DRAM FPM和EDO DRAM都是异步的. SDRAM用与驱动内存控制器相同的外部时钟信号的上升沿来代替许多这样的控制信号 双倍数据速率同步DRAM(Double Data-Rate Synchronouse DRAM, DDR SDRAM) DDR SDRAM是对于SDRAM的一种增强,使用两个时钟沿作为控制信号使得DRAM的速度翻倍 不同类型的DDR SDRAM是用预取缓冲区的大小来划分的, DDR2 3 4 5 视频RAM(Video RAM, VRAM) 它用在图形系统的帧缓冲区中,VRAM的思想和FPM DRAM类似,两个主要区别是 VRAM的输出是通过依次对内部缓冲区的整个内容进行移位得到的 VRAM允许对内存并行的读写,因此系统可以在新值写入的同时用帧缓冲区中的相似刷新屏幕(读) 访问主存 数据流通过称为总线的共享电子电路在处理器和DRAM主存之间传送.每次CPU和主存之间的数据传送都是通过一系列步骤完成的,这些步骤称为总线事务. 读事务:从主存传送数据到CPU 写事务:从CPU传送数据到主存 总线是一组并行的导线,可以携带地址,数据和控制信号,取决于总线的设计,数据和地址信号可以共享同一组导线,也可以使用不同的.**同时两个以上的设备也能共享同一总线.**控制线携带的信号会同步事务,并标示出当前正在被执行的事务的类型.例如当前关注的这个事务是到主存的么?还是到诸如磁盘控制器这样的其他IO设备的.是读还是写,总线上的信息是地址还是数据项 上图展示了一个示例计算机系统的配置,主要部件是CPU芯片,被称为IO桥接器的芯片组(包括内存控制器),以及组成主存的DRAM内存模块.这些部件由一对总线连接起来,其中一条总线是系统总线,他连接CPU和IO桥接器. 另一条总线是内存总线,他链接IO桥接器和主存,IO桥接器将系统总线和电子信号翻译成内存总线和电子信号. IO桥也将系统总线和内存总线连接到IO总线,像磁盘和图形卡这样的IO设备共享IO总线 总线设计是计算机系统一个复杂而且变化迅速的方面,不同的厂商提出了不同的总线体系结构作为产片差异化的一种方法.例如Intel系统使用北桥和南桥的芯片组分别将CPU连接到内存和IO设备关于主板的南桥芯片推荐一个B站科普视频:【硬件科普】电脑主板右下角的散热片下面究竟隐藏着什么？详解主板南桥芯片组的功能和作用】 https://www.bilibili.com/video/BV1cJ411K7HW/?share_source=copy_web&amp;vd_source=33e283fd587efff3f4345e881f063588这些不同的总线体系结构的细节超出了存储器结构层次的返回,我们将使用上图中的高级总线体系结构作为一个运行示例贯穿时钟,这是一个简单但是有用的抽象,使得我们可以很具体,并且可以掌握主要思想而不必与任何私有设计的细节绑得太紧 考虑当CPU执行如下一个加载操作时会发生什么? movq A, %rax 这里地址A的内容被加载到寄存器%rax中 CPU芯片上称为总线接口的电路在总线发起读事务.读事务由三个步骤组成 首先CPU将地址A放到系统总线上,IO桥将信号传递到内存总线 接下来主存感知到内存总线上的地址信号,内存总线读地址,从DRAM取出数据字,并将数据写到内存总线,IO桥将内存总线信号翻译成系统总线信号,然后然后沿着系统总线传递 最后CPU感知到系统总线上的数据,从总线上读数据,并将数据复制到寄存器%rax 连接IO设备 例如图形卡,显示器,鼠标键盘,磁盘等IO设备都是通过IO总线连接到CPU和主存的.例如Intel的PCI(Peripheral Component Interconnect)总线 下图展示了一个典型的IO总线结构,虽然IO总线比系统总线和内存总线慢,但是他可以容纳种类繁多的第三方IO设备 通用串行总线USB(Universal Serial Bus),USB总线是一个广泛使用的标准,连接各种外围设备,USB3.0总线最大带宽是625MB/s 图形卡 主机总线适配器:将一个或多个磁盘连接到IO总线,使用的是一个特别的主机总线接口定义的通信协议,两个最常用的磁盘接口是SCSI和SATA SCSI磁盘通常比SATA驱动器更快但是更贵,除此之外还有一种相对新的NVMe,目前市面上最常见的SSD产品，几乎都是SATA的，主流产品的读写通常都在550MB/s，而NVMe可以轻松打破这一限制，NVMe固态硬盘价格会比SATA固态贵一些 其他:例如网络适配器,可以通过适配器查到主板上空的扩展槽中连接到IO总线,这些插槽提供了到总线的直接电路连接 上图的IO总线是一个简单的抽象,在现代系统中共享的PCI总线已经被PCIe(PCI express)总线取代,PCIe是一组高速串行,通过开关连接的点到点链路.PCIe总线最大吞吐量可到16GB/s,比PCI总下快一个数量级(PCI总线的最大吞吐量533MB/s) 访问磁盘 CPU使用一种称为内存映射的技术向IO设备发射命令,在使用内存映射的IO系统中,地址空间中有一块地址是为IO设备通信保留的,每个这样的地址称为一个IO端口,当一个设备连接到总线之后,它与一个或者多个端口相关联(或者它被映射到一个或多个端口) 来看一个简单的例子: 假设磁盘控制器映射到端口0xa0,随后CPU可能通过执行三个对地址0Xa0的存储指令来发起磁盘读.第一条指令是发送一个命令字以及其他参数,告诉磁盘发起一个读,第二条指令指明应该读的逻辑块号,第三条指令指明应该存储磁盘扇区内容的主存地址 当CPU发送请求之后,在磁盘执行读的时候他通常会做一些其他的工作.因为一个1GHz的处理器时钟周期是1ns,再用来读磁盘的16ms的时间里他潜在的可能执行1600万条指令,如果在传输进行的时候只是简单的等待什么也不做则是一种极大的浪费! 磁盘控制器收到来自CPU的读命令之后将逻辑块号翻译成一个扇区地址,读该扇区的内容,然后将这些内容直接传送到主存,不需要CPU干涉.设备可以自己执行读或者写总线事务而不需要CPU干涉的过程称为直接内容访问DMA(Direct Memory Access),这种数据传送称为DMA传送 在DMA传送完成之后,磁盘扇区的内容被安全的存储在主存以后,磁盘控制器通过向CPU发送一个中断信号来通知CPU,这个中断信号会发送到CPU芯片的一个外部引脚,导致CPU暂停它当前的工作跳转到一个操作系统例程,这个程序会记录下IO已经完成,然后将控制返回到CPU被中断的地方","categories":[],"tags":[{"name":"体系结构","slug":"体系结构","permalink":"https://luzhixing12345.github.io/tags/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"}]},{"title":"RDMA简介","slug":"体系结构/RDMA简介","date":"2022-12-02T08:30:57.000Z","updated":"2023-04-23T06:57:55.114Z","comments":true,"path":"2022/12/02/体系结构/RDMA简介/","link":"","permalink":"https://luzhixing12345.github.io/2022/12/02/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/RDMA%E7%AE%80%E4%BB%8B/","excerpt":"","text":"RDMA简介 参考 https://zhuanlan.zhihu.com/p/55142557 参考 https://www.bilibili.com/video/BV1Aq4y1C7Fh DMA和RDMA概念 DMA(直接内存访问)是一种能力，允许在计算机主板上的设备直接把数据发送到内存中去，数据搬运不需要CPU的参与 传统内存访问需要通过CPU进行数据copy来移动数据，通过CPU将内存中的Buffer1移动到Buffer2中。DMA模式：可以同DMA Engine之间通过硬件将数据从Buffer1移动到Buffer2,而不需要操作系统CPU的参与，大大降低了CPU Copy的开销 RMDA RDMA是一种概念，在两个或者多个计算机进行通讯的时候使用DMA， 从一个主机的内存直接访问另一个主机的内存 数据发生多次拷贝,中间的处理过程都需要CPU参与,如果不绕过操作系统内核对于CPU来说就是持续的开销 RDMA是一种host-offload, host-bypass技术，允许应用程序(包括存储)在它们的内存空间之间直接做数据传输。具有RDMA引擎的以太网卡(RNIC)–而不是host–负责管理源和目标之间的可靠连接。使用RNIC的应用程序之间使用专注的QP和CQ进行通讯 RDMA 直接绕过内核,让数据在应用层传递到网络接口.可以将数据从应用层直接 INFINIBAND TRADE ASSOCIATION (IBTA) 制定IB标准, openfabrics 开发IB 软件 硬件和软件配合为应用提供加速服务 Host Channel Adapter(HCA) 主机通道适配器,这里的通道指的是网络中的两个主机节点借助HCA IB网卡来建立主机通道,提供传输服务 SDN网络,不需要广播,网络扩展性非常好 子网管理器SDN控制器提供管理服务 48000 ioid 低延迟 高带宽 传输卸载,这里的卸载指的是从一个主机发送数据到另外一个主机,在传输的控制部分不需要CPU去执行控制协议栈,所有的控制传输服务都是由HCA配合交换网络完成的 infiniband 最大特点是它是一个SDN(software define networking 软件定义网络) 子网管理器构成了软件定义网络的控制面,控制面发送子网的所有配置到各个交换机到各个端口. 在设备上电之后,子网管理器会给所有的给所有的端口分配二层地址,之后的通信都是由二层地址在子网端口之间进行通信. 因为子网管理器在SDN中具有全局的视角,所以它可以轻易的进行一个子网的路由计算,计算两点之间的路由,并且把对应的路由表下发到对应的交换机 所有的路由寻址都是由SDN来控制的,这样使得网络的路由拓扑收敛性特别好,任何一个交换机,任何一个路由或者交换机离线或者上线,就会进行一次路由表的更新,可扩展性和易维护性很好 Infiniband使用的是基于信用的二层流控(credit based link layer flow control) 当一跳的交换机端口要往下一跳的端口发送数据之前,它会首先查询下一条是否存在buffer来接收数据,如果有才会传输 他会先在控制链路上和下一跳进行沟通,否则如果没有buffer也发就会造成丢包,造成性能的损失 相比于尽力而为,量力而行,只要物理层是可靠的,二层之上可以实现无损网络 在无损网络之上,我们就可以利用infiniband获得很好的传输服务 如果一个应用想要从另外一个节点的伙伴应用获取数据,IB可以通过HCA管理QP在两个节点之间建立虚拟通道,可以使发起应用的数据获取到想要得到的数据,否则就需要调用OS的传输协议栈,经过多次的传输拷贝才能从网络发送过来,infiniband提供了更好的传输服务 传输层需要提供的一个服务是把一段发送的message进行切分,假如发送2G的数据,传输层会由HCA将数据切分成package(mtu 最大传输单元 4k),发送到对面再由对面的HCA组装package成message写入到应用中去,整个的过程都是由网卡来卸载的,不需要CPU去做消息切分,发送,整合,复制 QP(queue pair)可以建立不同模式的队列对,面向连接的,不面向连接的 面向连接指的是一个QP会和另外一个节点的QP组成关联,读写是一对一的 datagram不面向连接都需要指定具体是发送给哪一个QP,建立一对多 可靠的,不可靠的 可靠的发送ACK,保证传输层的可靠/否则NACK发起重传,都不需要CPU干预,实现高质量的传输和直接的内存访问 不可靠,只管发,appication来决定,重传也是application决定重传 这种传输服务使能了RDMA直接访问内存的机制,access而不只是收发 用户数据复制到kernel协议栈,kernel协议栈找到一块可用的网卡,网卡把数据传输到对方,又要用CPU,复制到协议栈,耗时耗费CPU资源 相比于IB,CPU不感知,kernel bypass,最低的延迟 PEER TO PEER COMMUNICATION 应用运行在用户态,每当他需要去和远端的用户通信的时候,他不得不调用另外一个CPU进程,这个进程运行在内核态,他按照网络的协议栈进行处理判断去调用另外一个进程,硬件的driver,这个driver再去进行 占用内存,耗费时间,CPU资源也被分到了内核协议栈这里,使得没有办法完全投入到应用中去 相比之下RDMA CPU资源沉浸在计算,通信的开销由HCA卸载 GPUDIRECT RDMA 数据 -&gt; host memory -&gt; host to device copy 将数据写到GPU memory,host memory 得到写入完成的通知即可,全部完成启动下一阶段的并行计算 MPI MPI是高性能计算常用的实现方式，它的全名叫做 Message Passing Interface 在MPI超级计算中,所有的MPI进程齐头并进的做计算,它计算出来的数据需要发送给伙伴节点,去支持伙伴节点的计算 以及当它自己计算到某些节点的时候,也要得到伙伴节点的数据才可以进行下一步的计算,这种时候就需要MPI运行时提供 tag matching 的服务 这种服务需要分两块buffer管理 软件上需要实现,如果我已经在请求接收远端的某些buffer,那么我需要注册一个tag,如果还没有算到并且数据已经到了那么就临时的放在一个buffer中.目前这种匹配机制可以完全由infinband网卡进行卸载 也就是说网卡接收到一个数据之后,他回去检查该数据是否存在匹配的receive,如果存在则网卡直接将数据送给应用.反之,如果没有发现对应的tag,他会直接放到软件的buffer中去 另外一种高级的卸载是,如果我的伙伴通知数据已经计算完毕并且提供了发送了 Rendezvous 的消息头, 则网卡在接收到该信息之后会根据该消息头直接去远端的伙伴节点读取数据并写入指定应用中,以上过程都不需要CPU参与 例如在 OpenMPI 通信库中,在infiniband的网络之上调用 OpenUCX 进行点对点的RDMA传输,这种传输可以再去控制可靠的,不可靠的,面向连接的,不面向连接,都可以通过不同的UCX配置 tag matching ,GPU RDMA都可以在UCX中配置 在UCX之上有OpenMPI,由OpenMPI去构建点对点的 PML (p2p messageing layer), 再去支持上层的MPI,API","categories":[],"tags":[{"name":"体系结构","slug":"体系结构","permalink":"https://luzhixing12345.github.io/tags/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"}]},{"title":"Ubuntu切换NVIDIA驱动","slug":"环境配置/Ubuntu切换NVIDIA驱动","date":"2022-11-28T11:11:24.000Z","updated":"2023-01-03T04:15:51.192Z","comments":true,"path":"2022/11/28/环境配置/Ubuntu切换NVIDIA驱动/","link":"","permalink":"https://luzhixing12345.github.io/2022/11/28/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/Ubuntu%E5%88%87%E6%8D%A2NVIDIA%E9%A9%B1%E5%8A%A8/","excerpt":"","text":"笔者使用 Ubuntu22.04 出现了卡死的情况,且网上提到的解决办法均不奏效 其他解决办法: https://blog.csdn.net/qq_39779233/article/details/114758689 所以参考文章: https://blog.csdn.net/weixin_38890593/article/details/124795412 决定更换显卡驱动, ubuntu 默认使用nouveau显卡驱动,安装NVIDIA的显卡驱动 下载显卡驱动 首先需要电脑是N卡,可以通过如下命令查看显卡型号,笔者这里是笔记本的3060 lspci |grep -E &quot;VGA|3D&quot; 进入 https://www.nvidia.cn/geforce/drivers/ 根据电脑显卡型号下载对应的驱动安装包,这里笔记本是notebook 下载之后修改文件的权限 chmod +x /path/to/NVIDIA-Linux-*.run 根据文档执行,这里以 Ubuntu 的情况为例,如果是 Debian and Linux Mint 需要根据文档修改 https://www.if-not-true-then-false.com/2021/debian-ubuntu-linux-mint-nvidia-guide/ 进入root用户 如果是vmware的话是不能su的,需要先sudo passwd root改一下密码(可以相同),然后以后就可以了 sudo -i apt update apt upgrade apt autoremove $(dpkg -l xserver-xorg-video-nvidia* |grep ii |awk &#x27;&#123;print $2&#125;&#x27;) apt reinstall xserver-xorg-video-nouveau reboot 重启之后 sudo -i apt install linux-headers-$(uname -r) gcc make acpid dkms libglvnd-core-dev libglvnd0 libglvnd-dev dracut echo &quot;blacklist nouveau&quot; &gt;&gt; /etc/modprobe.d/blacklist.conf 修改grub配置文件 vim /etc/default/grub 修改配置文件 GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet splash rd.driver.blacklist=nouveau&quot; update-grub2 mv /boot/initrd.img-$(uname -r) /boot/initrd.img-$(uname -r)-nouveau dracut -q /boot/initrd.img-$(uname -r) $(uname -r) systemctl set-default multi-user.target reboot 再次重启之后 再次重启之后就失去了开机的图形界面,接下来的操作在命令行中执行 sudo -i cd 进入下载的NVIDIA驱动的目录,浏览器下的话默认在 ~/Download ./NVIDIA-Linux-*.run 然后一路ENTER确认就可以了 这部分时间很短,结束之后重新回到命令行,这里要注意重新回到的命令行很小很小,在屏幕的左下角,你可以按下回车看到 systemctl set-default graphical.target reboot 安装完成","categories":[],"tags":[{"name":"环境配置","slug":"环境配置","permalink":"https://luzhixing12345.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"}]},{"title":"双系统安装","slug":"环境配置/双系统安装","date":"2022-11-15T08:24:28.000Z","updated":"2023-02-28T03:32:54.024Z","comments":true,"path":"2022/11/15/环境配置/双系统安装/","link":"","permalink":"https://luzhixing12345.github.io/2022/11/15/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/%E5%8F%8C%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/","excerpt":"","text":"前言 笔者由于学习原因需要使用Ubuntu系统编译源码,但是服务器使用的系统是Debian,且使用docker编译内存不足.且考虑到后续修改和性能原因不希望使用虚拟机,于是决定安装双系统(Win11+Ubuntu22.04),本文记录一下安装过程 配置双系统 Ubuntu 双系统安装流程 Windows10安装ubuntu22.04双系统教程 0. 开始之前 由于开始安装双系统之后就离开了Windows,所以如果需要对照文档你还需要另一台设备. 由于本博客挂载在 Github 的域名之下,所以请考虑你的另一台设备能否打开这个网址 其次切换系统时 Windows 会进入一个蓝屏白字的状态并且要求进行 BitLocker 恢复密钥以确保系统运行正常 你可以打开如下Microsoft 帐户恢复密钥网址,登录之后就可以查看到你的恢复密钥ID及其对应的恢复密钥了. 建议截图保存,以便后续输入使用 恢复密钥输入时使用的是F1-F10进行输入 以下内容为笔者经验之谈,记录分享. 不过毕竟是涉及到操作系统的切换以及安装,很难保证万无一失,所以如果您的windows系统中真的有及其重要的文件资源请提前备份 1.下载Ubuntu镜像 Ubuntu版本存在多个版本,部分用户偏爱更稳定的老版本,部分用户偏向使用新版本,笔者使用的是当前(2022/11/15)最新的版本Ubuntu22.04,不同版本的安装过程是完全相同的,如果读者更偏好其他版本可以自行选择下载 Ubuntu22.04 Ubuntu20.04 Ubuntu18.04 Ubuntu16.04 2.制作U盘启动盘 首先找到一块U盘,制作启动盘会导致U盘内部数据全部清除,如果内部有重要数据请做好备份. U盘启动盘制作之后可以在还原回到U盘,这一点不必担心 Ubuntu系统大小大约在2-4G,正常市面的U盘容量应该都足够 下载启动盘制作软件 rufus, 软件很小且无需安装,打开之后可以看到如下界面 其中设备选择你的U盘,引导类型选择打开下载的Ubuntu镜像,其他不需要更改,点击开始,确认推荐即可 绿色进度条满之后U盘启动盘就制作好了 3.为Ubuntu的安装腾出磁盘空间 右键我的电脑,选择 管理,找到磁盘管理,可以看到你的磁盘状况 如图为笔者的磁盘状态,其中红色框中的区域为已经安装好的Ubuntu系统的磁盘区域 双系统需要占据一定大小的磁盘空间,你的电脑可能是一整块C盘也可能是已经分区好了,这个没有影响.选择一块较为空闲的磁盘(比如D盘),划分一块空间 这个空间的大小不宜过小,至少也要在40GB以上吧,因为后续的软件安装以及其他库下载都需要占据这一块磁盘. 右键磁盘,压缩卷,根据1GB = 1024MB换算计算应该划分的大小,笔者这里分配了80GB的空间.划分之后的空间变为黑色(未分配) 4.Ubuntu启动安装 插入U盘,重启. 在启动界面 连续多次 按F2或者F12可以进入Bios设置界面 笔者电脑是DELL,使用F2进入的是bios的设置,F12进入的是boot menu,后者才是我们选择U盘启动盘的正确地方,读者可以根据电脑型号自行查找,不外乎这两个 进入界面之后可以看到一个Windows的启动选项,一个U盘型号的启动选项,选择U盘的选项进入 然后就会进入系统选择界面,选择 Install Ubuntu 安装系统 语言环境一定要选择英文 语言环境一定要选择英文 语言环境一定要选择英文,重要的话说三遍. 我们可以后续安装中文拼音输入法,也可以使用各种翻译软件工具辅助,但是一定要选择英文环境安装,不然后续出现一些字符编码问题,路径问题都是极其头痛的,切记!!! 可以先不联网,后续联网配置VPN代理一并搞定. 安装方式选择 Normal Installation 即可. Other option 什么也不勾选 安装类型(Installation type)选择 Something else,因为需要自定义划分磁盘空间 接下来进入一个磁盘空间的页面,找到之前划分的那一块未分配的空间(free space),我们将会对这一块空间进行再划分 选中区域,点击左下角加号 以下所有的都是空间起始位置(Beginning of this space),不需要修改 200MB Logical EFI,用于启动引导 这里的选择EFI是指切换下面的Ext4 journaling file system,找到EFI 8GB(8096MB) Logical swap area(用于交换区) 这里我建议有条件的把内存划分的大一些,16GB,32GB.linux内核编译就很占内存,分大一些对于软件和编译来说都比较友好 除此之外你可以利用剩余的空间划分 / 和 /home,其中 / 根目录,用于安装系统和软件相当于C盘,可以适当划分大一些 30GB(30720MB) Primary / 剩下的 Primary /home 下面的这一步非常重要 : 在分区界面的下方，选择安装启动项的位置, 这里要选择你刚刚划分的efi分区的编号 efi分区的大小是200MB,有一个是Windows的efi那个不要动! 找到你划分的那个分区的EFI. 目前划分的四个分区是连在一起的,你可以很容易的找到它(200MB),例如下图中的 /dev/nvmeOn1p9 然后选择安装启动引导器的设备,选择这个引导器,现在安装 注意不要用中文环境,使用英文环境! 5.安装完成 接下来就是选地区,用户名密码这都没什么好说的. 等待安装全部完成之后,会提醒你重启,把U盘拔了,点&quot;restart now&quot;，如果卡死就强制关机再重启就好,不要慌没有问题的 6.双系统收尾工作 注意,刚刚安装好的双系统不要马上有特别大的动作, 稍微等电脑凉一凉, 风扇不转了再配环境等等, 不然容易死机… 开机引导 双系统的引导菜单是Ubuntu的引导其grub的菜单,所以重启之后排在第一位的是ubuntu系统的启动,第二位通常是ubuntu的高级选项,第三是windows,我们可以根据情况选择. 你可以在开机的时候使用F2进入boot configuration调整windows boot manager的优先级到ubuntu的上面,这样开机默认进入windows了 第一次由Ubuntu安装完毕再进入windows可能会需要输入Bitlock解锁,你可以在如下网址找到你的恢复密钥,不过这是笔者一开始0节处就提到过的内容 如果你不想被反复的bitlock困扰, 可以使用 F2 进入 boot configuration 取消勾选 security https://account.microsoft.com/devices/recoverykey 如果想要切换默认进入windows,可以修改开机引导grub,但笔者习惯直接进入F2将windows的启动项移到ubuntu前面,这样默认进入的是windows的启动盘 如果需要进入ubuntu就F12然后选择ubuntu启动即可 卸载 如果不想使用ubuntu系统了就删除磁盘空间即可,右键删除卷 不过最开始的efi分区无法被直接删除,需要手动删除一下 进入windows, 使用 win + r 打开运行, 输入 diskpart 进入磁盘管理 输入 list disk 查看磁盘状态 DISKPART&gt; list disk 磁盘 ### 状态 大小 可用 Dyn Gpt -------- ------------- ------- ------- --- --- 磁盘 0 联机 476 GB 16 MB * 磁盘 1 联机 931 GB 0 B 当然你也有可能不是这样的,笔者的磁盘1是一块移动硬盘 如果你手动增加了一块硬盘的话也可能是如下的情况,这里我新增了一块1TB的NVM SSD硬盘,并且分配了500GB,剩下453GB没有分配 DISKPART&gt; list disk 磁盘 ### 状态 大小 可用 Dyn Gpt -------- ------------- ------- ------- --- --- 磁盘 0 联机 476 GB 79 GB * 磁盘 1 联机 953 GB 453 GB * 磁盘 2 联机 931 GB 0 B 现在的状态是我已经之前分配的80GB空间删除卷,所以磁盘0剩余空间79GB,efi分区暂时没有删除,我想将双系统转移到磁盘1中的未分配的453GB中 输入 select disk 0 选择磁盘0(即主磁盘), 输入 list partition 查看所有分区 DISKPART&gt; select disk 0 磁盘 0 现在是所选磁盘。 DISKPART&gt; list partition 分区 ### 类型 大小 偏移量 ------------- ---------------- ------- ------- 分区 1 系统 200 MB 1024 KB 分区 2 已保留 128 MB 201 MB 分区 3 主要 257 GB 329 MB 分区 4 主要 99 GB 257 GB 分区 5 主要 19 GB 357 GB 分区 6 系统 191 MB 377 GB 分区 10 未知 7721 MB 377 GB 分区 11 未知 28 GB 385 GB 分区 12 未知 43 GB 414 GB 分区 7 恢复 990 MB 457 GB 分区 8 恢复 16 GB 458 GB 分区 9 恢复 1501 MB 475 GB 这里可以看到类型中有两个是 系统 类型,其中200MB并且较小偏移量的是windows的引导,不要动! 选择剩下的那个 191MB 的系统分区,这个是我们ubuntu的引导区, 这个分区的编号与上文 4.Ubuntu启动安装 的efi分区是相同的编号,注意不要选错了 以下情况根据笔者自身情况分析,请读者自行调整为你的分区编号 选择分区6 ,完成删除 select partition 6 delete partition override 下面看一下删除之后的效果，可以看到将EFI分区删除之后，未分配的80GB正是之前用来安装Ubuntu设置的空间大小 最后F2进BIOS把ubuntu的引导删掉即可,这样就彻底删除了~ 可能遇到的问题 Ubuntu efi删除失败 如果使用 delete partition override 失败,则可使用下面的方式 选择分区6 select partition 6 创建一个新的挂载盘 assign letter=K, 这时候可以看到计算机多出来了一个盘,但是这个盘无法进入 在开始菜单找到记事本，右键【记事本】，选择【以管理员身份运行】，点击【文件】，点击【打开】。在文件浏览器里面可以进入刚刚挂载的K盘，找到名为Ubuntu的文件夹删除即可 删除之后再把刚刚挂载的K盘卸载就行。输入 remove letter=K Windows Boot Manager 丢失 误删除Windows Boot Manager电脑会进入grub终端 导入模块 insmod part_gpt 查看子目录 ls 此时应该会列出一些 hd, gpt, (hd,gpt)的文件 找到windows的所在目录 通常来说是(hd0, gpt1), 如果不是的话你可以一个一个试 set root=(hd0,gpt1) chainloader /efi/Microsoft/Boot/bootmgfw.efi 如果chainloader这一步没有报错,则说明成功. 如果报错了那就换一个 chainloader成功后重启 boot 如果一次chainloader就成功了那么没有问题了,如果chainloader失败过几次那么你的引导项会出现好几个Windows,删掉前面的保留最后一个就行, 最后一个是成功的 参考 https://zhuanlan.zhihu.com/p/392633489 https://bbs.huaweicloud.com/blogs/303695","categories":[],"tags":[{"name":"环境配置","slug":"环境配置","permalink":"https://luzhixing12345.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"}]},{"title":"Ubuntu工作环境配置","slug":"环境配置/Ubuntu工作环境配置","date":"2022-11-15T07:59:08.000Z","updated":"2023-06-04T11:35:58.670Z","comments":true,"path":"2022/11/15/环境配置/Ubuntu工作环境配置/","link":"","permalink":"https://luzhixing12345.github.io/2022/11/15/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/Ubuntu%E5%B7%A5%E4%BD%9C%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","excerpt":"","text":"前言 如今Linux发行版不少,也有各种好看的Linux桌面.如果只是想使用一个Linux的环境+bash那么无论是WSL还是SSH到一台远程服务器都是比较方便的,或者docker创建一个Linux的环境等等,配合Vscode做各种代码开发我想应该都是老生常谈的事情了. 本文用于记录笔者在Ubuntu22.04桌面版的工作环境配置,包括各种笔者认为必要的软件的安装,配置修改和个人偏好,主要目的有两个 另外笔者使用的是Ubuntu22.04的操作系统,对于老版本和更新的版本有一些出入,还请各位注意 换源 sudo apt install vim git sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak sudo vim /etc/apt/sources.list 删除所有内容,然后在最开头添加中科大源 deb https://mirrors.ustc.edu.cn/ubuntu/ jammy main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ jammy-security main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy-security main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse 22.04源 20.04源 18.04源 16.04源 sudo apt update 有时候 apt install 会有 lock 的问题: apt-get /var/lib/dpkg/lock-frontend sudo rm /var/lib/dpkg/lock-frontend sudo rm /var/lib/dpkg/lock sudo rm /var/cache/apt/archives/lock Ubuntu基础配置 在跳出自动更新的时候,顺势进入setting将自动更新时间修改为Never privacy-&gt;息屏时间调为永不 Software下载screenshot 设置中将截图快捷键修改为 ctrl + alt + a(QQ的默认截图快捷键),默认的截图保存在 ~/Picture/Screenshot,笔者一般配合vscode+picgo传到GitHub图床 terminal配置 在上方keyboard相同位置,搜索terminal,修改唤起快捷键为 option + r (同windows下win+r) 唤起terminal,perference,uname 背景颜色改为黑色,字体色白色,略微放大字体,修改字体为ubuntu bone 下载vscode 进入官网,对于ubuntu下载deb即可 不要使用ubuntu的software来安装vscode,存在中文无法输入的问题,到官网下载linux版本的 同步一下扩展 安装picgo依赖 sudo apt install xclip 精简左侧默认任务栏 网络代理 因为众所周知的原因,我们需要配置一下网络代理,解决代理问题之后我们就可以推进很多工作了 笔者个人倾向于v2rayA,比较省事.参考官方文档 v2rayA 下载并使用v2rayA 提供的镜像脚本 sudo apt install curl wget curl -Ls https://mirrors.v2raya.org/go.sh | sudo bash 关闭服务 sudo systemctl disable v2ray --now 添加公钥 wget -qO - https://apt.v2raya.org/key/public-key.asc | sudo tee /etc/apt/trusted.gpg.d/v2raya.asc 添加 V2RayA 软件源 echo &quot;deb https://apt.v2raya.org/ v2raya main&quot; | sudo tee /etc/apt/sources.list.d/v2raya.list sudo apt update 安装 V2RayA sudo apt install v2raya 启动并设置开机自启 sudo systemctl start v2raya.service sudo systemctl enable v2raya.service 安装之后就可以访问到UI界面了 http://localhost:2017 如果是服务器配置的话还需要打开这个端口,入方向规则和出方向规则 创建账号,导入节点,这里直接使用V2free的用户的订阅链接即可 导入成功后SERVER中全选,测试HTTP连接,选择几个延迟较低的,应用即可 默认端口为20170(socks5), 20171(http), 20172(带分流规则的http) 端口 桌面端的Ubuntu系统需要手动开启网络代理应用于本机(127.0.0.1) 127.0.0.1 20171 127.0.0.1 20171 空 空 127.0.0.1 20170 安装中文输入法 setting-&gt;region and language-&gt;manage installed language(打开之后会让你安装) 安装ficitx5 sudo apt install fcitx5 \\ fcitx5-chinese-addons \\ fcitx5-frontend-gtk3 fcitx5-frontend-gtk2 \\ fcitx5-frontend-qt5 kde-config-fcitx5 如果不是ubuntu22.04版本的话最后一项会报错找不到, 其他版本的中文输入法安装见: https://zhuanlan.zhihu.com/p/529892064 中文词库 在 GitHub 打开维基百科中文拼音词库的 Releases 界面，下载最新版的 .dict 文件 先运行一下fcitx5创建一下.local/share目录 fcitx5 然后ctrl+c退出即可 wget https://github.com/felixonmars/fcitx5-pinyin-zhwiki/releases/download/0.2.4/zhwiki-20220416.dict mkdir ~/.local/share/fcitx5/pinyin/ mkdir ~/.local/share/fcitx5/pinyin/dictionaries/ mv zhwiki-20220416.dict ~/.local/share/fcitx5/pinyin/dictionaries/ 设置为fcitx5默认输入法 setting-&gt;region and language-&gt;manage installed language, 切换ibus为fcitx5 环境变量 vim ~/.bashrc shift+G切到最下面,添加 export XMODIFIERS=@im=fcitx export GTK_IM_MODULE=fcitx export QT_IM_MODULE=fcitx 保存退出,激活 source ~/.bashrc 开机自启动 sudo apt install gnome-tweaks gnome-tweaks 修改默认fcitx5配置 fcitx5-configtool 打开GUI后取消勾选 only show current language,将pinyin移至左侧,apply 这里english在第一个,pinyin第二个 切简体中文 ctrl+space切换输入法为pinyin(可以在addons中修改,这里保持默认不修改),点击traditional chinese切换为simplified chinese 然后你就可以打字了 输入法美化 这个因人而异,可以搜索fcitx5其他主题 笔者这里使用的是nord主题,alpha-black这款我也比较喜欢 git clone https://github.com/tonyfettes/fcitx5-nord.git mkdir -p ~/.local/share/fcitx5/themes/ cd fcitx5-nord cp -r Nord-Dark/ Nord-Light/ ~/.local/share/fcitx5/themes/ 切换classic user interface 最后效果大概这样 Chrome wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb sudo dpkg -i google-chrome-stable_current_amd64.deb 接着就可以找到chrome了,这里有可能出现chrome图标找不到的问题,打开chrome也可能卡死,不过重启一下或者重新dpkg装一下似乎就好了,然后就可以把firefox卸了 ubuntu的话默认fn键是启用的,所以F12这里会调整音量,永久禁用(重启生效) echo options hid_apple fnmode=0 | sudo tee -a /etc/modprobe.d/hid_apple.conf sudo update-initramfs -u -k all 暂时性的禁用和启用fn见 https://www.bilibili.com/read/cv14517991/ 然后同步一下google账号 Vim 这里直接用了我的个人vimrc配置,大家可以换成自己的,我改的不是很多 curl -fLo ~/.vim/autoload/plug.vim --create-dirs https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim wget https://raw.githubusercontent.com/luzhixing12345/vimrc/main/.vimrc vim .vimrc :PlugInstall 软件安装 deepin-wine sudo apt-get update wget -O- https://deepin-wine.i-m.dev/setup.sh | sh 看到如下界面说明成功了,然后 关闭当前终端新开一个终端 # 微信 sudo apt-get install com.qq.weixin.deepin # QQ sudo apt-get install com.qq.im.deepin 全部列表: https://deepin-wine.i-m.dev/ 其他 其他配置的话也有很多,不过笔者之前已经有文章记录了,现在已经解决网络代理的问题了所以访问博客应该也没有问题了 git的SSH username email 切换NVIDIA显卡驱动 连接服务器的SSH免密配置一下 然后切一下双系统默认Windows,笔者电脑是DELL,使用F2进入的是bios的设置,F12进入的是boot menu.这里就是用F2进入bios把windows的调到ubuntu前面即可 参考 Linux代理配置 windows下v2rayN+wsl2代理配置 Ubuntu22.04安装Fcitx5中文输入法（详细） ubuntu 22.04 安装 微信、QQ","categories":[],"tags":[{"name":"环境配置","slug":"环境配置","permalink":"https://luzhixing12345.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"}]},{"title":"Linux代理配置","slug":"环境配置/Linux代理配置","date":"2022-11-08T06:16:29.000Z","updated":"2023-03-06T08:20:58.748Z","comments":true,"path":"2022/11/08/环境配置/Linux代理配置/","link":"","permalink":"https://luzhixing12345.github.io/2022/11/08/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/Linux%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/","excerpt":"","text":"Linux 代理配置 V2rayA 参考官方文档 v2rayA,已经比较详细了,笔者个人使用的是 Debian,ubuntu同理, 这里以它为例 下载并使用v2rayA 提供的镜像脚本 sudo apt install curl wget curl -Ls https://mirrors.v2raya.org/go.sh | sudo bash 关闭服务 sudo systemctl disable v2ray --now 添加公钥 wget -qO - https://apt.v2raya.org/key/public-key.asc | sudo tee /etc/apt/trusted.gpg.d/v2raya.asc 添加 V2RayA 软件源 echo &quot;deb https://apt.v2raya.org/ v2raya main&quot; | sudo tee /etc/apt/sources.list.d/v2raya.list sudo apt update 如果这一步update出错, 那就直接前往V2rayA下载包手动安装 wget &lt;package.deb&gt; sudo dpkg -i &lt;package.deb&gt; # 如果出现问题 # sudo apt-get install -f 安装 V2RayA sudo apt install v2raya 启动并设置开机自启 sudo systemctl start v2raya.service sudo systemctl enable v2raya.service 安装之后就可以访问到UI界面了 http://localhost:2017 如果是服务器配置的话还需要打开这个端口,入方向规则和出方向规则 创建账号,导入节点,这里直接使用V2free的用户的订阅链接即可 导入成功后SERVER中全选,测试HTTP连接,选择几个延迟较低的,应用即可 默认端口为20170(socks5), 20171(http), 20172(带分流规则的http) 端口 如果是桌面端的Ubuntu系统需要手动开启网络代理应用于本机(127.0.0.1) 127.0.0.1 20171 127.0.0.1 20171 空 空 127.0.0.1 20170 如果是服务器端可以在 .bashrc 最后加入配置代理端口(不要忘记如果云服务器没开放这个端口要去云服务器网站手动开启这个端口的入出方向规则) vim ~/.bashrc 加入 export http_proxy=&quot;http://localhost:20171&quot; export https_proxy=&quot;http://localhost:20171&quot; 激活环境 source ~/.bashrc clash for linux https://me.tofly.cyou/doc/#/linux/clash 进入clash的release,根据系统选择对应的文件 通常来说是linux-amd64,两个安装包都可以,选择第一个即可 wget https://github.com/Dreamacro/clash/releases/download/v1.12.0/clash-linux-amd64-v1.12.0.gz 386是对于32位的,amd64是x86 下载完成之后解压得到可执行文件 gzip -f clash-linux-amd64-v1.12.0.gz -d 授权可执行权限 chmod +x clash-linux-amd64-v1.12.0 初始化执行 ./clash-linux-amd64-v1.12.0 初始化执行 clash 会默认在 ~/.config/clash/ 目录下生成配置文件和全球IP地址库：config.yaml 和 Country.mmdb 如果初始化出现问题可以到原网站手动下载 用wget下载clash配置文件，替换默认的配置文件，下面的wget命令后面的 你的Clash订阅链接网址 ，用上面的实际的clash订阅链接替换 这里的clash订阅地址需要到 https://me.tofly.cyou/doc/#/linux/clash 查看自己的 wget -U &quot;Mozilla/6.0&quot; -O ~/.config/clash/config.yaml 你的Clash订阅链接网址 再次启动clash, 这里使用后台启动, 前台启动的话如果关闭当前终端则clash代理就终止了 nohup ./clash-linux-amd64-v1.12.0 &amp; clash 默认 http 端口默认监听 7890 , socks5 端口默认监听 7891 如果是ubuntu桌面端手动配置代理端口即可 如果是服务器端可以在 .bashrc 最后加入配置代理端口(不要忘记如果云服务器没开放这个端口要去云服务器网站手动开启这个端口的入出方向规则) vim ~/.bashrc 加入 export http_proxy=&quot;http://localhost:7890&quot; export https_proxy=&quot;http://localhost:7890&quot; 激活环境 source ~/.bashrc","categories":[],"tags":[{"name":"环境配置","slug":"环境配置","permalink":"https://luzhixing12345.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"}]},{"title":"docker基本命令","slug":"环境配置/docker基本命令","date":"2022-11-07T17:06:27.000Z","updated":"2023-03-13T15:31:50.021Z","comments":true,"path":"2022/11/08/环境配置/docker基本命令/","link":"","permalink":"https://luzhixing12345.github.io/2022/11/08/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/docker%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/","excerpt":"","text":"Docker docker教程 基本架构 docker有两个概念,镜像和容器. 镜像相当于类,容器相当于类创建的对象. 一个镜像可以创建多个容器 安装docker curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 换源 拉取一个Ubuntu的镜像(默认最新) docker pull ubuntu 拉取特定版本的 docker pull ubuntu:16.04 查看所有镜像 docker images 以下内容以笔者本机为例, 笔者拉取了两个版本的Ubuntu镜像和一个默认拉取的hello-world镜像 (base) root@hecs-67846:~# docker images REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu latest a8780b506fa4 4 days ago 77.8MB hello-world latest feb5d9fea6a5 13 months ago 13.3kB ubuntu 16.04 b6f507652425 14 months ago 135MB 查看容器情况 docker ps -a 笔者这里有一个正在运行的容器 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES da1811a84ddc ubuntu:16.04 &quot;/bin/bash&quot; 7 hours ago Up 4 hours csapp 启动一个容器 docker run --name kamilu -itd ubuntu /bin/bash 其中 -it 的 -t 选项让Docker分配一个伪终端(pseudo-tty)并绑定到容器的标准输入上, -i 则让容器的标准输入保持打开 -d 是笔者个人喜欢使用的,它会使容器在后台运行并且返回生成的容器的ID 后面的ubuntu指的就是镜像的名字,这里使用的ubuntu,也就是ubuntu:latest, 最后启动一个 bash 终端,允许用户进行交互 前面的 --name 是为这个容器指定一个名字,如果不指定的话这个名字比较随意,不是很方便管理 再使用 docker ps -a 查看可以看到容器已经运行起来了 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 9041786640c9 ubuntu &quot;/bin/bash&quot; 8 seconds ago Up 6 seconds kamilu da1811a84ddc ubuntu:16.04 &quot;/bin/bash&quot; 7 hours ago Up 5 hours csapp 如果在gdb调试的时候遇到了warning: Error disabling address space randomization: Operation not permitted的报错,需要在OPTION中加入如下参数,后面一样不变docker run --cap-add=SYS_PTRACE --security-opt seccomp=unconfined 重启一个已关闭的容器使用 docker restart &lt;CONTAINER_ID&gt; 进入容器 进入容器之前容器需要处于正在运行的状态,进入有两种方式 attach 和 exec attach 从容器退出会导致容器的停止 # 直接使用容器的名字 docker attach kamilu # 使用容器的ID docker attach 9041786640c9 exec 退出不会导致容器停止,比较适合需要持续运行的后台服务 docker exec -it kamilu /bin/bash 如果需要在一个容器中使用多个终端处理不同的任务,应该使用exec的方式进入,attach会导致两个终端的状态同步 文件传输 主机-&gt;容器 docker cp &lt;PATH&gt; &lt;CONTAINER_ID/NAME&gt;:&lt;PATH&gt; # docker cp bomb.tar csapp:/root 容器-&gt;主机 docker cp &lt;CONTAINER_ID/NAME&gt;:&lt;PATH&gt; &lt;PATH&gt; # docker cp csapp:/home/bomb.tar /home/files 退出 关闭 删除容器 退出 exit ctrl + d 关闭 docker stop &lt;NAME&gt; docker stop &lt;CONTAINER_ID&gt; 删除 docker rm -f &lt;NAME&gt; docker rm -f &lt;CONTAINER_ID&gt; 导入和导出 导出 docker export csapp &gt; csapp.tar 导入: 从容器快照文件中再导入为镜像 docker import csapp.tar another_csapp:v1.0 cat csapp.tar | docker import - another_csapp:v1.0 删除镜像 docker rmi another_csapp:v1.0 上传容器 首先需要前往docker hub注册一个账号,假设账号名为kamidalu 你希望上传的容器名为miniCRT,你需要先将其打包成 Docker 镜像,注意打包的名字里面不能有大写字符 docker commit miniCRT kamidalu/minicrt 登录docker账号 docker login 如下结果为登录成功 Authenticating with existing credentials... WARNING! Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded 上传你的docker镜像 docker push kamidalu/minicrt 基础环境搭建 纯docker容器相当的干净,可以快速地把常用软件安装一下,以便后续使用 基本 apt-get -y update apt-get -y install sudo sudo apt -y install vim sudo apt -y install wget sudo apt -y install unzip 软件 sudo apt -y install git C sudo apt -y install gcc sudo apt -y install build-essential gdb sudo apt -y install gcc-multilib Docker 代理配置 docker代理配置的也很简单,并且官方提供了镜像,我们只需要直接运行就可以拉取镜像创建容器了 如果你的本机已经配置了代理,那么只需要在创建的时候加入--network=host 即可(不过似乎有点小问题…) docker run -itd --network=host --name=&lt;NAME&gt; ubuntu docker run -d \\ --restart=always \\ --privileged \\ --network=host \\ --name v2raya \\ -e V2RAYA_ADDRESS=0.0.0.0:2017 \\ -v /lib/modules:/lib/modules:ro \\ -v /etc/resolv.conf:/etc/resolv.conf \\ -v /etc/v2raya:/etc/v2raya \\ mzz2017/v2raya 值得注意的是镜像制作使用的是 alpine linux ,所以进入的话需要使用 /bin/sh docker exec -it v2raya /bin/sh 并且默认源太慢了,可以换成中科大的源(推荐) sed -i &#x27;s/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g&#x27; /etc/apk/repositories 或者阿里的镜像源 sed -i &#x27;s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g&#x27; /etc/apk/repositories alpine linux下载使用的是 apk add &lt;name&gt; 而不是 apt install &lt;name&gt; apt-get install apt-transport-https ca-certificates 最后分享一个个人的新容器初始化的shell脚本 apt-get -y update apt-get -y install sudo sudo apt install ca-certificates sudo echo &quot;deb https://mirrors.ustc.edu.cn/ubuntu/ jammy main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ jammy-security main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy-security main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse&quot; &gt; /etc/apt/sources.list sudo apt -y update sudo apt -y upgrade sudo apt -y install vim sudo apt -y install wget sudo apt -y install unzip sudo apt -y install gcc sudo apt -y install build-essential gdb sudo apt -y install gcc-multilib git 保存为 dockerinit.sh chmod +x dockerinit.sh ./dockerinit.sh","categories":[],"tags":[{"name":"环境配置","slug":"环境配置","permalink":"https://luzhixing12345.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"}]},{"title":"疑难杂症的报错","slug":"杂/疑难杂症的报错","date":"2022-10-23T08:56:42.000Z","updated":"2023-01-09T05:06:34.945Z","comments":true,"path":"2022/10/23/杂/疑难杂症的报错/","link":"","permalink":"https://luzhixing12345.github.io/2022/10/23/%E6%9D%82/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87%E7%9A%84%E6%8A%A5%E9%94%99/","excerpt":"","text":"TypeError: expected str, bytes or os.PathLike object, not int 关闭VPN,更新pip包 pip install --upgrade pip --no-cache-dir No such file or diectory 64-32 sudo apt install lib32ncurses5 pip下载 user下pip/pip.ini [global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple no-cache-dir = True proxy = http://127.0.0.1:10809 [install] trusted-host=mirrors.aliyun.com 这里的10809是v2rayN的代理端口 conda clean -a 我的世界 https://www.bilibili.com/video/BV1Xe4y1X7G7 PCL2: https://ltcat.lanzoum.com/iJrst0fn1w0h JAVA18 : https://www.oracle.com/java/technologies/javase/jdk18-archive-downloads.html java --version javac --version","categories":[],"tags":[{"name":"杂","slug":"杂","permalink":"https://luzhixing12345.github.io/tags/%E6%9D%82/"}]},{"title":"计算机系统基础:浮点数的表示","slug":"csapp/浮点数的表示","date":"2022-10-07T15:23:41.000Z","updated":"2023-02-28T09:58:40.816Z","comments":true,"path":"2022/10/07/csapp/浮点数的表示/","link":"","permalink":"https://luzhixing12345.github.io/2022/10/07/csapp/%E6%B5%AE%E7%82%B9%E6%95%B0%E7%9A%84%E8%A1%A8%E7%A4%BA/","excerpt":"","text":"前言 大二的时候学习过这部分知识,现在也只剩下模糊的印象了,隐约记得做题的时候要算来算去好不麻烦. 为了速成看了一些技术博客,但总感觉走马观花,绝知此事还是要躬行,故留此文以便日后忘记之际重温. 本文主要参考深入理解计算机系统第三版书籍中对于该部分的描述,并且例举一些书中的习题以加深印象,以及CSAPP的Data Lab实验对于浮点数的函数实现 二进制小数 对于一个十进制的数 12371892398, 这个表达式描述的数被定义为 d=∑i=0n10i×did = \\sum\\limits_{i=0}^n10^i\\times d_i d=i=0∑n​10i×di​ 如果我们考虑小数点 . , 那么左边的权是正幂,右边是负幂,例如 12.3412.3412.34 表示的数字是 1×101+2×100+3×10−1+4×10−2=12341001\\times 10^1 + 2\\times 10^0 + 3\\times 10^{-1} + 4\\times 10^{-2}=12\\frac{34}{100}1×101+2×100+3×10−1+4×10−2=1210034​ 而对于二进制数,这个权就变为了2 (d=∑i=0n2i×did = \\sum\\limits_{i=0}^n2^i\\times d_id=i=0∑n​2i×di​),所以对于 101.11101.11101.11来说这个值就是 1×22+0×21+1×20+1×2−1+1×2−2=534=5.751\\times 2^2 + 0\\times 2^1+1\\times 2^0+1\\times 2^{-1}+1\\times 2^{-2}=5\\frac{3}{4}=5.751×22+0×21+1×20+1×2−1+1×2−2=543​=5.75 假定我们仅考虑有限长度的编码，那么十进制符号是不能准确地表达像 13\\frac{1}{3}31​ 和 57\\frac{5}{7}75​ 这样的数的。类似地，小数的二进制表示法只能表示那些能够被写成 x×2yx\\times 2^yx×2y 的数。其他的值只能够被近似地表示。例如，虽然加长二进制表示能够提高近似表示数’的精度，但是我们并不能把它准确地表示为一个二进制数: IEEE 浮点数表示 像前一节中谈到的位置表示法不能很有效地表示非常大的数字。例如，表达式 5×21005\\times 2^{100}5×2100 的表示是由 101后面跟随100个零的位模式组成的。相反地，我们希望通过给定x和y 的值，来表示形如 x×2yx\\times 2^yx×2y 的数。 IEEE浮点标准用 V=(−1)s×M×2EV=(-1)^s\\times M \\times 2^EV=(−1)s×M×2E 的形式来表示一个数: 符号S 用来决定这个数是负数(s=1)还是正数(s=0),对于数值0的符号位解释作为特殊情况处理 有效数 M 是一个二进制小数,它的范围在 1~2-e 之间,或者在0-1-e之间 指数 E 是2的幂,可以是负数,它的作用是对浮点数加权 所以IEEE754标准规定了如下的三个域 s对应符号位,exp对应E指数位,frac则是对应有效数M float 32位 : 1(s) + 8(exp) + 23(frac) double 64位 : 1(s) + 11(exp) + 52(frac) 接下来按理来说应该讲到规格化和非规格化的部分,但是这部分记忆的内容有点复杂,大片的文字也比较容易劝退,所以我想直接上图,我们对着结果来反过来讲 这是一个8位的浮点格式,格式为 1(s)+4(exp)+3(frac) 对于非规格化的数,即分割横线以上,他们的特点是(exp)的部分都是0,然后后面的(frac)部分在不断增加 规格化的则是这两部分01都有 最后的正无穷则是(exp)部分全为1,(frac)全为0 注意到上面有e E f M V五个字母,我们先观察一下他们和左面数据的对应关系,可以得出 e 是指数部分,和(exp)的二进制值相同 E 是指数,在非规格化的时候一直是-6,在规格化的情况下是e-7 f 是小数部分,在非规格化的时候和M相同,规格化的时候是 M-1 M 是有效数 V 是小数的值,根据之前的IEEE754的公式,可以得到 V=2E×fV = 2^E\\times fV=2E×f 现在经过一个初步的分析我们已经可以看出一些关系了,但是还有一些疑问 e 和 E 有什么关系呢? f 和 M 有什么关系呢? 这两个值又是怎么算出来的呢? 这里的分隔线提到的非规格化和规格化是什么意思呢? 又为什么要这么做呢? 对于第一个问题 : e 和 E 有什么关系呢? 之前提及的这个8位的浮点格式为 1(s)+4(exp)+3(frac),这里一个非常重要的概念是偏置项(Bias),这个数的计算方法是 2exp−1−12^{exp-1}-12exp−1−1 ,即 24−1−1=72^{4-1}-1=724−1−1=7 对于非规格化, E = 1-Bias = -6 对于规格化, E = e-Bias 这样我们利用了一个Bias就可以实现指数E的正负,既可以表示一个相对大的数,也可以表示一个趋近于0的数 对于第二个问题 : f 和 M 有什么关系呢? 这两个值又是怎么算出来的呢? f的分子部分很容易看出是剩下的 (frac) 的二进制的值,分母部分则是8,也就是 232^323, 即 2frac2^{frac}2frac 对于非规格化, f = M 对于规格化, f = M-1, 或者说 M = f+1 好,到目前为止我们可以做到两件事情了,第一件是给定一个浮点数的格式,给我它的二进制表示,我可以将这个浮点数的值计算出来 比如 1 01111 001, 那么很明显首先根据符号位判断是一个负数,指数部分为5位,所以可以计算出Bias = 25−1−1=152^{5-1}-1 = 1525−1−1=15. 指数部分并非全0所以是一个规格化的数, 所以 E = e-Bias = 15-15=0. 再看小数部分的值为 f = 1/8,由于是规格化所以 M = f+1 = 9/8, 所以最后的值为 20×98=9/82^0 \\times \\frac{9}{8} = 9/820×89​=9/8 ,加个负号 -9/8 再比如 1 0111 0010, 首先是一个负数, 指数4位 Bias = 7, 规格化, E = 7-7 = 0. 小数部分 f = 2/16, M = f+1 = 18/16,所以值为 -18/16 = -9/8 最后来一个 0 00000 111, 正数, 指数5位 Bias = 15, 非规格化 E = -14, f = 7/8 = M, 所以值为 78×2−14=7/217\\frac{7}{8} \\times 2^{-14} = 7/2^{17}87​×2−14=7/217 总结一下做题技巧, 半秒钟扫一眼符号位记在脑子里, 看指数多少位, 算一下 Bias, 一定注意是 2的exp-1次幂 -1 ,exp-1如果记错了那可糟糕了. 然后看一眼指数部分是不是全0, 如果全零那就是非规格化,否则是规格化. 根据规格化还是非规格化计算 E, 算一下f然后判断是否加1, 乘起来最后把符号位加上,结果化简一下就可以了 这个过程主要是熟能生巧, 课后习题练几道考试绝对不慌. 第二件事情可就头大了,那就是给我一个数,我能不能写出来它的二进制的浮点数格式? 写这个可是相当耗脑筋,而且几乎除了做几道习题其余时间毫无用处,在这之前我们不妨先回答一下第三个问题 这里的分隔线提到的非规格化和规格化是什么意思呢? 又为什么要这么做呢? 对于任意的一个数,我们总是可以调整指数E使得 M 在0-1之间,即第一位是0.xxx的话就小数点右移 小数域frac解释为描述小数值f,其中 0≤f&lt;10\\leq f &lt; 10≤f&lt;1, 而有效数M的定义为 1+f. 既然第一位总是1,那么我们就不需要显示的来表示它了 为什么会有偏置值Bias呢? 首先我们考虑到一个小数肯定是既可以表示较大的数,也可以表示较小的数(指趋近于0),那么这时候指数就一定是负数才可以. 负数的表示方法再补码的时候是使用最高位的1来表示的,经过简单的对比计算不难发现.如果浮点数的格式中留给exp的位数有4位. 那么原先补码的方式区分正负的话可以表示的范围为 -8 ~ 7, 如果以上文提到的计算方式则是 -6 ~ 7, 范围反而更小了? 这里的范围是 -6~7是因为最小值是1-7=-6, 而最大值由于规格化的情况下指数部分不能全为1,全为1是一种特殊情况表示无穷,所以最大值为1110(14),14-7=7 补码的形式这个取值范围暂时没有考虑需要去除无穷的情况,我们也可以假定 1000(即-8)是代表无穷 但是规格化非规格化区分的时候采用了f/f+1来计算有效数 M, 即如果是非规格化就是 1-Bias作为指数,f作为M; 如果是规格化则是 e-Bias作为指数, f+1作为 M. 采用1-Bias的一个好处是 使得最大非规格化数到最小规格化数的变化非常平滑 另外可以观察到这个表达式具有一个很有趣的属性, 如果我们忽略符号位(s),将后面的(exp)和(frac)解释为无符号整数,他们就是按照升序排列的,就像它们表示的浮点数一样.这并不是偶然的,IEEE格式如此设计就是为了 浮点数能够使用整数排序函数进行排序. 而如果是补码的形式,即造成了混乱了排序,需要额外处理指数部分的正负,还有过渡不平滑等等问题. 特殊情况 特殊情况有两种,一种是指数部分(exp)全为1,并且(frac)全为0,这时候表示的是无穷,根据符号位判断是正无穷或者负无穷 另一种情况是(exp)全1,但是(frac)不全1,这种情况代表NaN(Not a Number),用于处理异常情况,无效运算,数学上未定义的情况. 例如:负数的平方根 舍入 上图可以看出浮点数的范围和精度有限,对于该规格的8位最小是0,其次就是1/512了,240以上的数也无法表示. 即使是对于精度更高的float/double 也同样存在无法表示的数据 这时候我们想有一种系统的方法,能够找到最接近的匹配值,它可以用期望的浮点形式表示出来 参考IEEE 754 的舍入规则 常用的舍入方式分为四种,分别是向零舍入,向上舍入,向下舍入,向偶数舍入 其中向零舍入,向上舍入,向下舍入就不再赘述了,大家看一下上图结合实际很清晰明了,这里着重讲一下向偶数舍入 计算机中为什么要采用向偶数舍入的方式呢? 前文已经提及了计算机可能无法精确表示某一个浮点数,所以在计算的过程中舍入的情况必须要考虑. 如果我们只采用向上或者向下中的一种，就会造成平均数过大或者过小，实际上这时候就是引入了统计偏差。如果是采用偶数舍入，则有一半的机会是向上舍入，一半的机会是向下舍入，这样子可以在一定程度上避免统计偏差 如何使用向偶数舍入计算呢? 这里首先要提到一个很重要的概念, 中间值. 中间值的确定首先要看我们要保留多少位有效数字,或者说我们要精确到哪一位. 以十进制为例,比如对于 1.2349999 舍入到小数点后两位,也就是百分位.那么中间值就是舍入位下一位为该进制的中间值,后面全为0; 对于这个题目来说,中间值就是小数点后第三位为5,其后全为0,即 1.2350000 当具体的值大于中间值的时候，向上舍入 当具体的值小于中间值的时候，向下舍入 当具体的值等于中间值的时候，向偶数舍入 所以本题舍入的情况是实际值 1.2349999 小于中间值 1.2350000, 故向下舍入为 1.23. 如果是 1.2350001 则大于中间值舍入为 1.24 那么如果刚好是 1.2350000 如何进行偶数舍入呢? 这时就看舍入位是奇数还是偶数. 此时舍入位为3是偶数,所以向偶数4舍入得到 1.24. 如果是 1.2450000 则舍入位4为偶数所以还是向偶数4舍入得到1.24 接下来以二进制为例，有效位数保留到小数点后两位 这里值得一提的是二进制中间值为什么是1呢? 如果是三进制的话012我们肯定很容易的得到1是中间值.但是二进制实际上只有两个值0/1为什么就选择了1而不是0呢? 实际上这个问题也很好解释,因为舍入位下一位选择中间值,而其之后全为0,所以对于二进制来说的它情况如下 00 : 一定会向下舍入 01 : 一定会向下舍入 10 : 不确定,刚好等于中间值了所以向偶数舍入 11 : 一定会向上舍入 接近一个3:2的舍入情况,而如果选择0作为中间值可以看出来除了00是偶数舍入,01,10,11都是向上舍入了就变成了1:4的分类了,显然1作为二进制的中间值是合理的.这也就同时解释了偶数进制(十进制,十六进制)为什么采用一半(5,8)作为中间值了. 写到此处关于浮点数的基本知识点说的差不多了,接下来我们来一些习题的实战吧. 我们先来解决到之前遗留下来的那个问题,给我一个值,我如何写出它的二进制的浮点数格式? 根据这张图我们可以明显的看出一个非规格化和规格化的分界线,即7/512和8/512 前文提到过IEEE754标准的浮点数是一个升序的,所以第一步是计算出非规格化的最大值并且判断这个数是规格化还是非规格化,如果需要转化的数值比它小,那么就一定是非规格化表示,否则使用规格化表示 第一步判断之后就可以进入第二步了,首先如果是非规格化,那么很显然(exp)的部分全是0,符号位一眼鉴定,所以实际上只需要计算(frac)的部分就可以了. 我们可以通过(exp)的位数计算出来Bias,这样就得到了E=1-Bias,接下来只需要 V2E\\frac{V}{2^E}2EV​ 就可以计算出有效数 M ,然后再根据(frac)的位数算出分母是多少,然后就可以计算出分子,转换成二进制就可以了 如果判断是规格化,那就有点费劲了. 因为我们需要同时考虑(exp)的部分和(frac)的部分. 这时候需要先观察一下给的值是多少,因为最后算出的有效数M一定是1-2之间的,然后这个M再乘上指数2^E得到的结果,所以我们可以通过结果反推指数的值, 比如结果是35,那么很可能这个指数就是5,因为 25=322^5=3225=32 ,再乘上一个1.多的小数就有可能得到35,大概意思如此. 简单判断出来指数的E的值之后就可以通过规格化的公式反向推出e=E+Bias了,这就是(exp)的部分了,M是通过 V2E\\frac{V}{2^E}2EV​ 计算出来, f = M-1 然后再转换成二进制,最后得到(frac)部分 这一部分实在是麻烦,考试或者做题的时候需要保持头脑清醒,计算准确,需要勤加练习 易错易忘的地方有几个,规格化和非规格化中1-Bias还是e-Bias,要不要f+1,Bias的计算方法,化简的时候注意是2的幂. 有的时候还会遇到一些棘手的情况比如没办法表示,只能依靠舍入来计算一个近似的结果,或者发现规格化的最大值也无法表示这个数值,只能选择无穷了. 这里直接引用了CSAPP书中的一道习题,这里中文版和英文版的题目内容不同,本文采用英文版的习题 A格式是1(s)+5(exp)+3(frac), B格式是1(s)+4(exp)+4(frac). 题目要求将A的值转换为最接近的B的值,如果需要舍入采用向正无穷舍入 A-Bits A-Value B-Bits B-value 1 01111 001 -9/8 1 0111 0010 -9/8 0 10110 011 1 00111 010 0 00000 111 1 11100 000 0 10111 100 题目答案如下: A-Bits A-Value B-Bits B-value 1 01111 001 -9/8 1 0111 0010 -9/8 0 10110 011 176 0 1110 0110 176 1 00111 010 -5/1024 1 0000 0101 -5/1024 0 00000 111 7/2177/2^{17}7/217 0 0000 0001 2−102^{-10}2−10 1 11100 000 -8192 1 1110 1111 -248 0 10111 100 384 0 1111 0000 +∞+\\infin+∞ 最后是datalab中最后的三道浮点数和整数之间的题目 //float /* * floatScale2 - Return bit-level equivalent of expression 2*f for * floating point argument f. * Both the argument and result are passed as unsigned int&#x27;s, but * they are to be interpreted as the bit-level representation of * single-precision floating point values. * When argument is NaN, return argument * Legal ops: Any integer/unsigned operations incl. ||, &amp;&amp;. also if, while * Max ops: 30 * Rating: 4 */ unsigned floatScale2(unsigned uf) &#123; int exp_mask = 0x7f800000; int exp = (uf&amp;exp_mask)&gt;&gt;23; int frac_mask = 0x7fffff; int frac = uf &amp; frac_mask; if (exp == 0) &#123; if (frac&gt;&gt;23&amp;1) &#123; frac = frac * 2 - 0x7fffff; &#125; else &#123; frac = frac &lt;&lt; 1; &#125; return (uf &amp; ~frac_mask) | frac; &#125; else if (exp == 255) &#123; return uf; &#125; else &#123; return (uf &amp; ~exp_mask) | (exp+1)&lt;&lt;23; &#125; &#125; /* * floatFloat2Int - Return bit-level equivalent of expression (int) f * for floating point argument f. * Argument is passed as unsigned int, but * it is to be interpreted as the bit-level representation of a * single-precision floating point value. * Anything out of range (including NaN and infinity) should return * 0x80000000u. * Legal ops: Any integer/unsigned operations incl. ||, &amp;&amp;. also if, while * Max ops: 30 * Rating: 4 */ int floatFloat2Int(unsigned uf) &#123; int exp_mask = 0x7f800000; int frac_mask = 0x7fffff; int exp = (uf &amp; exp_mask)&gt;&gt;23; int frac = uf &amp; frac_mask; int signal = uf&gt;&gt;31&amp;1; int bias; int ans; if (exp &lt; 127) &#123; return 0; &#125; else if (exp == 255 || exp &gt; 127+31) &#123; return 0x80000000; &#125; else &#123; if (exp==127+31)&#123; if (frac==0 &amp;&amp; signal == 1) &#123; return 0x80000000; &#125; else &#123; return 0x80000000; &#125; &#125; else &#123; bias = exp-127; if (bias &gt;= 23) &#123; ans = (1&lt;&lt;bias) + (1&lt;&lt;bias&gt;&gt;23)*frac; &#125; else &#123; ans = 1&lt;&lt;bias; &#125; return signal ? -ans:ans; &#125; &#125; &#125; /* * floatPower2 - Return bit-level equivalent of the expression 2.0^x * (2.0 raised to the power x) for any 32-bit integer x. * * The unsigned value that is returned should have the identical bit * representation as the single-precision floating-point number 2.0^x. * If the result is too small to be represented as a denorm, return * 0. If too large, return +INF. * * Legal ops: Any integer/unsigned operations incl. ||, &amp;&amp;. Also if, while * Max ops: 30 * Rating: 4 */ unsigned floatPower2(int x) &#123; int frac, exp; if (x &lt; -149) return 0; else if (x &gt;= -149 &amp;&amp; x &lt;= -127) &#123; frac = x+149; return 1 &lt;&lt; frac; &#125; else if (x&lt;128) &#123; exp = x+127; return exp &lt;&lt; 23; &#125; else &#123; return 255 &lt;&lt; 23; &#125; &#125;","categories":[],"tags":[{"name":"CSAPP","slug":"CSAPP","permalink":"https://luzhixing12345.github.io/tags/CSAPP/"}]},{"title":"WSL2配置","slug":"环境配置/WSL2配置","date":"2022-10-06T09:35:04.000Z","updated":"2023-06-05T13:32:48.939Z","comments":true,"path":"2022/10/06/环境配置/WSL2配置/","link":"","permalink":"https://luzhixing12345.github.io/2022/10/06/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/WSL2%E9%85%8D%E7%BD%AE/","excerpt":"","text":"WSL 官方文档 安装 WSL Windows可以使用WSL(Windows Subsystem for Linux)来使用Linux环境 打开控制面板-&gt;程序 启动或关闭 Windows 功能 开启 “适用于 Linux 的 Windows 子系统” 和 “虚拟机平台” 选项 启用服务,重启电脑 键盘按下 Win + r 输入 cmd 后回车 wsl --install -d Ubuntu 当然我们也可以选择其他操作系统,可以通过如下命令查看可用发行版列表 wsl --list --online 等待安装完毕之后,输入用户名 密码就可以进入Linux系统了,这个操作系统的名字是 Ubuntu 如果关闭窗口后再想重新进入这个系统,只需要在命令行中输入 wsl 或者这个操作系统的名字就可以直接进入 当然也支持安装运行多个操作系统,不过暂时没有这个必要 WSL 中使用gdb调试 检查系统中是否已经安装了gdb gdb -v 如果没有安装,则使用命令行安装 sudo apt-get update sudo apt-get install build-essential gdb 如果下载太慢了 考虑切换一个下载的源 vim /etc/apt/sources.list 在文件最前面加入 / 删除整个文件重新创建一个新的文件并写入 deb http://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ jammy-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ jammy-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiverse 保存退出,重新执行 其他源 查看WSL版本 wsl --list --verbose 如果是WSL1的运行gdb会出现问题,升级到WSL2 Github Issue1 Github Issue2 回到Windows系统的命令行, 升级WSL系统 wsl --set-version Ubuntu 2 WSL 与 Windows文件互传 WSL正常情况下会出现在文件资源管理器,可以直接在 home 目录下找到当前安装的操作系统 如果安装之后没有找到, 可以通过其他方式 win + r 输入 \\\\wsl$ 进入wsl的操作系统中,在终端中输入 explorer.exe . 我们可以直接打开两个文件夹,直接通过复制粘贴实现文件传输 除此之蛙wsl将windows中的文件挂载到 /mnt 虚拟磁盘下,默认的登录路径也是这里,我们可以直接通过mnt切换盘符及路径,比如: kamilu@LZX:/mnt/c/Users/luzhi$ cd /mnt/d kamilu@LZX:/mnt/d$ 再利用 cp 或者 mv 命令就可以实现文件的传输了,笔者这里还是推荐第一种,比较直接 安装一个更加美观的 Terminal 终端 原生的命令行窗口并不好看,由于本实验可能需要大部分时间面对一个终端的显示,我们考虑选择使用一个更加美观漂亮的终端 在 terminal release 中下载最新版的安装包 注意区分 Win10/11版本,不要下错了 如果不清楚windows版本可以按下Win + r 输入 winver查看 下载后点击对应版本安装即可,接下来尝试再来按下 Win + r 输入cmd进入控制台吧,是不是好看多了? WSL2代理配置 WSL2由于直接使用局域网与本机通信,可以直接使用Windows上的代理端口,这里假定读者已安装过 Windows 下的 V2ray 修改V2ray默认选项 设置-&gt;参数设置-&gt;允许来自局域网的连接 查看代理端口 http的系统代理走局域网的10811端口 修改.bashrc文件 打开.bashrc vim ~/.bashrc 在文件结尾加入 export host_ip=$(cat /etc/resolv.conf |grep &quot;nameserver&quot; |cut -f 2 -d &quot; &quot;) export http_proxy=&quot;http://$host_ip:10811&quot; export https_proxy=&quot;http://$host_ip:10811&quot; :wq保存退出,激活环境 source ~/.bashrc 测试 wget www.google.com wget https://raw.githubusercontent.com/luzhixing12345/MyScripts/main/main.py 得到两个文件即为成功 直连域名配置 正常使用v2ray会出现访问一些服务器的域名无法访问,但是直连可以访问.这时候需要 设置-路由设置-直连的Domain/IP SSH 失败 之前有一段时间突然发现 git 一直push不上去, 也pull不下来 然后使用 ssh -vT git@github.com 查看发现原来是 SSH 的问题, 一直卡在下面的这个地方 debug1: expecting SSH2_MSG_KEX_ECDH_REPLY 后来查阅了一些资料, 在 Github cloning error in wsl2 (driver MTU) 得到了解决 总结一下就是先下载网卡驱动 正常来说你安装完网卡驱动应该就可以解决了, 重启一下, 要不就等一下 如果仍然有问题: 用 ip addr | grep mtu 看下 eth0 的 mtu (base) kamilu@LZX:~$ ip addr | grep mtu 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 2: bond0: &lt;BROADCAST,MULTICAST,MASTER&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000 3: dummy0: &lt;BROADCAST,NOARP&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000 4: tunl0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop state DOWN group default qlen 1000 5: sit0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop state DOWN group default qlen 1000 6: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000 改成 sudo ifconfig eth0 mtu 1350 或者 sudo ip link set eth0 mtu 1400 NPM 失败 安装 npm 后使用提示: /usr/bin/env: ‘bash\\r’: No such file or directory 相关问题及解决办法见: After installing npm on WSL sudo apt install nodejs npm 修改 /etc/wsl.conf sudo vim /etc/wsl.conf 复制下面的内容 [interop] appendWindowsPath = false 重启 wsl --shutdown wsl","categories":[],"tags":[{"name":"环境配置","slug":"环境配置","permalink":"https://luzhixing12345.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"}]},{"title":"使用hexo部署Github Pages网页","slug":"网站/hexo部署网页","date":"2022-09-19T16:53:46.000Z","updated":"2022-11-08T05:37:40.212Z","comments":true,"path":"2022/09/20/网站/hexo部署网页/","link":"","permalink":"https://luzhixing12345.github.io/2022/09/20/%E7%BD%91%E7%AB%99/hexo%E9%83%A8%E7%BD%B2%E7%BD%91%E9%A1%B5/","excerpt":"","text":"这篇博客讲一下如何给我们的GitHub仓库生成一个网页,我们可以利用GitHub pages,无需服务器的部署静态资源,通常来说是简单的功能js交互或者一些文档说明,都可以很好的使用这个方法 首先我们新建一个GitHub仓库,然后在主分支写一些源代码.这时候如果我们希望在网页端部署一些资源,给一个url地址可以让其他人查看,我们可以利用hexo快速部署 hexo 的安装很简单,安装nodejs之后一行命令就可以了,这里都比较基础就直接跳过了 npm install hexo-cli -g 通常来说一个仓库应该是main/master分支包含仓库对应的源代码,dev/debug分支用于测试/修改,gh-pages分支用于网页端文档的展示或是效果的展示 我个人的习惯的构建方式如下,即使用一个GitHub_pages目录单独保存所有的网页文档,源代码则在repo中改动,实现原仓库的代码和网页端的文章内容分开,方便管理 |--- Github_pages |--- C-libs |--- ... |--- repo |--- C-libs |--- ... 在GitHub_pages目录下使用hexo初始化一个文件夹 hexo init C-libs 安装必要的部署插件 cd C-libs npm install hexo-deployer-git --save 查看仓库所在的URL和仓库部署的对应的网站地址 这里可以看到所有的仓库是建立在你的github.io的域名之下的子目录 修改 _config.yml 需要修改两个地方,一个是url,一个是deploy的部分 url如果不修改的话hexo部署上去是没有主题样式的,因为css文件的的引用关系不正确. 虽然在本地使用 hexo server查看没有问题但是在GitHub网页端它的路径不一样,所以这里需要修改. deploy的修改则表示使用git部署,GitHub地址,对应的branch分支 # URL ## Set your site url here. For example, if you use GitHub Page, set url as &#x27;https://username.github.io/project&#x27; url: https://luzhixing12345.github.io/C-libs/ deploy: type: &#x27;git&#x27; repo: github: git@github.com:luzhixing12345/C-libs.git branch: gh-pages 通常来说我们会单独将仓库对应的网页部署在gh-pages这个分支下 上传 hexo clean hexo g -d 等待Github Action执行完毕打开链接即可浏览网页 上述的5步其实都是在命令行中就可以完成的,所以我们可以简单写一个脚本 我这里用的是C写的,其实什么语言都差不多,就是一些简单的命令行功能 复制如下代码,将 user_name 改为你的, local_GithubPages_URL 改为你的本机文件夹地址 编译之后得到exe文件,放到path目录下即可全局调用 gcc page.c -o page #include &lt;stdlib.h&gt; #include &lt;unistd.h&gt; #include &lt;stdio.h&gt; #define BUF_SIZE 1024 char buf[BUF_SIZE]; const char* user_name = &quot;luzhixing12345&quot;; // 你的用户名 char* local_GithubPages_URL = &quot;G:\\\\Github_pages&quot;; // 这里修改为你的本机文件夹地址 char* branch = &quot;gh-pages&quot;; char *getfileall(char *fname) &#123; FILE *fp; char *str; char txt[BUF_SIZE]; int filesize; //打开一个文件 if ((fp=fopen(fname,&quot;r&quot;))==NULL)&#123; printf(&quot;打开文件%s错误\\n&quot;,fname); return NULL; &#125; //将文件指针移到末尾 fseek(fp,0,SEEK_END); filesize = ftell(fp);//通过ftell函数获得指针到文件头的偏移字节数。 str=(char *)malloc(filesize);//动态分配str内存 str[0]=0;//字符串置空 rewind(fp); while((fgets(txt,BUF_SIZE,fp))!=NULL)&#123;//循环读取,如果没有数据则退出循环 strcat(str,txt);//拼接字符串 &#125; fclose(fp); return str; &#125; char *str_replace(char *orig, char *rep, char *with) &#123; char *result; // the return string char *ins; // the next insert point char *tmp; // varies int len_rep; // length of rep (the string to remove) int len_with; // length of with (the string to replace rep with) int len_front; // distance between rep and end of last rep int count; // number of replacements // sanity checks and initialization if (!orig || !rep) return NULL; len_rep = strlen(rep); if (len_rep == 0) return NULL; // empty rep causes infinite loop during count if (!with) with = &quot;&quot;; len_with = strlen(with); // count the number of replacements needed ins = orig; for (count = 0; tmp = strstr(ins, rep); ++count) &#123; ins = tmp + len_rep; &#125; tmp = result = malloc(strlen(orig) + (len_with - len_rep) * count + 1); if (!result) return NULL; while (count--) &#123; ins = strstr(orig, rep); len_front = ins - orig; tmp = strncpy(tmp, orig, len_front) + len_front; tmp = strcpy(tmp, with) + len_with; orig += len_front + len_rep; // move to next &quot;end of rep&quot; &#125; strcpy(tmp, orig); return result; &#125; int main(int argc, char *argv[]) &#123; // input format : git@github.com:luzhixing12345/C-libs.git char *total_lib_name = argv[1]; char *lib_name = total_lib_name + strlen(&quot;git@github.com:/&quot;) + strlen(user_name); lib_name[strlen(lib_name)-4] = &#x27;\\0&#x27;; chdir(local_GithubPages_URL); sprintf(buf,&quot;hexo init %s&quot;,lib_name); system(buf); sprintf(buf,&quot;%s\\\\%s&quot;,local_GithubPages_URL,lib_name); chdir(buf); system(&quot;npm install hexo-deployer-git --save&quot;); // printf(&quot;%s\\n&quot;, getcwd(s, 100)); char *str = getfileall(&quot;_config.yml&quot;); sprintf(buf,&quot;http://%s.github.io/%s/&quot;,user_name,lib_name); str = str_replace(str,&quot;http://example.com&quot;,buf); sprintf(buf,&quot;type: git\\n repo:\\n github: %s.git\\n branch: %s&quot;,total_lib_name,branch); str = str_replace(str,&quot;type: \\&#x27;\\&#x27;&quot;,buf); FILE *fp = fopen(&quot;_config.yml&quot;,&quot;w+&quot;); fputs(str,fp); fclose(fp); sprintf(buf,&quot;hexo g -d&quot;); system(buf); return 0; &#125; 这里其实username也可以通过popen拿到git config --global user.name 的返回值做到,不过没有这么做 这段代码就是实现了之前提到的一系列操作,自动把网页部署上去.需要传入一个参数argv[1]就是你的GitHub仓库的ssh地址,注意一定是ssh地址不是http的地址! page git@github.com:luzhixing12345/C-libs.git 注意到这里只是单纯的hexo init之后就直接部署上去了,所以看到的效果是最初始的hexo,这段代码也只是为了快速初始化一个页面.至于后续使用什么hexo主题,怎么写就是后面的事情了~ 相关使用视频可以查看TODO","categories":[],"tags":[{"name":"博客","slug":"博客","permalink":"https://luzhixing12345.github.io/tags/%E5%8D%9A%E5%AE%A2/"}]},{"title":"git常用命令","slug":"git/git常用命令","date":"2022-07-15T14:56:19.000Z","updated":"2023-02-21T15:06:59.619Z","comments":true,"path":"2022/07/15/git/git常用命令/","link":"","permalink":"https://luzhixing12345.github.io/2022/07/15/git/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"git常用命令 相关解释 : BRANCH_NAME : 分支的名字 默认远程仓库的地址名称为 origin 删除远程分支 git push origin --delete &#123;BRANCH_NAME&#125; 修改本地remote git remote set-url origin &#123;URL&#125; 删除本地分支 git checkout &#123;ANOTHER_BRANCH&#125; git branch -D &#123;BRANCH_NAME&#125; 分支重命名 git branch -m &#123;NEW_NAME&#125; 拉取远程仓库某一分支 git checkout -b &#123;BRANCH_NAME&#125; origin/&#123;BRANCH_NAME&#125; 拉取远程仓库某一分支到本地某一分支 git pull origin master:&#123;BRANCH_NAME&#125;","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://luzhixing12345.github.io/tags/git/"}]},{"title":"服务器的各项配置","slug":"服务器/服务器的各项配置","date":"2022-07-10T02:38:01.000Z","updated":"2023-03-13T08:50:09.301Z","comments":true,"path":"2022/07/10/服务器/服务器的各项配置/","link":"","permalink":"https://luzhixing12345.github.io/2022/07/10/%E6%9C%8D%E5%8A%A1%E5%99%A8/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%90%84%E9%A1%B9%E9%85%8D%E7%BD%AE/","excerpt":"","text":"本文以华为的云服务器为例,各大服务器平台基本流程类似.本文默认已经购买了一台服务器,并且完成了基本的操作系统搭建,具体可以参考本系列之前的两篇文章 服务器端口 如果你对服务器的基本端口/域名/端口号尚且不清楚,可以先阅读这篇科普文章,IP,域名和端口号之间的联系,我觉得说的还是清晰的 我们现在来运行一个服务吧,在/home/目录下新建一个project文件夹,新建 server.js文件并写入以下代码创建一个简单的nodejs的HTTP服务 const http = require(&#x27;http&#x27;); const server = http.createServer((req, res) =&gt; &#123; console.log(&quot;receive one connect&quot;); res.end(&#x27;hello world&#x27;) &#125;); server.listen(9000, () =&gt; &#123; console.log(&quot;start server&quot;) &#125;); 启动服务 node server.js 接着打开浏览器,输入 IP:9000 看一看吧 什么也没有? 这很正常,虽然服务在9000端口启动了,但是你访问不了,只有服务器本机可以访问. 那么外界如何访问这个服务呢,你需要手动开启这个服务 需要添加入方向规则和出方向规则,注意出入两条规则都需要添加,不然还是无法访问 我们开放9000端口,然后再次访问 IP:9000 很好,一个简单的hello world界面,并且在终端里也输出了receive one connect 但是你会发现终端被占用了,一旦你关闭了终端或者使用ctrl+c结束进程就再也无法访问了,我们总不可能持续的开启这个终端不关闭吧,我们还要做别的事情啊,我的电脑不可能像服务器一样一直不关机啊,所以我们需要把这个服务挂在后台 nohup node server.js &amp; nohup 就是不挂起的命令, &amp;代表运行在后台,我们也可以选择输出文件的名字,默认是nohup.txt,参考 现在我们可以在终端继续别的事情了,这个服务也会一直启动着不结束.你什么时候想访问都可以 如果想要结束这个服务怎么办呢? 可以使用命令查看所有进程 ps -ef 浏览一下所有进程,哦找了,node server.js, pid号是7964(这个自己看一下,每次都不一样,别杀错了) 也可以使用ps -ef | grep server.js 更加精确的搜索 kill 7964 这样这个进程就结束了,但是这种方法稍微有点笨. 毕竟还要手动找一下,我这里推荐两个可以帮助我们在后台使用服务的,pm2和forever,我个人推荐使用pm2,命令行的输出做的更加美观一些~ 安装 npm install -g pm2 pm2 start server.js // 启动 pm2 stop server.js // 停止 pm2 restart server.js // 重启 查看所有运行后台服务 pm2 list pm2 flush // 清除日志 也可以直接查看log日志 pm2 log // 查看所有运行后台服务 pm2 log 0 // 单独查看某一个的日志 可以直接通过id关闭服务 pm2 stop 0 forever的命令完全相同,把pm2换成forever就行了,使用起来差不多 服务器域名 现在我们可以启动一个服务了,但是似乎我们的访问方式有点老土,直接访问ip:端口号有点不专业,不好记也不方便. 正常都是直接访问一个网址的,这就需要域名的出场了.我们需要购买一个域名 这里推荐一个视频,对域名的讲解很全面,顶级域/一级二级域名都说的不错,这个视频系列也是很通俗易懂的理解服务的相关知识,建议看一下 华为云-域名注册,你可以在这里购买一个域名,可以选xyz top这样的顶级域,比较便宜 域名购买完成了之后不是直接就可以和服务器绑定使用的,在中国还需要进行IPC备案,各大云服务器厂商也都提供了备案方式,在哪里购买的域名就在哪里备案就可以,省得麻烦. 备案步骤比较繁琐,先有平台审核,然后管局审核,我的域名kamilu.top就是大约10多天才备案通过,不同地区的管局处理速度不同,一般都是十天左右 备案完成之后我们就可以进行域名的DNS解析了,华为云的解析文档说的很详细了,我就不再赘述 域名解析不生效文档 将域名映射到服务器之后,你就可以通过域名来替换你的IP地址了,这样刚才的服务就可以通过 域名:9000 来访问了 如果网站访问不了,也可以通过网站无法访问怎么办这篇文章来排查问题 C:\\Windows\\System32\\drivers\\etc -&gt; HOST文件 HTTPS的申请与二级域名 我们现在的连接是HTTP连接,我们最好使用HTTPS的连接,有了SSL的服务更加安全. 可以在华为云 HTTPS证书申请申请一个证书,很快也不复杂 个人用户没必要购买,可以直接使用免费的证书 购买之后会指引如何进行DNS解析,在SSL证书管理可以看到进度 DNS解析就是加一个_dnsauth的域名,选择TXT,输入值,这个也都有文档很详细的说明 对于二级域名同理,域名选择你的二级域名就可以了 不要忘记开启SSL服务哦,云服务器端口哪里的安全组可以快速添加,很方便 服务器端口反向代理 那么我们接下来把证书的部署和端口一起处理一下,平时似乎也没见过谁访问一个网址还要单独带一个端口号,最好我们直接就是输入一个网址就可以访问服务了,这里用到nginx的反向代理服务,可以把你的网址的访问映射到端口号的服务上 安装 sudo apt install nginx 后面的都需要root了, 启动Nginx服务 systemctl start nginx 安装之后你可以查看你的nginx的配置文件的位置 nginx -t 显示配置文件在/etc/nginx/nginx.conf,打开这个文件,然后配置你的服务 官网的nginx和我的不太一样,我看好多都是直接编译nginx的,我是一键下载,不过没啥大差别 下载你的证书,然后你可以看到一个nginx的子文件夹,里面有两个文件(crt | key) 在/etc/nginx/ 下新建一个cert文件夹用于保存证书文件,然后将nginx的两个证书ftp传入这个目录 关于conf的配置文件主要如下,http请求转换成https请求, 对于443端口(HTTPS默认是443端口请求)映射到location的位置,默认index.html文件 我给出我的配置文件 这里解释一下我的配置,kamilu.top是我的一级域名也就是我购买的,访问这个域名会被跳转到/home/cloud-server这个目录下的index.html文件,也就是我的主页. ssl_certificate和ssl_certificate_key就是证书的名字,改成你的 注意这里不要放在一个用户下面, css的显示会有问题 除此之外可以再申请一个HTTPS证书用于二级域名,二级域名不需要买,买了一级域名就可以使用旗下的所有二级域名,但是因为我们的HTTPS证书是免费的,所以所有的二级域名还是需要重新申请证书的,如果是泛域名的证书那么 *.kamilu.top 的二级域名都可以直接使用,不过那就要花钱了,也没必要 visual.kamilu.top 是我的申请的一个二级域名,它会被映射到我的3000端口的服务,也就是说访问https://visual.kamilu.top就相当于访问 https://kamilu.top:3000 内容加在http {} 大括号中间的位置就可以 events &#123; worker_connections 1024; ## Default: 1024 &#125; http &#123; server &#123; # 自动跳转到https listen 80; server_name kamilu.top; #将请求转成https rewrite ^(.*)$ https://$host$1 permanent; &#125; server &#123; listen 443 ssl; #配置HTTPS的默认访问端口为443。如果在此处未配置HTTPS的默认访问端口，可能会导致Nginx无法启动。 server_name kamilu.top; #修改为您证书绑定的域名。 ssl_certificate cert/scs1657261851237_kamilu.top_server.crt; #替换成您的证书文件的路径。 ssl_certificate_key cert/scs1657261851237_kamilu.top_server.key; #替换成您的私钥文件的路径。 ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; #加密套件。 ssl_prefer_server_ciphers on; location / &#123; root /home/cloud-server; #站点目录。 index index.html; #添加属性。 &#125; &#125; server &#123; listen 443 ssl; server_name visual.kamilu.top; ssl_certificate cert/scs1657282492078_visual.kamilu.top_server.crt; ssl_certificate_key cert/scs1657282492078_visual.kamilu.top_server.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / &#123; proxy_pass http://localhost:3000/; &#125; # modify the maximum file upload size client_max_body_size 2000m; # 如果有文件上传和下载功能需要注意修改为合适的值，默认为 1m &#125; &#125; 修改完成之后你可以使用nginx -t查看一下有没有配置文件错误,如果ok,successful的话重启一下nginx服务 nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful systemctl reload nginx 稍微等待一会儿,然后访问你的域名,不加任何端口号就可以看到主页了(如果你的这个目录下有东西的话),访问二级域名也可以看到了 注意要使用https访问 创建用户 adduser kamilu 将kamilu添加到sudo组： usermod -aG sudo kamilu sudo whoami","categories":[],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://luzhixing12345.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]},{"title":"服务器入门","slug":"服务器/服务器入门","date":"2022-06-13T17:39:19.000Z","updated":"2023-02-28T03:17:04.152Z","comments":true,"path":"2022/06/14/服务器/服务器入门/","link":"","permalink":"https://luzhixing12345.github.io/2022/06/14/%E6%9C%8D%E5%8A%A1%E5%99%A8/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%85%A5%E9%97%A8/","excerpt":"","text":"服务器的购买 如果你已经购买了一台服务器并且已经可以成功连接上服务器那么可以跳过这一部分 听起来服务器这个名字很厉害,总是听别人大谈特谈,一些专家技术骨干也是几句不离服务器,拥有一台服务器好像似乎是一件很酷的事情. 确实,拥有一台服务器可以实现很多有趣的功能,你可以通过https://kamilu.top访问我的网页,他目前还在建设当中,但你不觉得很酷吗? 那么我们废话不多说,直接开始吧~ 我个人是在腾讯云和华为云各购买了一台服务器,说是买其实就是租. 对于新用户来说很便宜,一般来说都会打折促销,几块钱十几块钱租几个月,花点小钱买一个试试看,玩一玩还是可以的 买/租服务器还是选大厂的比较好,阿里腾讯华为这种更值得信赖一些.刚开始价格比较低,但是后期几年之后那个租的价格就一下子上去了.我自己在华为云打折的时候买了一台一年的服务器185元,打的甚至是0.91折,而不是9.1折.强烈建议大家买服务器之前想好自己要用这台服务器干什么.我想做图床,做博客,那你这个年限不能短了,最好一次到位,不然年年续费一次比一次贵我就想玩玩,搞个小网站试试,那随意,新用户很便宜搞一台我有钱,那没事了 服务器也是五花八门,像腾讯云这种下面列了一排,新手的话压根不知道买什么. 初次购买也不用考虑那么多,差不多就行,通用性的.我买的是一个2核2GB 40GB SSD的轻量应用服务器,3个月18元 腾讯云这台服务器也就是实验性质的,随便玩玩,2022/9月就到期,我也不会续费 购买之后你就可以看到你的服务器了,一般会默认帮你安装操作系统,也是比较方便的.我选的是比较稳定的Debian 11.1 这里就涉及到第二个问题,怎么选择操作系统? 一般来说用服务器的都是懂计算机的,linux我就不必多说.自然也不需要图形化界面,centos和debian两个分支我觉得都可以,debian是公认的稳定性,centos,ubuntu这种社区环境会好很多,遇到了很多问题都能找到答案.这个差距其实不大,纠结这个毫无意义.要是不知道怎么选centos就完事了 腾讯云的网站会开启一个命令行的界面,安装完毕之后就可以正常使用了,不过我们肯定不是在它的官网上操作,毕竟还要肯定是要写代码传文件什么的,无论如何还是本地比较方便 腾讯云也提供了远程登陆的例子,首先创建一个密钥,把密钥保存在一个不会乱删的地方,服务器关机,然后绑定,重置密码等等 教程给的很详细,如果遇到什么问题了自己搜索解决,教程中给的是putty的例子,我比较习惯使用xshell,都可以,按照他的方式填写就可以了,顺利远程登录服务器 也可以通过SSH的方式直接连接,这种方式更加直接,而且vscode的ssh支持的非常舒适,我个人很喜欢. SSH连接和FTP传输 下面给出两种SSH连接方式,Xshell和Vscode + SSH,对于开发写代码来说使用第二种更为方便,当然你可以现在本地完成所有开发然后再使用FTP/SCP将文件传输上去运行 XSHELL 用户默认第一次 root , 密码就是你服务器的密码. 对于用户来说默认是root登录,如果你需要创建多个用户的话你可以使用adduser创建,如果只有你一个人用的话也没必要,最高权限开发也未尝不可,不过root用户登陆的默认入口是/root/目录,最好不要在root目录下存放所有文件信息,在/home/文件夹在 创建用户,赋予sudo权限的方式参考debian创建用户 Vscode + SSH 实际开发之中我倾向于使用Vscode远程开发,不得不说Vscode的SSH服务实在是香,很方便,Vscode界面还好看,有插件,真棒 默认安装了git,ssh等基本配置,这一步与github建立SSH连接是类似的,参考git的SSH连接 ssh-keygen -t rsa -C &quot;YOUR@EMAIL&quot; 将id_rsa.pub传入服务器,传入/root/目录下 以root用户登录 cat id_rsa.pub &gt;&gt; .ssh/authorized_keys service sshd restart 在进行本机ssh登录的时候就要求验证,选择yes认证之后就可以免密登录了 Vscode的环境就是使用远程资源管理器登录 由于过程比较简单,这里介绍的并不是很详细,推荐几个比较详细的配置流程,如果新手小白遇到了一些问题可以参考 https://zhuanlan.zhihu.com/p/68577071 https://www.cnblogs.com/huoyanCC/p/14730244.html FTP 用于大批量文件传输 这个也有不同的WinSCP/XFTP等等软件,我这里就直接推荐XFTP吧,我个人很喜欢 与Xshell类似的配置,完成之后就可以传入文件了.值得一提的是最高修改一下设置显示隐藏文件,必要情况下还是需要直接传入这些文件夹内的","categories":[],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://luzhixing12345.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]},{"title":"深度学习模型部署(2)-服务器与本地","slug":"python/深度学习模型部署-2","date":"2022-06-13T11:50:08.000Z","updated":"2023-01-08T05:18:48.623Z","comments":true,"path":"2022/06/13/python/深度学习模型部署-2/","link":"","permalink":"https://luzhixing12345.github.io/2022/06/13/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2-2/","excerpt":"","text":"既然是深度学习,那想必Python是主力开发语言了,这里我们暂时不考虑性能啊,响应啊,多线程高并发那么多,我们也不用什么java/c++写一个后台服务器,我们的任务就只是单纯的部署到服务器上,能用就行啊. 毕竟我都用python了,还要啥性能呢,对吧 那么,我们接下来就来使用以下python的一个库: flask flask入门 我们先来构建一个网页,和专业的的Web,Nodejs功能相似,python自然有很多类似的库可以实现对应的功能,我们可以使用python的flask库来构建页面和 flask的中文文档比较全面,从快速上手到开发一应俱全,入门到入土可以说是一条龙,不过这并不是我们现在的重点 安装: pip install flask 新建文件app.py,复制以下代码 from flask import Flask app = Flask(__name__) @app.route(&#x27;/&#x27;) def hello_world(): return &#x27;Hello World!&#x27; if __name__ == &#x27;__main__&#x27;: app.run() 运行,你可以看到如下结果 python app.py 按住ctrl左键点击链接即可跳入对应网址,或者在浏览器中输入 http://127.0.0.1:5000 打开浏览器,很好,我们看到了一个简单的hello world 有可能会在运行时报错 cannot import name 'soft_unicode' from 'markupsafe' flask,那是因为你的pip版本老了,你可以uninstall flask然后升级pip重新下一个,或者升级markupsafepip install markupsafe flask进阶 那么,这些代码是什么意思呢 首先我们导入了 Flask 类。该类的实例将会成为我们的 WSGI 应用 接着我们创建一个该类的实例。第一个参数是应用模块或者包的名称。 __name__ 是一个适用于大多数情况的快捷方式。有了这个参数, Flask 才能知道在哪里可以找到模板和静态文件等东西 然后我们使用 route() 装饰器来告诉 Flask 触发函数 的 URL 函数返回需要在用户浏览器中显示的信息。默认的内容类型是 HTML ,因此字 符串中的 HTML 会被浏览器渲染 一头雾水,没关系,能用就行,python的库不都是这样么,(笑) 值得一提的是除了python运行文件启动之外,我们还可以使用如下命令启动服务flask runflask run提供了更多命令行可选参数flask run --help如果电脑本机5000端口被占用了,那么也可以更换端口flask run --port=5500但是需要注意这种情况下如果文件名为 app.py 或者 wsgi.py ,那么不需要设置 FLASK_APP 环境变量,否则需要配置一下环境变量,以(hello.py为例)set FLASK_APP=hello flask run关于flask run 和 python .py的区别,请阅读这里 当然,没有必要一定是使用flask run,我们仍然使用python.exe执行文件即可,但是在实际服务器部署上的时候还是需要依靠flask的服务,也就是说并不能将一些预先的函数写在if __name__ == &quot;__main__&quot; 里,还是要写在整个python文件中处理,因为flask run是不会走这条分支的 通过调用run()方法启动Flask应用程序。但是,当应用程序正在开发中时,应该为代码中的每个更改手动重新启动它。为避免这种不便,请启用调试支持。 你可能会感到奇怪,服务器呢? 127.0.0.1这不本机么?只有我电脑是可以使用服务,换个别的电脑肯定就不行了啊 没错,本篇文章的标题就是服务器与本地,所谓不要一口吃个胖子,渐进式的学习是有好处的,而且现在的代码只要稍作修改就可以放到服务器上了,我将会在下一节介绍如何在真正的服务器上搭建可以别所有人访问到的网站,并且将我们的模型部署上去 好,那我们再来进阶一步,现在页面显示的实在是有点糟糕,一个极其简陋的 hello world,我们能不能美化一下啊? 我们能不能搞一点触发事件? 一些CSS/JS? — 当然可以,我们可以得到这样的效果 将app.py修改为 from flask import render_template from flask import Flask app = Flask(__name__) @app.route(&#x27;/&#x27;) def index(): return render_template(&#x27;index.html&#x27;) if __name__ == &#x27;__main__&#x27;: app.run(debug = True) 新建文件夹 templates,static 注意这两个文件夹是必建的,不只是为了模块化区分,静态网页部署需要这两个文件夹 新建&quot;templates/index.html&quot;,复制以下内容 &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;Document&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;../static/index.css&quot;&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css&quot;&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&quot;inputBox&quot;&gt; &lt;input type=&quot;text&quot; required=&quot;required&quot; id=&quot;first_name&quot;&gt; &lt;span&gt;First Name&lt;/span&gt; &lt;/div&gt; &lt;div class=&quot;inputBox&quot;&gt; &lt;input type=&quot;text&quot; required=&quot;required&quot; id=&quot;last_name&quot;&gt; &lt;span&gt;Last Name&lt;/span&gt; &lt;/div&gt; &lt;div&gt; &lt;button onclick=&quot;getInputValue()&quot; class=&quot;custom-btn btn-style&quot;&gt;Submit&lt;/button&gt; &lt;/div&gt; &lt;script src=&quot;../static/index.js&quot;&gt;&lt;/script&gt; &lt;/body&gt; &lt;/html&gt; 新建&quot;static/index.css&quot;,复制以下内容 @import url(&#x27;http://fonts.googleapis.com/css?family=Poppins:400,500,600,700&amp;display=swap&#x27;); * &#123; margin: 0; padding: 0; box-sizing: border-box; font-family: &quot;Poppins&quot;, sans-serif; &#125; body &#123; display: flex; justify-content: center; align-items: center; min-height: 100vh; flex-direction: column; gap: 30px; background-image: linear-gradient(to right, #f6d365 0%, #fda085 100%); &#125; .inputBox &#123; position: relative; width: 250px; &#125; .inputBox input &#123; width: 100%; padding: 10px; border: 1px solid rgba(255, 255, 255, 0.25); background: rgba(255, 255, 255, 0.25); border-radius: 5px; outline: none; color: #fff; font-size: 1em; transition: 0.5s; &#125; .inputBox span &#123; position: absolute; left: 0; padding: 10px; pointer-events: none; font-size: 1em; color: rgba(255, 255, 255, 0.25); text-transform: uppercase; transition: 0.5s; &#125; .inputBox input:valid ~ span, .inputBox input:focus ~ span &#123; color: #00dfc4; transform: translateX(10px) translateY(-7px); font-size: 0.65em; padding: 0 10px; background-image: linear-gradient(to right, #f6d365 0%, #fda085 100%); border-left: 1px solid #00dfc4; border-right: 1px solid #00dfc4; letter-spacing: 0.2em; &#125; /* .inputBox:nth-child(2) input:valid ~ span, .inputBox:nth-child(2) input:focus ~ span &#123; background: #00dfc4; color: rgba(255, 255, 255, 0.25); border-radius: 2px; &#125; */ .inputBox input:valid, .inputBox input:focus &#123; border: 1px solid #00dfc4; &#125; .custom-btn &#123; width: 130px; height: 40px; color: #fff; border-radius: 5px; padding: 10px 25px; font-family: &quot;Lato&quot;, sans-serif; font-weight: 500; background: transparent; cursor: pointer; transition: all 0.3s ease; position: relative; display: inline-block; box-shadow: inset 2px 2px 2px 0px rgba(255, 255, 255, 0.5), 7px 7px 20px 0px rgba(0, 0, 0, 0.1), 4px 4px 5px 0px rgba(0, 0, 0, 0.1); outline: none; &#125; .btn-style &#123; border: none; color: #000; &#125; .btn-style:after &#123; position: absolute; content: &quot;&quot;; width: 0; height: 100%; top: 0; left: 0; direction: rtl; z-index: -1; box-shadow: -7px -7px 20px 0px #fff9, -4px -4px 5px 0px #fff9, 7px 7px 20px 0px #0002, 4px 4px 5px 0px #0001; transition: all 0.3s ease; &#125; .btn-style:hover &#123; color: #000; &#125; .btn-style:hover:after &#123; left: auto; right: 0; width: 100%; &#125; .btn-style:active &#123; top: 2px; &#125; 新建&quot;static/index.js&quot;,复制以下内容 function getInputValue()&#123; var first_name = document.getElementById(&quot;first_name&quot;).value; var last_name = document.getElementById(&quot;last_name&quot;).value; alert(&quot;Hello &quot; + first_name + &quot; &quot; + last_name); &#125; 重新运行python app.py , 打开浏览器尝试一下吧~ flask精通 好了,你已经是flask大师了,快去做一个像样的网页吧.我的链接传送门 flask还是有很多比较复杂的地方没有去讲,包括重定向,py和js之间的数据传输,我推荐一个教程网站,我个人认为说的还是很详细的,推荐感兴趣的朋友去看一下. 当然如果遇到py和js之间的数据传输的问题,我建议去看一下我的这个网站的源代码,ajax固然可以发送POST请求但是无法再实现网页的刷新即render_template一个新的页面,这令我很头大,具体的解决方法就是在div标签中加入数据项进行python-&gt;js文件的数据传入,从js传出python就还是要利用form表单的onsubmit. 我在这个项目中遇到并且解决了一些问题,可以去浏览一下代码 关于前端的网页编写,那基本就是看个人的html+css+js的能力了,我前端的本身水平不高,这个仓库有我的一些记录的例子,感兴趣的话可以参考一下 flask入土 这么快就入土了? -确实 运行服务器后,会发现只有您自己的电脑可以使用服务,而网络中的其他电脑却不行。默认的设置就是这样的,因为在调试模式下该应用的用户可以执行您电脑中 的任意 Python 代码。 如果您关闭了调试器或信任您网络中的用户,那么可以让服务器被公开访问。 只要在命令行上简单的加上 --host=0.0.0.0 即可: 但是我们之前提到过需要在服务器运行,所以如果你写好了app.py的话那么运行的话就是 flask run --host=0.0.0.0 --port=3000 但是这样的话还是不行,因为它需要保证你的终端是开启的,一旦你关闭终端这个进程就会被杀死,所以我们需要将这个进程挂在后台 nohup flask run --host=0.0.0.0 --port=3000 2&gt;&amp;1 &amp; 如果要结束这个进程的话就去查找它的PID号然后杀死他 ps -ef kill PID 关于服务器的部署,我会把这部分的内容放到服务器的目录下方,如果你对服务器的网页搭建,IP端口访问,HTTPS连接的建立尚且不熟悉可以参考我的文章 到此为止我们的客户端/移动端访问网页的任务已经完成啦,值的一提的是服务器并不一定有GPU,所以在运行深度学习项目的时候算起来会有一点点慢,当然如果有财力的话可以直接购买GPU的服务器,对于一般的用户我们也就退而求其次设置一下CPU不是CUDA就完事了,但是不要忘记模型加载的时候也会需要一个map_location=torch.device('cpu') 如果不知道在哪里写的话运行的时候会有报错,按照说明改一下就可以了","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://luzhixing12345.github.io/tags/python/"}]},{"title":"深度学习模型部署(1)-前言及基本介绍","slug":"python/深度学习模型部署-1","date":"2022-06-13T08:12:34.000Z","updated":"2023-01-08T05:18:42.320Z","comments":true,"path":"2022/06/13/python/深度学习模型部署-1/","link":"","permalink":"https://luzhixing12345.github.io/2022/06/13/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2-1/","excerpt":"","text":"本系列以pytorch为例,其他框架请移步别处. 前言 深度学习的教程很多,网上也有很多现成的简单的模型训练的例子和预训练模型,然而在实际的工业场景中,我们往往更加关注如何部署一个已经训练好的模型. 我们希望可以客户端/移动端访问网页就可以看到模型的效果,计算由服务器帮我们处理. 我们希望在一个没有python环境的地方依然可以执行模型的效果 我们希望加速模型的计算,python换成c++提高计算性能 本系列关注的是: 如何将一个深度学习模型部署到服务器,并且可以通过网页的方式呈现效果 如何利用前向推理框架生成不依赖python环境的exe可执行文件 基本介绍 笔者假定读者已经训练了一个神经网络模型,并且对python/pytorch有一定了解,并且对c++的编写有一定了解,对html/css/javascript有基本了解 作为教程/学习记录,笔者提供了较为基础的网页代码和较为基础的c++/python代码,以供学习使用. 本系列所有的代码都可以在pytorch模型部署仓库中找到,请留意对应分支和博客的内容 希望这个系列可以对你有所帮助,那我们开始吧~ 参考 https://zhuanlan.zhihu.com/p/35879835 https://github.com/lxztju/pytorch_classification https://www.w3cschool.cn/flask/ https://flask.palletsprojects.com/en/2.1.x/","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://luzhixing12345.github.io/tags/python/"}]},{"title":"GAN网络详解(四) - 使用WGAN生成动漫头像","slug":"GAN/GAN网络详解(四)","date":"2022-05-19T09:38:22.000Z","updated":"2022-05-24T13:21:33.325Z","comments":true,"path":"2022/05/19/GAN/GAN网络详解(四)/","link":"","permalink":"https://luzhixing12345.github.io/2022/05/19/GAN/GAN%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3(%E5%9B%9B)/","excerpt":"","text":"本文将会介绍一个我的项目,使用WGAN-GP生成动漫头像. 项目地址: Github-Anime-WGAN 简介 其实这个项目的起因很简单,就是想动手实践一下,顺着GAN往下学就到了WGAN-GP,然后就搜了搜代码找了一个很不错的项目跟着改了改,然后完成了这次任务 关于具体的训练细节,实验结果,潜在空间探索等等内容我都在项目的README里面写的很详细了,这里不再赘述,主要想讲一讲一些细节的部分 有关模型 DCGAN,WGAN模型都继承了BasicGAN,所有的函数定义,基本实现什么的也都放在了这里,子类专注于重载train方法就可以了 最开始我尝试了DCGAN来训练,遇到了经典的 mode collapse问题, 详见之前的文章.于是我调查了一些原因,最后选择使用WGAN-GP来跑 最开始的我找的两个数据集都是96x96的,然后我改了改模型的结构,输出了一份64x64的动漫头像 这是一些比较好的结果,看起来还不错 然后我就想扩大这个图像的分辨率,变成256x256的,然后我就想找一个数据集256x256像素的,但是没找到.然后我索性就直接搞了爬虫去自己爬,然后动漫人脸识别,然后再剔除不好的样本,前前后后搞了好长好长时间,数据集在这里,结果第二天我就找到了一个512x512的数据集,更大,更好,真的不知道说啥了… 接下来就是该模型,于是我就照葫芦画瓢呗,改一个256x256的,但是马上就出了问题 首先就是来的一个问题,模型太大了,连续的卷积这个维度太高了,爆显存了.于是我又调整维度,又去改batch size,最后好不容易可以正常训练了. 然后又马上来了一个更致命的问题,生成的图像及其诡异,具有非常明显的诡异色块?这我也没改啥啊? 于是我赶紧去调查了一下,发现了这其实是一个转置卷积操作带来的问题 : 棋盘效应 反卷积有许多解释和不同的名称,包括“转置卷积” 关于这个问题,这篇文章其实已经探讨的非常详细了问题就是出在这个转置卷积的操作 nn.ConvTranspose2d.当我们让神经网络生成图像时,我们经常让它们从低分辨率、高级描述中构建图像。这允许网络描述粗略的图像,然后生成详细图像为了做到这一点,我们需要一些方法来从较低分辨率的图像到较高的图像。我们通常使用反卷积运算来执行此操作。粗略地说,反卷积层允许模型使用小图像中的每个点在较大的图像中“绘制”正方形不幸的是,反卷积很容易产生“不均匀的重叠”,在某些地方比在其他地方放置更多的隐喻颜料。特别是,当内核大小（输出窗口大小）不能被步幅（顶部点之间的间距）整除时,反卷积具有不均匀的重叠。虽然原则上,网络可以仔细学习权重以避免这种情况,但实际上神经网络很难完全避免它 一个更加直观的例子 现在,神经网络在创建图像时通常使用多层反卷积,从一系列较低分辨率的描述中迭代构建更大的图像。虽然这些堆叠的反卷积可以抵消伪像,但它们通常会复合,从而在各种尺度上创建伪影 一种方法是将上采样从卷积分离到更高的分辨率,以计算特征。例如,您可以调整图像大小（使用最近邻插值或双线性插值）,然后执行卷积层。这似乎是一种自然的方法,并且大致类似的方法在图像超分辨率 这就是我为什么又给64x64的模型补做了WGANP,它的改变就是将 nn.ConvTranspose2d 调整为 nn.Unsample + nn.Conv2d 虽然在64x64的并不明显,但是要是在256x256里使用反卷积这种棋盘效应会及其明显,很遗憾我并没有保留当时的图片,现在也找不到了,不过确实及其明显 后来我改成了上采样+卷积仍然效果不好,依然很差很差,于是我又去找了找其他的论文,发现了一个论文也是做这个动漫头像生成的,但是这个论文比较早了,更新的论文我也没有去调研,有点懒得搞了. 这个论文还给了一个可以直接在线体验的网站: https://make.girls.moe/#/ , 感觉还是挺好的,虽然有时候头发颜色白色生成的不是很好(老白毛控了) 然后我就去学这篇论文的架构,它用了残差的思想,所以我也加了残差连接,结果还是不理想,现在大概是长成这样 后来我就懒得搞了,搞一个64x64得了,一下子扩展维度这个怕是有点困难,也许小模型还凑活看看大模型就不太好使了 有关评价指标可以参考文章","categories":[],"tags":[{"name":"GAN","slug":"GAN","permalink":"https://luzhixing12345.github.io/tags/GAN/"}]},{"title":"vscode基本配置","slug":"杂/vscode基本配置","date":"2022-05-18T19:14:31.000Z","updated":"2023-03-24T13:01:35.502Z","comments":true,"path":"2022/05/19/杂/vscode基本配置/","link":"","permalink":"https://luzhixing12345.github.io/2022/05/19/%E6%9D%82/vscode%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/","excerpt":"","text":"添加snipplet 在settings.json中添加如下设置启用markdown的snippets &quot;[markdown]&quot;: &#123; &quot;editor.formatOnSave&quot;: true, &quot;editor.renderWhitespace&quot;: &quot;all&quot;, &quot;editor.quickSuggestions&quot;: &#123; &quot;other&quot;: true, &quot;comments&quot;: true, &quot;strings&quot;: true &#125;, &quot;editor.acceptSuggestionOnEnter&quot;: &quot;on&quot; &#125;, 我的基本markdown快捷键配置 &#123; &quot;create table&quot;: &#123; &quot;prefix&quot;: &quot;table&quot;, &quot;body&quot;: [ &quot;|$1|$2|&quot;, &quot;|:--:|:--:|&quot;, &quot;|||&quot; ], &quot;description&quot;: &quot;create table in markdown&quot; &#125;, &quot;create code snippet&quot;:&#123; &quot;prefix&quot;: &quot;code&quot;, &quot;body&quot;: [ &quot;```$1&quot;, &quot;&quot;, &quot;```&quot; ], &quot;description&quot;: &quot;create code snippet&quot; &#125;, &quot;create note info in my blog&quot;:&#123; &quot;prefix&quot;: &quot;info&quot;, &quot;body&quot;: [ &quot;&#123;% note info %&#125;&quot;, &quot;$1&quot;, &quot;&#123;% endnote %&#125;&quot; ] &#125;, &quot;create note success in my blog&quot;:&#123; &quot;prefix&quot;: &quot;suc&quot;, &quot;body&quot;: [ &quot;&#123;% note success %&#125;&quot;, &quot;$1&quot;, &quot;&#123;% endnote %&#125;&quot; ] &#125;, &quot;create note warning in my blog&quot;:&#123; &quot;prefix&quot;: &quot;warn&quot;, &quot;body&quot;: [ &quot;&#123;% note warning %&#125;&quot;, &quot;$1&quot;, &quot;&#123;% endnote %&#125;&quot; ] &#125; &#125; 安装clangd vscode扩展,搜索clangd,安装. 右下角弹出提示下载clangd,点击确定即可 官网的地址在 https://clangd.llvm.org/, 如果没有代理可以根据系统参考文档下载release 如果文件中使用了部分头文件,添加方法为: 新建.vscode/settings.json 其中 -I + 头文件目录即可, 编译的参数可以在这里指定. 如果gcc版本低可以使用指定使用clang编译器 如果不需要c++17标准不需要加入-std=c++17 &#123; &quot;clangd.fallbackFlags&quot;: [ &quot;-I/root/X86&quot;, &quot;-std=c++17&quot; ], &quot;clangd.arguments&quot;: [ &quot;--query-driver=/usr/bin/clang++&quot;, // 使用clang编译 &quot;--background-index&quot;, // 在后台自动分析文件（基于complie_commands) &quot;-j=12&quot;, // 同时开启的任务数量 &quot;--clang-tidy&quot;, // clang-tidy功能 &quot;--clang-tidy-checks=performance-*,bugprone-*&quot;, &quot;--all-scopes-completion&quot;, // 全局补全（会自动补充头文件） &quot;--completion-style=detailed&quot;, // 更详细的补全内容 &quot;--header-insertion=iwyu&quot; // 补充头文件的形式 ] &#125; 重启即可 clang-format sudo apt install clang-format clang-format -style=Google -i main.c 使用clang-format -h 查看所有style https://blog.csdn.net/softimite_zifeng/article/details/78357898 下面贴一个我自己比较喜欢的clang-format BasedOnStyle: Google IndentWidth: 4 AllowShortFunctionsOnASingleLine: None AllowShortBlocksOnASingleLine: Never AllowShortIfStatementsOnASingleLine: false BraceWrapping: AfterFunction: true AfterClass: true AfterControlStatement: false SplitEmptyFunction: false SplitEmptyRecord: false SplitEmptyNamespace: false BeforeCatch: true BeforeElse: true IndentBraces: true AfterFor: true 使用snippets屏蔽推荐词,并且使snippet的推荐置顶 &#123; &quot;editor.wordBasedSuggestions&quot;: false, &quot;editor.snippetSuggestions&quot;: &quot;top&quot; &#125; VS Code加载 Web 视图时出错 解决办法 code --no-sandbox","categories":[],"tags":[{"name":"杂","slug":"杂","permalink":"https://luzhixing12345.github.io/tags/%E6%9D%82/"}]},{"title":"GAN网络详解(三) - WGAN-CP 与 WGAN-GP","slug":"GAN/GAN网络详解(三)","date":"2022-05-18T15:08:13.000Z","updated":"2022-05-19T10:57:29.470Z","comments":true,"path":"2022/05/18/GAN/GAN网络详解(三)/","link":"","permalink":"https://luzhixing12345.github.io/2022/05/18/GAN/GAN%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3(%E4%B8%89)/","excerpt":"","text":"本文将会介绍WGAN-CP和它的改进版本WGAN-GP WGAN-CP 参考文章GAN到WGAN,作者连续五篇文章非常详尽的分析了WGAN,读完之后受益匪浅 鉴于GAN网络存在的种种问题,那么我们应该寻求一个新的距离来替代JS.该文认为需要对“生成分布与真实分布之间的距离”探索一种更合适的度量方法。作者们把眼光转向了Earth-Mover距离,简称EM距离,又称Wasserstein距离 W距离是最优传输（Optimal Transportation）理论中的关键概念,而最优传输及W距离的场景可以用一个非常的简单实际问题来描述：有一座土山,需要把它搬运到另外一个地方堆积成一座新的土山,要求整个过程中土的总质量不能改变。最优传输问题即在诸多的运土方案中,寻找代价最小的那个方案,而W距离指的就是这个最小代价W距离也拥有一个非常形象的“花名”——“推土机距离”（Earth Mover’s Distance） 那么什么是最优传输的传输计划和传输代价呢? 下面以一个简单的挪箱子问题作为示例,黄色箱堆为P,需要将其挪动为虚线框所示的样子。我们这样定义代价：挪动每个箱子的代价为该箱子的质量与位移的乘积,那么传输代价为挪动所有箱子代价的总和. 假设每个箱子质量相同,现在我们想让P状态下所有的黄色箱子挪到虚线中(状态Q),最小的传输代价是多少呢? 最终的Q状态有三个位置,也就是说最终有3!种移动方法,由于所有箱子质量相同,故可以分为两种计划 这里我们以下标01234来代指计划移动的方式A计划就是将一个0位置的方块移动到1位置,然后将0,4两个位置的方块移动到3B计划就是将两个0位置的方块移动到3位置,然后将4位置的一个方块移动到1对于A计划传输代价为 1+3+1 = 5对于B计划传输代价为 3x2+3 = 9这样我们就完成了从P到Q的状态转移,完成了一次传输.显而易见,A传输计划的传输代价最小,故上述例子的W距离为5 传输计划可以很方便的用矩阵形式表示,即“传输矩阵”。给定一个“运输计划”,即可确定一个矩阵γ\\gammaγ,其元素γ(xp,xq)\\gamma(x_p,x_q)γ(xp​,xq​),表示从P中xpx_pxp​位置“运输”到Q中xqx_qxq​位置的“土量” 以上面挪箱子的问题为例,其中A、B计划对应的传输矩阵分别为 其中对应位置的数字表示移动了几个方块,代价计算的方式就是x y的差值乘数字对于A, costA=∣0−1∣×1+∣0−3∣×1+∣4−3∣×1=5cost_A = |0-1|\\times 1 + |0-3|\\times 1+|4-3|\\times 1 = 5costA​=∣0−1∣×1+∣0−3∣×1+∣4−3∣×1=5对于B, costB=∣0−3∣×2+∣4−1∣×1=9cost_B = |0-3|\\times 2 + |4-1|\\times 1 = 9costB​=∣0−3∣×2+∣4−1∣×1=9 所以可以得到总传输矩阵为 B(γ)=∑xp,xqγ(xp,xq)∣∣xp−xq∣∣B(\\gamma) = \\sum\\limits_{x_p,x_q}\\gamma(x_p,x_q)||x_p -x_q|| B(γ)=xp​,xq​∑​γ(xp​,xq​)∣∣xp​−xq​∣∣ 所以我们要求得的最小代价也就是 W(P,Q)=min⁡γ∈∏B(γ)W(P,Q) = \\min\\limits_{\\gamma\\in\\prod} B(\\gamma)W(P,Q)=γ∈∏min​B(γ) 所以可以很容易看出,只要获得最优传输矩阵,对应的W距离就可以很容易的计算得到 所以对于两个分布P,Q,他的传输矩阵其实表达了一个联合分布 艰难的回忆起概率论的知识… pg,prp_g,p_rpg​,pr​对应的边缘分布为 pg(xg)=∫xrγ(xg,xr)dxrpr(xr)=∫xgγ(xg,xr)dxgp_g(x^g) = \\int_{x^r}\\gamma(x^g,x^r)dx^r\\\\ p_r(x^r) = \\int_{x^g}\\gamma(x^g,x^r)dx^g pg​(xg)=∫xr​γ(xg,xr)dxrpr​(xr)=∫xg​γ(xg,xr)dxg 所以我们转换一下上述的B(γ)B(\\gamma)B(γ),可以得到 W(pg,pr)=inf⁡γ∈∏∬xg,xrγ(xg,xr)∣∣xg,xr∣∣dxgdxrW(p_g,p_r) = \\inf_{\\gamma\\in\\prod}\\iint_{x^g,x^r}\\gamma(x^g,x^r)||x^g,x^r||dx^gdx^r W(pg​,pr​)=γ∈∏inf​∬xg,xr​γ(xg,xr)∣∣xg,xr∣∣dxgdxr 其中γ(xg,xr)\\gamma(x^g,x^r)γ(xg,xr)是一个联合分布,∣∣xg,xr∣∣||x^g,x^r||∣∣xg,xr∣∣为随机变量的函数,这个公式又可以用数学期望来化简,于是我们用一个非常简洁的期望表达式来表示W距离 W(pg,pr)=inf⁡γ∈∏E(xg,xr)∼γ∣∣xg,xr∣∣W(p_g,p_r) = \\inf_{\\gamma\\in\\prod}E_{(x^g,x^r)\\thicksim\\gamma}||x^g,x^r|| W(pg​,pr​)=γ∈∏inf​E(xg,xr)∼γ​∣∣xg,xr∣∣ 这便是最终的Wasserstein距离的表达式由来,这种方式要比直接看定义要好理解的很多. 从上面的推导我们可以很容易的看出,以W距离作为分布之间相似性度量很不错,概括起来有以下三条优点: 交换性：W(pg,pr)=W(pr,pg)W(p_g,p_r) = W(p_r,p_g)W(pg​,pr​)=W(pr​,pg​)这一点比KL散度强多了 非负性：W(pg,pr)&gt;0W(p_g,p_r)&gt;0W(pg​,pr​)&gt;0,当pg=prp_g=p_rpg​=pr​时,W(pg,pr)=0W(p_g,p_r)=0W(pg​,pr​)=0,原地不动自然不用耗费体力 指标性：当Dist(pg,pr)&gt;Dist(pg′,pr′)Dist(p_g,p_r)&gt;Dist(p_{g&#x27;},p_{r&#x27;})Dist(pg​,pr​)&gt;Dist(pg′​,pr′​)时,W(pg,pr)&gt;W(pg′,pr′)W(p_g,p_r)&gt;W(p_{g&#x27;},p_{r&#x27;})W(pg​,pr​)&gt;W(pg′​,pr′​),这正是散度的“软肋”啊.距离与代价正相关很有利于训练,计算梯度 Wasserstein距离相比KL散度、JS散度的优越性在于,即便两个分布没有重叠,Wasserstein距离仍然能够反映它们的远近 KL散度和JS散度是突变的,要么最大要么最小,Wasserstein距离却是平滑的,如果我们要用梯度下降法优化θ\\thetaθ这个参数,前两者根本提供不了梯度,Wasserstein距离却可以。类似地,在高维空间中如果两个分布不重叠或者重叠部分可忽略,则KL和JS既反映不了远近,也提供不了梯度,但是Wasserstein却可以提供有意义的梯度。 看起来Wasserstein距离是一个挺不错的距离啊!但是它的缺点也是直观的,这就是太难算！直观上看我们要将所有可能的联合分布试一遍才能找到那个使得代价最小的分布.况且WGAN其实也并不是要求这个距离是多少,首先是基于线性规划的W距离在针对多状态高维数据的计算几乎不可能实现,100维,1000维,这种计算量实在是太可怕了. 如果想要了解如何快速计算两个分布的W距离,我们可以使用线性规划（Linear Programming）的方式先求解最优传输矩阵,最优传输矩阵一旦获得,W距离的计算也就易如反掌。参考https://zhuanlan.zhihu.com/p/358330515 求距离不是我们的目的,我们真正想要的是使得W距离取得最小的那个pgp_gpg​,我们不是求最小值,我们是求下确界 求下确界而不是最小值是因为最小值并不一定存在,例如某些渐进的函数 exe^xex诸如此类 所以现在的问题是我们要求的不是W,而是他的约束条件pgp_gpg​,这怎么求? 这一部分的数学推导十分复杂,作者也用了很严密的数学证明,其中涉及的公式证明较多,主要利用了对偶线性规划求解W距离,1-利普希茨连续条件(1-L)等方法.笔者自知数学功底较差,也并不指望能够给读者完整的解释清楚有兴趣的话可以去阅读一下原论文附录中的证明过程,或者浏览对偶线性规划与W-GAN,十分详尽 简而言之,我们得到了最终的结论 W(pg,pr)=sup⁡f∈1−LipschitzEx∼pr(x)[f(x)]−Ex∼pg(x)[f(x)]W(p_g,p_r) = \\sup\\limits_{f\\in 1-Lipschitz}E_{x\\thicksim p_r(x)}[f(x)]-E_{x\\thicksim p_g(x)}[f(x)] W(pg​,pr​)=f∈1−Lipschitzsup​Ex∼pr​(x)​[f(x)]−Ex∼pg​(x)​[f(x)] 其中 1-Lipschits 是1-利普希茨连续条件（Lipschitz continuity）K-普希茨连续条件的定义是,对于任意的xi,xh∈Rnx_i,x_h\\in R^nxi​,xh​∈Rn,都存在常数K使得∣f(xi)−f(xj)∣≤1K∣∣xi−xj∣∣|f(x_i)-f(x_j)|\\le 1K||x_i-x_j||∣f(xi​)−f(xj​)∣≤1K∣∣xi​−xj​∣∣直白一点说就是约束了这个函数f(x)的梯度,不能超过K这个值.1-L就是所有点的梯度不能超过1 上式中f满足1−利普希茨条件。若其满足K−利普希茨条件,则得到的距离为K⋅W(pg,pr)K\\cdot W(p_g,p_r)K⋅W(pg​,pr​) 假设有一族满足K-利普希茨条件的参数化函数fwf_wfw​,我们可以得到一个近似的表示 K⋅W(pg,pr)≈sup⁡f∈1−−LipschitzEx∼pr(x)[fw(x)]−Ex∼pg(x)[fw(x)]K\\cdot W(p_g,p_r) \\approx \\sup\\limits_{f\\in 1--Lipschitz}E_{x\\thicksim p_r(x)}[f_w(x)]-E_{x\\thicksim p_g(x)}[f_w(x)] K⋅W(pg​,pr​)≈f∈1−−Lipschitzsup​Ex∼pr​(x)​[fw​(x)]−Ex∼pg​(x)​[fw​(x)] W-GAN即将上式中的fw(x)f_w(x)fw​(x)构造为一个参数为www神经网络结构,由于神经网络的拟合能力足够强大,我们有理由相信,这样定义出来的一系列fw(x)f_w(x)fw​(x)虽然无法囊括所有可能,但是也足以高度近似公式要求的限制 f∈1−Lipschitzf\\in 1-Lipschitzf∈1−Lipschitz 这里的 f 应该满足以下两个条件 第一,fw(x)f_w(x)fw​(x)需要表达距离,而不是概率,所以不能像标准GAN中判别器那样输出概率了。不过这好办,只要在在网络最后的位置不使用Sigmoid激活函数即可 第二,fw(x)f_w(x)fw​(x)要满足K-利普希茨条件.我们要的并非距离本身,我们后续是要最小化这个距离,因此到K取多少都无所谓,只要要求fw(x)f_w(x)fw​(x)不要“跑飞”即可.因此在W-GAN中,使用了一种简单的权重裁剪（weight clipping）策略 即将fw(x)f_w(x)fw​(x)中的参数www限定在一个给定的范围 [−c,c][-c,c][−c,c] 之内.权重裁剪的出发点很简单：输入数据固定,函数输出值只与参数有关,而参数范围固定,则随着输入的变化,输出的改变也会限定在一个有限的范围内 此时关于输入样本 xxx 的导数 ∂fw∂x\\frac{\\partial f_w}{\\partial x}∂x∂fw​​也不会超过某个范围,所以一定存在某个不知道的常数 KKK 使得 fw(x)f_w(x)fw​(x) 的局部变动幅度不会超过它,Lipschitz连续条件得以满足 总结一下,到此为止,我们可以构造一个含参数 www 、最后一层不是非线性激活层的判别器网络 fw(x)f_w(x)fw​(x) ,在限制 www 不超过某个范围的条件下,使得 L=Ex∼pr(x)[fw(x)]−Ex∼pg(x)[fw(x)]L = E_{x\\thicksim p_r(x)}[f_w(x)]-E_{x\\thicksim p_g(x)}[f_w(x)] L=Ex∼pr​(x)​[fw​(x)]−Ex∼pg​(x)​[fw​(x)] 尽可能取最大值,此时 LLL 就会近似真实分布与生成分布之间的Wasserstein距离 接下来生成器要近似地最小化Wasserstein距离,可以最小化 LLL ,由于Wasserstein距离的优良性质,我们不需要担心生成器梯度消失的问题 G∗=arg min⁡Gmax⁡fw∈1−LipschitzEx∼pr(x)[fw(x)]−Ez∼p(z)[fw(G(z))]G^* = \\argmin\\limits_{G}\\max\\limits_{f_w\\in 1-Lipschitz}E_{x\\thicksim p_r(x)}[f_w(x)]-E_{z\\thicksim p(z)}[f_w(G(z))] G∗=Gargmin​fw​∈1−Lipschitzmax​Ex∼pr​(x)​[fw​(x)]−Ez∼p(z)​[fw​(G(z))] 注意这里的极大值极小值可能并不是很好理解,我举一个相似的例子比如说现在对于函数 y=ex+b,b∈[−1,1]y = e^x+b,b\\in [-1,1]y=ex+b,b∈[−1,1], 我们期望求这个函数在取最大值的时候取得的最小值很明显应该 b取1, 整个式子变成 y=ex+1y = e^x+1y=ex+1 这时候相较于其他 b的情况是最大的,在这种情况下的最小值(准确说是下确界)是 1 再考虑到 LLL 的第一项与生成器无关,就得到了WGAN的两个loss。 Gloss=−Ez∼p(z)[fw(G(z))]G_{loss} = -E_{z\\thicksim p(z)}[f_w(G(z))]Gloss​=−Ez∼p(z)​[fw​(G(z))] Dloss=Ex∼pr(x)[fw(x)]−Ez∼p(z)[fw(G(z))]D_{loss} = E_{x\\thicksim p_r(x)}[f_w(x)]-E_{z\\thicksim p(z)}[f_w(G(z))]Dloss​=Ex∼pr​(x)​[fw​(x)]−Ez∼p(z)​[fw​(G(z))] 论文中也据此给出了算法的伪代码 与GAN相比WGAN只改动了四点判别器最后一层去掉sigmoid生成器和判别器的loss不取log每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c不要用基于动量的优化算法（包括momentum和Adam）,推荐RMSProp前三点都是从理论分析中得到的,已经介绍完毕；第四点却是作者从实验中发现的,属于trick,相对比较“玄”。作者发现如果使用Adam,判别器的loss有时候会崩掉,当它崩掉时,Adam给出的更新方向与梯度方向夹角的cos值就变成负数,更新方向与梯度方向南辕北辙,这意味着判别器的loss梯度是不稳定的,所以不适合用Adam这类基于动量的优化算法。作者改用RMSProp之后,问题就解决了,因为RMSProp适合梯度不稳定的情况关于pytorch中的RMSProp优化器具体的WGAN-CP的代码实现可以参考这里 总结: WGAN前作分析了Ian Goodfellow提出的原始GAN两种形式各自的问题 第一种形式等价在最优判别器下等价于最小化生成分布与真实分布之间的JS散度,由于随机生成分布很难与真实分布有不可忽略的重叠以及JS散度的突变特性,使得生成器面临梯度消失的问题 第二种形式(-logD)在最优判别器下等价于既要最小化生成分布与真实分布直接的KL散度,又要最大化其JS散度,相互矛盾,导致梯度不稳定,而且KL散度的不对称性使得生成器宁可丧失多样性也不愿丧失准确性,导致collapse mode现象。 WGAN本作引入了Wasserstein距离,由于它相对KL散度与JS散度具有优越的平滑特性,理论上可以解决梯度消失问题。接着通过数学变换将Wasserstein距离写成可求解的形式,利用一个参数数值范围受限的判别器神经网络来最大化这个形式,就可以近似Wasserstein距离。在此近似最优判别器下优化生成器使得Wasserstein距离缩小,就能有效拉近生成分布与真实分布。WGAN既解决了训练不稳定的问题,也提供了一个可靠的训练进程指标,而且该指标确实与生成样本的质量高度相关 WGAN-GP 前文提到了我们最后利用 1-L约束可以得到的最终优化方程 G∗=arg min⁡Gmax⁡fw∈1−LipschitzEx∼pr(x)[fw(x)]−Ez∼p(z)[fw(G(z))]G^* = \\argmin\\limits_{G}\\max\\limits_{f_w\\in 1-Lipschitz}E_{x\\thicksim p_r(x)}[f_w(x)]-E_{z\\thicksim p(z)}[f_w(G(z))] G∗=Gargmin​fw​∈1−Lipschitzmax​Ex∼pr​(x)​[fw​(x)]−Ez∼p(z)​[fw​(G(z))] 实际我们也说了,是不是1都无所谓,只要函数别“跑飞”了就行。理论上很圆满,但是W-GAN在实现时却选择了一个略显粗糙的方法——权重裁剪 weight clipping,按照预先设定的截断范围,通过人为硬性的权重截断方式,以限制函数参数的方式来限制取值范围,这种想法显然是极其朴素的 从效果角度看,权重裁剪也是存在大问题的。正是因为这个原因,才有了本篇文章介绍具有梯度惩罚（Gradient Penalty, GP）策略的W-GAN,即W-GAN-GP 权重裁剪有什么问题么? 问题1: 参数二值化W-GAN的优化目标是两个数学期望的差,两个期望之差自然表示真假两路数据被 fwf_wfw​ 作用后平均值之间的差值,简单说就是函数要在两类数据上“扯开”试想我们在权重裁剪中给定常数 ccc, 比如 c=0.01c=0.01c=0.01 后,要求上面的差值越大越好,且要求参数不能小于-c且不能大于c,这样的操作势必导致参数的向着-c和c聚集,形成两极分化, fwf_wfw​ 即退化为一个二值神经网络,表现能力将异常低下判别器会非常倾向于学习一个简单的映射函数,都已经可以直接视为一个二值神经网络了,判别器没能充分利用自身的模型能力,经过它回传给生成器的梯度也会跟着变差。问题2: 训练难调节权重截断直接在参数上“做手术”,硬性将权重设定在 [−c,c][-c,c][−c,c] 范围,这存在将本来大的参数截小和将本来小的参数截大的可能。因此截断值的设定至关重要,否则要么梯度消失（梯度为0）,要么梯度爆炸（梯度为无穷大）原因是判别器是一个多层网络,如果我们把clipping threshold设得稍微小了一点,每经过一层网络,梯度就变小一点点,多层之后就会指数衰减；反之,如果设得稍微大了一点,每经过一层网络,梯度变大一点点,多层之后就会指数爆炸。只有设得不大不小,才能让生成器获得恰到好处的回传梯度,然而在实际应用中这个平衡区域可能很狭窄,就会给调参工作带来麻烦需要选取一个合适的权重裁剪的值才可以使这个网络训练梯度稳定 所以如何解决权重裁剪的问题呢? 面对上面权重裁剪存在的问题,W-GAN-GP的解决方案为在目标函数上添加一个梯度惩罚项（Gradient Penalty, GP）,“罚出”一个利普希茨条件 作者给出了两个版本的惩罚梯度 版本1 ω∗=arg min⁡ωEx∼pr(x)[fw(x)]−Ez∼p(z)[fw(G(z))]+λmax⁡(∥∇xfw(x)∥,1)\\omega^* = \\argmin\\limits_{\\omega}E_{x\\thicksim p_r(x)}[f_w(x)]-E_{z\\thicksim p(z)}[f_w(G(z))] + \\lambda\\max(\\|\\nabla_x f_w(x)\\|,1) ω∗=ωargmin​Ex∼pr​(x)​[fw​(x)]−Ez∼p(z)​[fw​(G(z))]+λmax(∥∇x​fw​(x)∥,1) 其中 λ\\lambdaλ 为梯度惩罚项的常系数。上面式子可以看出两件事 当 ∥∇xfw(x)∥≤1\\|\\nabla_x f_w(x)\\| \\le1∥∇x​fw​(x)∥≤1,惩罚项就剩下一个常数λ\\lambdaλ 当 ∥∇xfw(x)∥&gt;1\\|\\nabla_x f_w(x)\\| &gt; 1∥∇x​fw​(x)∥&gt;1,惩罚项为 λ∥∇xfw(x)∥\\lambda\\|\\nabla_x f_w(x)\\|λ∥∇x​fw​(x)∥, 这就意味着在求 arg min⁡\\argminargmin 的时候梯度越大则惩罚越大 意味着梯度超过1就做惩罚,即将梯度尽可能的限制在1之内,尽管版本1更符合1−利普希茨条件的要求,但是其惩罚项中的 max⁡\\maxmax 不可微,所以并没有选择这个版本 版本2 ω∗=arg min⁡ωEx∼pr(x)[fw(x)]−Ez∼p(z)[fw(G(z))]+λ(∥∇xfw(x)∥−1)2\\omega^* = \\argmin\\limits_{\\omega}E_{x\\thicksim p_r(x)}[f_w(x)]-E_{z\\thicksim p(z)}[f_w(G(z))] + \\lambda(\\|\\nabla_x f_w(x)\\|-1)^2 ω∗=ωargmin​Ex∼pr​(x)​[fw​(x)]−Ez∼p(z)​[fw​(G(z))]+λ(∥∇x​fw​(x)∥−1)2 版本2的梯度惩罚项来的更直接,距离1越远则惩罚越大,即将梯度尽可能的等于1。 对于上面两个版本的梯度惩罚,W-GAN中的利普希茨条件只是要求函数 fwf_wfw​ 的梯度有界,但是具体是多少其实无所谓 那么具体如何实现呢? 利普希茨连续条件可是要求函数在任意位置的梯度长度不能超过一个定值 KKK,即要求处处成立,上面惩罚项中抽象的 xxx 就表示任意的位置。但是,所谓的“任意”是无法操作的,所以还是需要带入具体的点 我们期望: 选择最好是样本空间的所有点,这样才最“任意”。但是很遗憾,这要求无穷多点,但只有有限的样本点,根本做不到 来自于全部的真实数据 pdatap_{data}pdata​ 和生成数据 pgp_gpg​ ,这样才比较“任意”。但是也很遗憾,一次训练不可能一次性读入全部 pdatap_{data}pdata​ ,并生成同样多的 pgp_gpg​,还是做不到 W-GAN-GP的解决方案是一个折中方案,选取一个训练小批次中全部的 xdata,xgx_{data},x_gxdata​,xg​,计算它们的随机混合部分x=ϵxdata+(1−ϵ)xg,ϵ∼U(0,1)x = \\epsilon x_{data} + (1-\\epsilon)x_g,\\epsilon\\thicksim\\mathcal{U(0,1)}x=ϵxdata​+(1−ϵ)xg​,ϵ∼U(0,1)这样的随机混合近似可以看作是任意点 关于梯度惩罚的pytorch实现 def calculate_gradient_penalty(self, real_images, fake_images): eta = torch.FloatTensor(self.batch_size,1,1,1).uniform_(0,1) eta = eta.expand(self.batch_size, real_images.size(1), real_images.size(2), real_images.size(3)).to(self.device) interpolated = eta * real_images + ((1 - eta) * fake_images) interpolated = interpolated.to(self.device) # define it to calculate gradient interpolated = Variable(interpolated, requires_grad=True) # calculate probability of interpolated examples prob_interpolated = self.D(interpolated) # calculate gradients of probabilities with respect to examples gradients = torch.autograd.grad(outputs=prob_interpolated, inputs=interpolated, grad_outputs=torch.ones( prob_interpolated.size()).to(self.device), create_graph=True, retain_graph=True)[0] grad_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * self.lambda_term return grad_penalty 论文还讲了一些使用gradient penalty时需要注意的配套事项:由于我们是对每个样本独立地施加梯度惩罚,所以判别器的模型架构中不能使用Batch Normalization,因为它会引入同个batch中不同样本的相互依赖关系。如果需要的话,可以选择其他normalization方法,如Layer Normalization、Weight Normalization和Instance Normalization,这些方法就不会引入样本之间的依赖。论文推荐的是Layer Normalization 实验表明,gradient penalty能够显著提高训练速度,解决了原始WGAN收敛缓慢的问题 总结与扩展思考 WGAN并不是最GAN网络中最优秀的,随着如今的发展,每年都会有很多GAN相关的论文和模型结构的提出,但是WGAN无疑是一次巨大的飞跃 初次学习了解GAN网络,不仅感叹前人的智慧,非常感谢网络上大佬无私分享的科普文章,阅读之后受益匪浅 笔者个人水平不足,绝大部分内容都为摘抄整理,加入自己的一些理解之后总结的.在对应的引用开头前都标注了原文章的出处,如有侵权即刻删除 从GAN,到使用深度卷积神经网络的DCGAN,到后来改进优化模型的WGAN,到后来进一步加入惩罚梯度的WGAN-GP,以及styleGAN,LSGAN等等等等,真的是学无止境啊!! 说起来这只是一门专选课的结课大作业,我上不上都可以的,不过老师的结课要求很宽松,自由度很高,正巧我之前只是了解过一点GAN相关的内容,并没有深入的学习过.这次正好利用了这次机会初步了解了GAN的相关内容和数学推导,确实令我折服. 后来也有很多人讨论了关于WGAN的内容,也提出了一些质疑的声音,可以参考这里,有兴趣的可以去了解一下 下一篇文章将会用我自己的一个示例来上手体验一下WGAN-GP的训练效果,使用WGAN-GP生成动漫头像","categories":[],"tags":[{"name":"GAN","slug":"GAN","permalink":"https://luzhixing12345.github.io/tags/GAN/"}]},{"title":"GAN网络详解(二) - DCGAN以及GAN网络存在的一些问题","slug":"GAN/GAN网络详解(二)","date":"2022-05-17T16:12:07.000Z","updated":"2022-05-19T10:50:20.739Z","comments":true,"path":"2022/05/18/GAN/GAN网络详解(二)/","link":"","permalink":"https://luzhixing12345.github.io/2022/05/18/GAN/GAN%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3(%E4%BA%8C)/","excerpt":"","text":"本文将会介绍DCGAN以及GAN网络存在的一些问题 DCGAN 这篇论文主要针对于GAN网络的经典问题: GANs have been known to be unstable to train, often resulting in generators that produce nonsensical outputs. 进而提出了使用深度卷积神经网络来改进 作者在论文中提出了了一些改进措施,比如 在生成器G中将去掉池化层(如maxpooling),替换为快速卷积,允许网络学习它自己的空间下采样(downsampling) 去除全连接层,作者认为全局平均池增加了模型的稳定性,但损害了收敛速度 以及加入BatchNormalization 特定位置使用ReLU,Tanh,LeakyReLU等激活函数 并且作者也指出了一些训练过程中的超参数,权重值,优化器学习率等等,一些细节不再这里赘述了,有兴趣的可以去看一下论文 DCGAN的生成器G网络结构如下图所示: 输入是一个100x1x1维的向量,首先将其转置卷积为1024x4x4,然后逐步转置卷积,最后得到一个3x64x64的图片 然后作者也做了跨数据集的分类问题的研究,在Imagenet-1k数据集中训练判别器D然后接一个L2-SVM的分类器,取得了82.8%的准确率. 从结构上来看,DCGAN比常见的判别式网络更加线性,因为连max pooling都没了,不那么线性的部分就只有最后输出图片的Tanh. 潜在空间的探索 作者提到了一个名词 walking the latent space,中译为探索潜在空间 参考文章了解机器学习中的潜在空间 什么是潜在空间呢? 它意味着压缩过的数据.对于经典的手写数据集MNIST,如果我们训练一个神经网络来实现它的分类问题 每次模型通过数据点学习时,图像的维度首先会降低,然后才会最终增加.当维度降低时,我们认为这是一种有损压缩形式. 由于模型需要然后重建压缩数据,因此它必须学会存储所有相关信息并忽略噪声这就是压缩的价值.它使我们能够摆脱任何无关的信息,只关注最重要的功能 这种压缩状态被称为数据的潜在空间. 那么为什么被称为空间呢? 每当我们绘制点图或想到潜在空间中的点时,我们都可以将它们想象为空间中的坐标,其中相似的点在图上更接近. 一个自然而然的问题是,我们如何想象4D点或n维点甚至非向量的空间,我们是3维生物,无法理解n维空间,我们只能假想一个超空间来映射多维空间的点,而相似的点在这个空间更加&quot;接近&quot;?或者说&quot;相似&quot;? 那么什么是相似呢? 如果我们看三个图像,两个椅子和一个桌子,我们很容易说两个椅子图像最相似,而桌子与任何一个椅子图像最不同.但是什么让这两把椅子的形象“更相似”呢？椅子具有明显的特征（即靠背,无抽屉,腿之间的连接）。这些都可以被我们的模型通过学习边缘,角度等的模式来“理解”。 如前所述,这些特征被打包在数据的潜在空间表示中。 因此,随着维数的降低,每个图像不同的“无关”信息（即椅子颜色）从我们的潜在空间表示中“删除”,因为只有每个图像最重要的特征存储在潜在空间表示中。 因此,当我们降低维度时,两把椅子的表示变得不那么明显,更加相似。如果我们想象它们在太空中,它们会“更紧密”地结合在一起。 *请注意,这里提到的“接近度”度量是一个模棱两可的术语,而不是明确的欧几里得距离,因为空间中的距离有多种定义。 那么探索潜在空间有什么意义呢? 潜在空间“隐藏”在我们最喜欢的许多图像处理网络、生成模型等中。 虽然潜空间对大多数人来说是隐藏的,但在某些任务中,理解潜空间不仅有帮助,而且是必要的. 在3D中,我们知道存在类似数据点的组,但是用更高维的数据描绘这些组要困难得多。 通过将数据的维数降低到2D（在这种情况下可以被认为是“潜在空间”表示）,我们能够更轻松地区分数据集中的流形(相似数据组) 我们可以使用在潜在空间中插值的方式来探索不同的面部结构,这也是用来研究GAN网络过程中相当有趣的一个工作 什么是在潜在空间中插值? 其实很简单,对于两个值X(a1,b1,…z1)和Y(a2,b2,…z2),我们可以使用GAN网络各自生成他们对应的图片,这没有问题. 而线性插值就是依次探索这两个高维点之间的空间,可以用来研究它们之间的过渡/变化过程 import torch X = torch.randn((5,5,5,5)) Y = torch.randn((5,5,5,5)) alpha = 0 walk_step = 100 images = [] G = generator() for i in range(walk_step): point = alpha * X + (1-alpha) * Y images.append(G(point)) alpha = alpha + 1/walk_step # then do visiualization for images to see latent space for generator 上图就体现出了这个转变的过程 关于latent space 的相关内容这里再扩展一些,因为目前做的都是线性插值,即直接取了两点之间的直线,有人认为在高维空间中数据其实分布在帐篷布上,但是线性插值的方法其实走的是帐篷杆,应该用一种更好的方式Slerp.详见知乎-行走在GAN的Latent Space,作者也讨论了Great Circle也做了一些实验,我觉得还是很值得一看的. 总结来说DCGAN依靠的是对判别器和生成器的架构进行实验枚举,最终找到一组比较好的网络架构设置,但是实际上是治标不治本,没有彻底解决问题.GAN网络的训练依旧十分困难 GAN网络存在的问题 参考文章: WGAN的来龙去脉 令人拍案叫绝的WGAN 为什么GAN网络难以训练 在介绍WGAN之前,我们需要先了解GAN网络存在的问题,WGAN的一作作者Martin Arjovsky在2017年先后参与了三篇相关论文,第一篇论文&quot;Towards Principled Methods for Training Generative Adversarial Networks&quot;,这篇论文是WGAN发表前的铺垫,它最大的贡献是从理论上解释了GAN训练不稳定的原因. 人们在应用GAN时经常发现一个现象：不能把Discriminator训练得太好,否则Generator的性能很难提升上去.该文以此为出发点分析了GAN目标函数的理论缺陷. 在上一节中,我们提到了GAN网络的目标函数 min⁡Gmax⁡DV(D,G)=Ex∼pdata(x)[log⁡D(x)]+Ez∼pz(z)[log⁡(1−D(G(z)))]\\min\\limits_{G}\\max\\limits_{D}V(D,G) = E_{x\\thicksim p_{data(x)}}[\\log D(x)] + E_{z\\thicksim p_{z(z)}}[\\log(1-D(G(z)))] Gmin​Dmax​V(D,G)=Ex∼pdata(x)​​[logD(x)]+Ez∼pz(z)​​[log(1−D(G(z)))] 同时证明了,固定Generator时,最优的Discriminator的取值是 DG∗(x)=Pdata(x)Pdata(x)+Pg(x)D^*_G(x) = \\frac{P_{data}(x)}{P_{data}(x) + P_g(x)} DG∗​(x)=Pdata​(x)+Pg​(x)Pdata​(x)​ 所以在面对最优Discriminator时,Generator的优化目标就变成了 写成JS散度的形式就是 C(G)=−log⁡4+2∗JSD(pdata∣∣pg)C(G) = -\\log4 + 2*JSD(p_{data}||p_g) C(G)=−log4+2∗JSD(pdata​∣∣pg​) 所以现在这个问题被转化为:在最优判别器的下,我们可以把原始GAN定义的生成器loss等价变换为最小化真实分布PdataP_{data}Pdata​与生成分布PgP_gPg​之间的JS散度。我们越训练判别器,它就越接近最优,最小化生成器的loss也就会越近似于最小化Pdata和P_{data}和Pdata​和P_g$之间的JS散度 问题就出在这个JS散度上。我们会希望如果两个分布之间越接近它们的JS散度越小,我们通过优化JS散度就能将PgP_gPg​&quot;拉向&quot;真实分布PdataP_{data}Pdata​ 这个希望在两个分布有所重叠的时候是成立的,也就是最终的优化目标Pg=PdataP_g = P_{data}Pg​=Pdata​.但是如果两个分布完全没有重叠的部分,或者它们重叠的部分可忽略,它们的JS散度是多少呢？ 重叠的部分可忽略是什么意思? GAN中的生成器一般是从某个低维（比如100维）的随机分布中采样出一个编码向量,再经过一个神经网络生成出一个高维样本（比如64x64的图片就有4096维）。当生成器的参数固定时,生成样本的概率分布虽然是定义在4096维的空间上,但它本身所有可能产生的变化已经被那个100维的随机分布限定了,其本质维度就是100,再考虑到神经网络带来的映射降维,最终可能比100还小,所以生成样本分布的支撑集就在4096维空间中构成一个最多100维的低维流形,“撑不满”整个高维空间.“撑不满”就会导致真实分布与生成分布难以“碰到面”,这很容易在二维空间中理解：二维平面中随机取两条曲线,它们之间刚好存在重叠线段的概率为0虽然它们很大可能会存在交叉点,但是相比于两条曲线而言,交叉点比曲线低一个维度,长度（测度）为0,可忽略三维空间中也是类似的,随机取两个曲面,它们之间最多就是比较有可能存在交叉线,但是交叉线比曲面低一个维度,面积（测度）是0,可忽略。 那么回到刚才的问题,如何计算两个分布的JS散度呢? 我们惊讶的发现这是一个定值 log⁡2\\log2log2 对于任意的空间中任意选定的一点x,在真实分布PdataP_{data}Pdata​与生成分布PgP_gPg​中的概率有四种情况 Pdata(x)=0,Pg(x)=0P_{data}(x) = 0,P_g(x) = 0Pdata​(x)=0,Pg​(x)=0, 这种情况对JS的计算无贡献,可以理解为选点选歪了 Pdata(x)≠0,Pg(x)≠0P_{data}(x) \\neq 0,P_g(x) \\neq 0Pdata​(x)​=0,Pg​(x)​=0, 这种情况下说明选点选到了重叠部分,但是由于重叠部分可忽略所以贡献也为0 Pdata(x)≠0,Pg(x)=0P_{data}(x) \\neq 0,P_g(x) = 0Pdata​(x)​=0,Pg​(x)=0 根据之前的得到的公式 Pdata(x)=0,Pg(x)≠0P_{data}(x) = 0,P_g(x) \\neq 0Pdata​(x)=0,Pg​(x)​=0 情况相同 换句话说,无论真实分布PdataP_{data}Pdata​与生成分布PgP_gPg​是远在天边,还是近在眼前,只要它们俩没有一点重叠或者重叠部分可忽略,JS散度就固定是常数,而这对于梯度下降方法意味着**梯度为0！**此时对于最优判别器来说,生成器肯定是得不到一丁点梯度信息的；即使对于接近最优的判别器来说,生成器也有很大机会面临梯度消失的问题 参考难以优化的GAN 我们就得到了WGAN前作中关于生成器梯度消失的第一个论证：在（近似）最优判别器下,最小化生成器的loss等价于最小化PdataP_{data}Pdata​与PgP_gPg​之间的JS散度,而由于PdataP_{data}Pdata​与PgP_gPg​几乎不可能有不可忽略的重叠,所以无论它们相距多远JS散度都是常数−log⁡2-\\log2−log2,最终导致生成器的梯度（近似）为0,梯度消失 JS散度是f散度的一种,所有的f散度都具有一个问题,那就是在两个分布几乎没有交集的时候,散度为一个常数,这意味着梯度为零,而我们是使用梯度下降求解的,所以这意味着我们无法很好地完成优化 好消息：两个分布完全无重叠,则一定存在一个最优分类器,能够使得对两种分布样本的分类精度达到100%。也就是说在GAN的判别器优化过程中,那个我们心心念念寻找的完美判别器是一定存在的,我们放开手去找就是了 坏消息：JS作为损失函数输出为常数,即梯度为0,意味着我们在优化生成器时,梯度下降法将不知道朝哪个方向下降。 该文花了大量的篇幅进行数学推导,证明在一般的情况下,上述有关JS散度的目标函数会带来梯度消失的问题。也就是说,如果Discriminator训练得太好,Generator就无法得到足够的梯度继续优化,而如果Discriminator训练得太弱,指示作用不显著,同样不能让Generator进行有效的学习。这样一来,Discriminator的训练火候就非常难把控,这就是GAN训练难的根源. mode dropping / mode collapse 什么是 mode collapse 指的是生成样本只集中于部分的mode从而缺乏多样性的情况。例如,MNIST数据分布一共有10个mode（0到9共10个数字）,如果Generator生成的样本几乎只有其中某个数字,那么就是出现了很严重的mode collapse现象即生成器仅仅生成部分重复的图片,缺乏多样性 mode collapse在GAN的训练中也非常的常见,比如将会在下一节中出现的示例,我自己的在使用DCGAN训练一个生成动漫头像的GAN网络,出现了十分明显的 mode collapse的现象 epoch 生成器的部分结果 30 70 可以很明显的看出随着训练过程的进行,生成器的图像出现了明显的重复 那么为什么会造成mode collapse呢? 这也是KL散度所带来的问题.我们假设有如下两个正态分布,我们可以画出需要优化的方向,即JS散度的图像 其中p代表真实图像的分布,q代表生成的图像的分布 当我们选取红线所在的位置(x=2),此时p(x)→0,q(x)&gt;0p(x)\\rightarrow0,q(x)&gt;0p(x)→0,q(x)&gt;0,此时对应的Djs(p∣∣q)D_{js}(p||q)Djs​(p∣∣q)很大,同样的对称位置(x=-2)JS散度依然很高,也就是惩罚很高 第一种情况(x=2)对应生成器没能生成真实的样本 第二种情况(x=-2)对应着生成器生成了不真实的样本. 这两种情况下的惩罚都是巨大的.导致生成器训练起来难度巨大 我们之前提到过训练生成器G的时候往往不使用 log⁡(1−D(G(z)))\\log(1-D(G(z)))log(1−D(G(z))),因为它接近0,梯度很小,很难训练G GAN的论文中也提出了一种改进做法是损失变为 −log⁡(D(G(z)))-\\log(D(G(z)))−log(D(G(z))),这种技巧也被成为 - log D trick或者 the - log D alternative,在训练中确实有所帮助 但是这会带来另外的问题,这种情况下我们计算生成器G的梯度时 Δθ=∇θEz∼p(z)[−log⁡D(gθ(z))]\\Delta\\theta = \\nabla_{\\theta}E_{z\\thicksim p(z)}[-\\log D(g_{\\theta}(z))] Δθ=∇θ​Ez∼p(z)​[−logD(gθ​(z))] 根据前文的数学推导可以得出这个梯度可以转化为 Δθ=KL(Pg∣∣Pdata)−2JS(Pdata∣∣Pg)\\Delta\\theta = KL(P_g||P_{data})-2JS(P_{data}||P_g) Δθ=KL(Pg​∣∣Pdata​)−2JS(Pdata​∣∣Pg​) 这个等价最小化目标存在两个严重的问题。第一是它同时要最小化生成分布与真实分布的KL散度,却又要最大化两者的JS散度,一个要拉近,一个却要推远！这在直观上非常荒谬,在数值上则会导致梯度不稳定,这是后面那个JS散度项的毛病 即便是前面那个正常的KL散度项也有毛病,我们先把这种状况下的KL散度图画出来 那么对于KL散度的定义 KL(p∣∣q)=∫xp(x)log⁡p(x)q(x)dxKL(p||q) = \\int_x p(x)\\log\\frac{p(x)}{q(x)}dxKL(p∣∣q)=∫x​p(x)logq(x)p(x)​dx KL(q∣∣p)=∫xq(x)log⁡q(x)p(x)dxKL(q||p) = \\int_x q(x)\\log\\frac{q(x)}{p(x)}dxKL(q∣∣p)=∫x​q(x)logp(x)q(x)​dx 我们可以分别画出它们对应的图像,值得注意的是KL散度是非对称的,两个图像不相同,我们这里只需要关注Dkl(Q∣∣P)D_{kl}(Q||P)Dkl​(Q∣∣P)红色的曲线即可 当我们选取红线所在的位置(x=2),此时p(x)→0,q(x)&gt;0p(x)\\rightarrow0,q(x)&gt;0p(x)→0,q(x)&gt;0,此时对应的Dkl(Q∣∣P)→0D_{kl}(Q||P)\\rightarrow0Dkl​(Q∣∣P)→0 当我们选取红线的对应的位置(x=-2),此时p(x)&gt;0,q(x)→0p(x)&gt;0,q(x)\\rightarrow0p(x)&gt;0,q(x)→0,此时对应的Dkl(Q∣∣P)→1D_{kl}(Q||P)\\rightarrow1Dkl​(Q∣∣P)→1 换言之,Dkl(Q∣∣P)D_{kl}(Q||P)Dkl​(Q∣∣P)对于上面两种错误的惩罚是不一样的 对于前文提到的两种情况: 第一种情况(x=2)对应生成器没能生成真实的样本 第二种情况(x=-2)对应着生成器生成了不真实的样本. 第一种错误对应的是“生成器没能生成真实的样本”,惩罚微小,第二种错误对应的是“生成器生成了不真实的样本” ,惩罚巨大. 我们按照“人类正常的思绪”来看,“像的生成不了”和“能生成的不像”实际表达的都是“生成器烂”这一件事儿,但是KL散度却给出了截然相反的两种惩罚结果,一个“挠痒痒”和一个“往死打” 这一放一打之下,生成器宁可多生成一些重复但是很“安全”的样本,也不愿意去生成多样性的样本,因为那样一不小心就会产生第二种错误,得不偿失。这种现象就是大家常说的mode collapse 第一种错误对应的是缺乏多样性,第二种错误对应的是缺乏准确性 除了上述的缺陷,该文还通过数学证明这种-logD的目标函数还存在梯度方差较大的缺陷,导致训练的不稳定。然后同样通过实验直观地验证了这个现象,如下图,在训练的早期（训练了1 epoch和训练了10 epochs）,梯度的方差很大,因此对应的曲线看起来比较粗,直到训练了25 epochs以后GAN收敛了才出现方差较小的梯度可以看到随着判别器的训练,蓝色和绿色曲线中生成器的梯度迅速增长,说明梯度不稳定,红线对应的是DCGAN相对收敛的状态,梯度才比较稳定","categories":[],"tags":[{"name":"GAN","slug":"GAN","permalink":"https://luzhixing12345.github.io/tags/GAN/"}]},{"title":"优雅的日志记录-logging","slug":"python/优雅的日志记录-logging","date":"2022-05-13T07:11:39.000Z","updated":"2022-05-14T02:17:38.220Z","comments":true,"path":"2022/05/13/python/优雅的日志记录-logging/","link":"","permalink":"https://luzhixing12345.github.io/2022/05/13/python/%E4%BC%98%E9%9B%85%E7%9A%84%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95-logging/","excerpt":"","text":"前言 最近在写代码的过程中遇到了一些问题,如果我想输出一些信息,如果使用print函数的话,由于深度学习项目时间较长,我会将它提交到超算进行计算,但是它并不会实时输出,我必须要等到运行结束才能看到结果,如果一点有任何异常报错退出,那么我也看不到所有的print信息. 况且使用print是一种比较简单的输出格式,输出到控制台的话无法记录下来,如果使用txt单独保存信息似乎过于原始,我希望选择一种更加优雅的方式来记录信息,于是查阅资料后尝试使用了logging模块来记录信息,体验很好,分享给大家. 参考文章: python3.7-logging模块 简书-logging模块使用教程 知乎-logging模块详解 B站视频-&lt;清晰详细&gt; 博客记录 logging模块简介 logging是python内置的模块,不需要下载就可以直接import使用 日志的等级分为五级 日志等级 描述 DEBUG 基本的调试信息,可以用于输出一些特定位置的值用于调试程序 INFO 正常的信息,可以用于输出某些节点/阶段的信息 WARNING 警告信息,可以用于输出一些不合适的错误信息,比如输入不符合预期等等 ERROR 错误信息,一些严重的错误信息 CRITICAL 严重错误信息 通常来说我们个人使用的话前三个日志等级应该就足够满足了 日志等级是从上到下,DEBUG等级的日志可以显示所有日志,CRITICAL等级就只能显示CRITICAL等级的. import logging logging.debug(&quot;debug_msg&quot;) logging.info(&quot;info_msg&quot;) logging.warning(&quot;warning_msg&quot;) logging.error(&quot;error_msg&quot;) logging.critical(&quot;critical_msg&quot;) 输出结果是 WARNING:root:warning_msg ERROR:root:error_msg CRITICAL:root:critical_msg 可以看出来默认的logging等级是WARNING 我们可以使用basicConfig函数来调整日志输出的等级 import logging logging.basicConfig(level=logging.DEBUG) logging.debug(&quot;debug_msg&quot;) logging.info(&quot;info_msg&quot;) logging.warning(&quot;warning_msg&quot;) logging.error(&quot;error_msg&quot;) logging.critical(&quot;critical_msg&quot;) 输出结果是 DEBUG:root:debug_msg INFO:root:info_msg WARNING:root:warning_msg ERROR:root:error_msg CRITICAL:root:critical_msg 这也给我们提供了一组思路,就是可以在编写程序的时候在一些位置使用DEBUG等级的日志,在某些关键节点使用INFO等级的日志作为阶段提示信息,在一些可能会需要获取用户输入的地方写入WARNING日志,在一些函数内部可以做一些判断,对错误信息打上ERROR日志,这样的话如果启用DEBUG等级的日志就可以查看到所有信息,如果没什么问题的话就使用INFO等级,只看到一些正常的阶段提示信息,这样直接就忽略了所有的DEBUG的日志,也不用去像以前一样注释print函数如果程序出错,INFO等级的日志也可以看到ERROR或CRITICAL等级的错误,进行排查 logging的进阶用法 接下来介绍logging模块的四个组件,初识这一部分的时候看文档看不太懂,后来还是看了视频的讲解对这几个组件的应用理解了很多,下面我尽可能使用平实的语言来介绍其使用方式 组件名称 用途 Logger(记录器) 创建一个基本的日志的对象 Handlers(处理器) 将记录器产生的日志信息发送到目的地 Filter(过滤器) 定向过滤显示一些日志,不显示一些日志,相比level等级有了更高的控制精度 Formatter(格式化器) 控制输出格式 这四个组件看起来不是特别好理解,一些文字描述似乎也有些云里雾里,下面我会通过一个实际的例子来介绍他们的使用方法 记录器Logger 我们先创建一个logger记录器,命名为PYTHON-LOGGER,然后将他的日志等级设置为DEBUG等级 import logging #创建记录器 （全局） logger = logging.getLoger(&quot;PYTHON-LOGGER&quot;) 值得一提的是,getLogger这个函数比较有趣,logging在定义了一个logger的名字之后,就会把这个记录器的相关信息保存起来,如果你在其他文件的位置(比如说另一个 xx.py 文件)中也使用了logger = logging.getLogeer(&quot;PYTHON-LOGGER&quot;)这样返回一个logger,他的信息与这个第一次定义过的完全相同,相当于是一个全局的变量 处理器Handler 接下来我们为这个记录器创建两个处理器(Handlers),一个用于把信息输出到控制台(console),一个用于把信息输出到日志文件(log file) import logging import sys #创建记录器 （全局） logger = logging.getLoger(&quot;PYTHON-LOGGER&quot;) logger.setLevel(logging.DEBUG) #用于输出到控制台，使用StreamHandler的处理器 consoleHandler = logging.StreamHandler(stream=sys.stdout) consoleHandler.setLevel(logging.DEBUG) #用于输出到文件，使用FileHandler处理器 fileHandler = logging.FileHandler(filename=&#x27;file.log&#x27;,mode = &quot;w&quot;) # w表示覆盖之前的文件内容，也可以使用 &quot;a&quot; 来从文件结尾接着写 fileHandler.setLevel(logging.INFO) #将处理器加入到记录器中 logger.addHandler(consoleHandler) logger.addHandler(fileHandler) 注意到我们给控制台的处理器设置了DEBUG等级,给文件处理器设置了INFO等级,也就是说现在的的fileHandler的日志等级更高,DEBUG的信息并不会输出到文件中同时注意到我们也需要给logger设置日志等级为DEBUG,因为默认的logger等级是WARNING,日志等级是层级递进的,记录器-&gt;处理器,只会显示更高等级的日志信息,所以我们的处理器日志等级要比logger更高才会显示,所以设置logger为DEBUG等级(最低) 接下来我们可以简单的记录一些信息来看一看现在是什么情况. ... logger.debug(&quot;this is a debug message&quot;) logger.info(&quot;this is a info message&quot;) logger.warning(&quot;this is a warning message&quot;) 可以看到控制台输出了三条信息,文件夹中创建了一个file.log文件,其中记录了两条信息 StreamHandler和FileHandler是两个比较常用的处理器类型,处理器的任务是将日志文件内容发送到某一个位置,这两个处理器分别是发送到流和发送到磁盘文件,当然除此之外还有其他的处理器函数 SocketHandler可以使用Socket将日志记录发送到网络套接字,建立TCP连接发送到某一个IP地址 WatchedFileHandler可以监视记录到的文件的类,如果文件发生更改，它将被关闭并使用文件名重新打开 TimedRotatingFileHandler可以按特定时间轮换替换日志文件,比如说你需要一个长时间运行在服务器上的python程序,每天的日志文件可能会很大,它可以设置按天/按时间/日志文件定时分离保存等等操作. SMTPHandler可以将日志记录邮件发送到电子邮件地址 HTTPHandler可以将日志记录消息发送到 Web 服务器 处理器的功能十分强大,基本标准库提供的处理器类型可以覆盖满足基本的日志需求. 当然作为个人使用的话其实用不到这么复杂的东西,我们使用控制台输出和文件记录两个日志处理器就可以满足我们debug文件的需求了,如果感兴趣的话可以了解一下 过滤器Filter 这个说实话我觉得没啥用,一看一过得了 过滤器的作用是可以精细的区分记录器. 比如说我们设置了多个记录器,我们可以使用过滤器来特定的显示记录器的内容,而不显示某些记录器的内容 import logging logger1 = logging.getLoger(&quot;a&quot;) logger2 = logging.getLoger(&quot;a.b&quot;) logger3 = logging.getLoger(&quot;a.b.c&quot;) logger4 = logging.getLoger(&quot;d.b.c&quot;) logger5 = logging.getLoger(&quot;d.b&quot;) logger6 = logging.getLoger(&quot;e.a&quot;) filter = logging.Filter(&quot;a.b&quot;) 过滤器的操作是与python的包名类似的,该包和其子包都会被过滤掉,也就是说2,3logger会被过滤掉,不会被记录 格式化器Formatter 格式化器是一个很有用的东西,它可以用于控制输出的格式 默认的输出格式是很简单的 DEBUG:root:debug_msg,它由三部分组成,DEBUG表示日志等级level,root是默认的记录器名字,我们可以用是getLogger来改变它的名字,debug_msg是输出的信息 我们可以使用格式化器来输出我们想要的格式 import logging import sys #创建记录器 （全局） def main(): logger = logging.getLoger(&quot;PYTHON-LOGGER&quot;) logger.setLevel(logging.DEBUG) #用于输出到控制台，使用StreamHandler的处理器 consoleHandler = logging.StreamHandler(stream=sys.stdout) consoleHandler.setLevel(logging.DEBUG) #用于输出到文件，使用FileHandler处理器 fileHandler = logging.FileHandler(filename=&#x27;file.log&#x27;,mode = &quot;w&quot;) # w表示覆盖之前的文件内容，也可以使用 &quot;a&quot; 来从文件结尾接着写 fileHandler.setLevel(logging.INFO) formatter = logging.Formatter( &quot;[%(asctime)s] [%(levelname)7s] [%(filename)8s] [%(funcName)8s] [%(lineno)3d]: %(message)s&quot;, datefmt=&quot;%Y %m/%d %H:%M:%S&quot;) fileHandler.setFormatter(formatter) consoleHandler.setFormatter(formatter) #将处理器加入到记录器中 logger.addHandler(consoleHandler) logger.addHandler(fileHandler) logger.debug(&quot;this is a debug message&quot;) logger.info(&quot;this is a info message&quot;) logger.warning(&quot;this is a warning message&quot;) if __name__ == &quot;__main__&quot;: main() 值得注意的是formatter是需要加在handler上面的 控制台的输出的结果是 [2022 05/14 00:48:31] [ DEBUG] [ demo.py] [ main] [ 29]: this is a debug message [2022 05/14 00:48:31] [ INFO] [ demo.py] [ main] [ 30]: this is a info message [2022 05/14 00:48:31] [WARNING] [ demo.py] [ main] [ 31]: this is a warning message 这是我比较喜欢的一种输出格式,我们可以设置时间,文件名,函数名,行号等等,还可以输出线程,进程,路径等等更多信息,不过对于我来说并不需要那么多 当你创建了一个logger并给了它一个名字之后(通常是项目名),你可以再次调用这个logger而不需要重新配置信息,比如再次使用getLogger(“PYTHON-LOGGER”)后使用logger.info记录日志,日志的保存方式依然和原先相同 logging的工程化用法 上述的方式已经可以基本完成需求了,但是我们可以有一种更加优雅的方式,使用配置文件. 新建一个logging.conf文件,将如下信息填入 conf文件暂不支持中文字符,否则读取的时候会出现gbk错误,所以注释都是英文写的 #./logging.conf # set a logger, root is must [loggers] keys=root,PROJECT # two handler, file and consolehandler [handlers] keys=fileHandler,consoleHandler # formatter, declear below [formatters] keys=simpleFormatter [logger_root] level=DEBUG handlers=consoleHandler [logger_PROJECT] level=DEBUG handlers=fileHandler,consoleHandler qualname=PROJECT_NAME # often choose propagate=0 propagate=0 [handler_consoleHandler] class=StreamHandler args=(sys.stdout,) level=DEBUG formatter=simpleFormatter # use TimeRotatineFileHandler is more professional [handler_fileHandler] class=handlers.TimedRotatingFileHandler # record after 3600s of midnight -&gt; 1:00, 0 means save all the previous files args=(&#x27;PROJECT_NAME.log&#x27;,&#x27;midnight&#x27;,3600,0) level=DEBUG formatter=simpleFormatter [formatter_simpleFormatter] format=[%(asctime)s] [%(levelname)7s] [%(filename)8s] [%(funcName)8s] [%(lineno)3d]: %(message)s datefmt=%Y %m/%d %H:%M:%S 这样一个配置文件的内容就完成了,我们省去了写代码的时间,直接可以通过读取配置文件来得到一个logger import logging import logging.config logging.config.fileConfig(&#x27;logging.conf&#x27;) logger = logging.getLogger(&#x27;PROJECT_NAME&#x27;) logger.debug(&quot;This is PROJECT logger, debug&quot;) logger.info(&quot;hello world&quot;) 运行结果 [2022 05/14 09:07:47] [ DEBUG] [ b.py] [&lt;module&gt;] [ 7]: This is PROJECT logger, debug [2022 05/14 09:07:47] [ INFO] [ b.py] [&lt;module&gt;] [ 9]: hello world 接下来以后我们只需要每次带着这个配置文件,然后每次修改PROJECT_NAME,这样就可以直接很方便的使用了 文件日志通常不选择覆盖写入,而是跟在后面写入,即’a’ 我个人的python工作流 https://github.com/luzhixing12345/python-template","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://luzhixing12345.github.io/tags/python/"}]},{"title":"GAN网络详解(一) - 基本原理及数学推导","slug":"GAN/GAN网络详解(一)","date":"2022-05-11T16:00:47.000Z","updated":"2022-05-19T10:59:27.708Z","comments":true,"path":"2022/05/12/GAN/GAN网络详解(一)/","link":"","permalink":"https://luzhixing12345.github.io/2022/05/12/GAN/GAN%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3(%E4%B8%80)/","excerpt":"","text":"生成对抗网络(GAN)的出现可以说在深度学习领域具有划时代的意义,如今GAN也被广泛应用于各种机器学习的场景之中.GAN系列也是我个人学习过程的收获和心得,分享出来希望可以学习进步,欢迎批评指正 本系列预计使用四个部分分别介绍: GAN的基本原理及数学推导 GAN的不足之处 WGAN-CP,以及后续的改进版本WGAN-GP 一个我的Github项目,使用WGAN-GP生成动漫头像 GAN的基本原理 GAN的基本原理其实非常简单.假设我们有两个网络,G(Generator)和D(Discriminator) G是一个生成图片的网络,它接收一个随机的噪声z,通过这个噪声生成图片,记做G(z) D是一个判别网络,判别一张图片是不是&quot;真实的&quot;. 它的输入参数是x,x代表一张图片,输出D(x)代表x为真实图片的概率. 0 ~ 1 的范围表示判别器认为这张图像是真实图像的概率是多少. 在训练过程中,生成网络G的目标就是尽量生成真实的图片去欺骗判别网络D.而D的目标就是尽量把G生成的图片和真实的图片分别开来.这样,G和D构成了一个动态的&quot;博弈过程&quot;. 图源:https://blog.csdn.net/LEE18254290736/article/details/97371930 最后博弈的结果是什么? 在最理想的状态下,G可以生成足以&quot;以假乱真&quot;的图片G(z).对于D来说,它难以判定G生成的图片究竟是不是真实的,因此D(G(z)) = 0.5.这个思想还是比较巧妙的. 这里借用李沐老师在GAN论文逐段精读中的讨论,我觉得讲解的非常清楚 假设你在玩游戏,你的显示器是4K的分辨率60fps,然后我说我要学一个生成器可以也能够生成跟游戏一样的图片,具体来说就是要生成一个 x ,大约是800万像素点,就是一个长为800万维的一个多维随机变量,我们认为每一个像素的值都是由后面的一个分布来控制的就是这个 pg,当我们知道我们这个分布其实就是对应的我们游戏那一个程序那么我们的生成模型怎么样输出 x 呢? 在一个输入的噪音变量上面叫噪音变量是 z 然后这个分布是 pz. z 你可以认为就是一个100维的一个向量每一个元素是一个均值为0方差为1的一个高斯噪音.我的生成模型就是把 z 映射成 x那么回到这个游戏的例子假设,你想生成游戏的图片,我去反汇编你的游戏代码,然后把代码给你拎出来那我就真正的知道这个游戏是怎么生成出来的,但是这种途径是代表的我们要去构造那个分布,在计算上比较难计算那么索性干脆就不管那个游戏程序怎么来的,虽然是 4k 的图片但是实际上呢他背后就是一些代码控制,可能就是那么100个变量控制.哪个人物出现在哪个位置,然后他们在干什么事情.虽然我不知道具体是什么东西,那么我估摸着你大概就是一个100维的向量足以表达你这些背后隐藏的一些逻辑因为我们知道 MLP 理论上可以拟合任何一个函数,那我就干脆说构造一个差不多大小的向量然后这个 MLP 都强行把这个 z 映射成我要的那些 x 使的长得很像就行了这个好处是算起来比较简单,但坏处也很明显.因为MLP其实不是真正的去了解他的代码,那么就是说我看到某一个图片的时候我很难去找到他背后对应的 z 是什么东西,而只能反过来说我每次随机的给你一个 z 然后看你看手气,生成一个也还像样的一个图片就行了,所以这是他带来的不方便的地方 对于判别器D来说,D 也是个 MLP,他的作用是把800万的像素的图片放进来然后他输出一个标量他要去判断你这个 x 到底是来自你真实采样的数据呢还是你生成出来的图片在前面那个例子就是说你的这个图片到底是来自于在游戏中的截图还是你的生成器生出来的图片因为我们知道我们的数据到底是哪里来的所以我们就给数据一个标号.如果来自真实的数据就是 1如果来自于生成器就是 0 那我们就采样一些数据训练一个两类的分类器 论文中也给出了博弈双方的数学公式 min⁡Gmax⁡DV(D,G)=Ex∼pdata(x)[log⁡D(x)]+Ez∼pz(z)[log⁡(1−D(G(z)))]\\min\\limits_{G}\\max\\limits_{D}V(D,G) = E_{x\\thicksim p_{data(x)}}[\\log D(x)] + E_{z\\thicksim p_{z(z)}}[\\log(1-D(G(z)))] Gmin​Dmax​V(D,G)=Ex∼pdata(x)​​[logD(x)]+Ez∼pz(z)​​[log(1−D(G(z)))] 这个公式看上去很复杂,其实他是D G 共同求解的一个博弈过程. 对于x,z分别来自两个分布,一个是真实数据的分布data,一个是噪声的分布Z. D的计算式是 log⁡D(x)+log⁡(1−D(g(z)))\\log D(x) + \\log(1-D(g(z)))logD(x)+log(1−D(g(z))),理想状态D可以完美区分来自真实图片x的数据(D(X)=1)和来自生成器图片的数据(D(G(z))=0),即 log⁡1+log⁡1=0\\log 1 + \\log 1 = 0log1+log1=0 ,但事实上判别器D存在误分类的问题,所以两项都为负值,优化的方向是max,希望求得最大为0 对于生成器 G 的优化只有一项,G的目的就是使得判别器误判,也就是期望D(G(z))=1,希望后式从 log⁡(1−0)=0\\log(1-0)=0log(1−0)=0 优化到 log⁡(1−1)=−∞\\log(1-1)= -\\inftylog(1−1)=−∞ 这是一个双人的minmax游戏,需要生成器G和判别器D同时训练,同时优化. 最开始a状态真实图像的分布pdatap_{data}pdata​(黑线)和生成的图像pzp_zpz​(绿线)具有显著的差异,判别器(蓝线)可以很轻易的分辨,后来两者的分布趋势逐渐相似,直至最后完全相同,此时判别器已无法准确分辨(0.5) GAN的算法思路 论文也提供了具体的算法伪代码 该算法的语言描述为,一共进行N次循环迭代,每次迭代首先训练K(默认为1)次判别器,从噪音分布pzp_zpz​中取m个噪音样本输入给G生成图片,和从真实分布pdatap_{data}pdata​中的m个真实样本一起,反向传播计算更新判别器D的梯度,正向更新求最大然后再从噪音分布pzp_zpz​中取m个噪声样本,更新生成器G的梯度,反向更新求最小 pytorch版本的简略代码如下,值得一提的是GAN论文本身并没有提出模型的结构,如果读者有兴趣可以自己构建两个模型然后找一些数据集来训练一下. import torch import torch.nn as nn # define the model structure by yourself D = discriminator() G = generator() # compute BCE_Loss using real images where BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x)) loss_fn = nn.BCELoss() d_optimizer = torch.optim.Adam(D.parameters()) g_optimizer = torch.optim.Adam(G.parameters()) for epoch in EPOCHS: for id, data in enumerate(train_loader): # init labels for real images and fake images real_labels = torch.ones(32) fake_labels = torch.zeros(32) # first update for discriminator for i in range(k): # init random noise z = torch.randn((32,100,1,1)) real_images = data outputs = D(real_images) d_loss_real = loss_fn(outputs,real_labels) fake_images = G(z) outputs = D(fake_images) d_loss_fake = loss_fn(outputs,fake_labels) # calculate d_loss d_loss = d_loss_real + d_loss_fake # update D D.zero_grad() d_loss.backward() d_optimizer.step() # start to update G z = torch.randn((32,100,1,1)) fake_images = G(z) outputs = D(fake_images) g_loss = loss_fn(outputs,fake_labels) D.zero_grad() G.zero_grad() g_loss.backward() g_optimizer.step() 这种思路看起来没什么问题,但是在实际训练的时候存在很多问题. 就好比警察和造假钞的人,如果你的警察特别厉害,一旦造出来一点假钞一下子就把造假钞的人一窝端了,那么你也得不到很好的假钞. 反过来如果说你的警察很弱,随便造一点假钞就能蒙混过关,那么造假钞的人没有动力去更新技术迭代机器了.最理想的情况是旗鼓相当的对手,互有胜负相互进步.Discriminator的火候把握令GAN网络的训练十分不稳定. 此外在训练初期,生成器G的生成效果很差,这时候你很容易就可以把判别器D训练的很好,这时候计算梯度更新G的时候由于判别器D训练的非常好,计算出的损失值很小,log⁡(1−D(G(z)))\\log(1-D(G(z)))log(1−D(G(z)))接近0,梯度很小,很难训练G 论文中也提出了一种改进做法是损失变为 −log⁡(D(G(z)))-\\log(D(G(z)))−log(D(G(z))),这样做避免了梯度消失的问题,但是带来了新的问题,将会在下一节中介绍 GAN的数学推导 对于之前提到的 V(D,G)=Ex∼pdata(x)[log⁡D(x)]+Ez∼pz(z)[log⁡(1−D(G(z)))]V(D,G) = E_{x\\thicksim p_{data(x)}}[\\log D(x)] + E_{z\\thicksim p_{z(z)}}[\\log(1-D(G(z)))] V(D,G)=Ex∼pdata(x)​​[logD(x)]+Ez∼pz(z)​​[log(1−D(G(z)))] 我们将期望E展开 Ex∼pf(x)=∫xp(x)f(x)dxE_{x\\thicksim p}f(x) = \\int_x p(x)f(x)dxEx∼p​f(x)=∫x​p(x)f(x)dx,得到 V(D,G)=∫xpdata(x)log⁡D(x)dx+∫zpz(z)log⁡(1−D(G(z)))dzV(D,G) = \\int_x p_{data(x)}\\log D(x)dx + \\int_z p_{z(z)}\\log(1-D(G(z)))dz V(D,G)=∫x​pdata(x)​logD(x)dx+∫z​pz(z)​log(1−D(G(z)))dz 然后将G(z)用x替换,得到 V(D,G)=∫xpdata(x)log⁡D(x)dx+∫zpg(x)log⁡(1−D(x))dxV(D,G) = \\int_x p_{data(x)}\\log D(x)dx + \\int_z p_{g(x)}\\log(1-D(x))dx V(D,G)=∫x​pdata(x)​logD(x)dx+∫z​pg(x)​log(1−D(x))dx 合并两项得到 V(D,G)=∫xpdata(x)log⁡D(x)+pg(x)log⁡(1−D(x))dxV(D,G) = \\int_x p_{data(x)}\\log D(x) + p_{g(x)}\\log(1-D(x))dx V(D,G)=∫x​pdata(x)​logD(x)+pg(x)​log(1−D(x))dx 里面的函数就是对于一个x,在两个分布data(x),g(x),求积分. 我们可以将其简化为 V=alog⁡y+blog⁡(1−y)V = a\\log y + b \\log(1-y) V=alogy+blog(1−y) 这个函数是一个凸函数,我们可以很容易的计算其导数为0的位置 ay−b1−y=0\\frac{a}{y} - \\frac{b}{1-y} = 0 ya​−1−yb​=0 y=aa+by = \\frac{a}{a+b} y=a+ba​ 当G固定住了,最优的D的计算式为: DG∗(x)=Pdata(x)Pdata(x)+Pg(x)D^*_G(x) = \\frac{P_{data}(x)}{P_{data}(x) + P_g(x)} DG∗​(x)=Pdata​(x)+Pg​(x)Pdata​(x)​ 其中data代表真实数据的分布,PdataP_{data}Pdata​也就是说我把一个x放在这个分布中得到的概率是多少. PgP_gPg​就是生成器所拟合的分布中将x带入后的概率 一个分布的概率是在 [0∼1][0\\thicksim 1][0∼1]之间的,所以这个概率值的范围也是[0∼1][0\\thicksim 1][0∼1]的,同时当data和g的分布完全相同时这个值取到0.5,表示这两个分布我是完全分不开的 单独看这个公式也是非常有用的. D 的训练过程就是单独从两个分布里取数据,使用之前的目标函数训练一个二分类的分类器,如果说这个分类器给的值是0.5那么就代表这两个分布是重合的当我们希望判断训练数据样本和测试数据样本或者说真实环境中的样本是否相同时,我们就可以训练一个二分类分类器,如果不能成功分类那么就可以说明这两个分布是相同的 所以我们现在得到了最有情况下D的计算式,将其带入D G的共同优化公式之中 min⁡Gmax⁡DV(D,G)=Ex∼pdata(x)[log⁡D(x)]+Ez∼pz(z)[log⁡(1−D(G(z)))]\\min\\limits_{G}\\max\\limits_{D}V(D,G) = E_{x\\thicksim p_{data(x)}}[\\log D(x)] + E_{z\\thicksim p_{z(z)}}[\\log(1-D(G(z)))] Gmin​Dmax​V(D,G)=Ex∼pdata(x)​​[logD(x)]+Ez∼pz(z)​​[log(1−D(G(z)))] 得到对于G的优化公式为 katex这个多行公式显示不出来 最后的结果可以表示为两个KL散度之和 KL散度是用来衡量两个分布之间的差异程度,若两者差异越小,KL散度越小,反之亦反.当两分布一致时,其KL散度为0KL(P∣∣Q)=Ex∼plog⁡p(x)q(x)KL(P||Q) = E_{x\\thicksim p}\\log\\frac{p(x)}{q(x)}KL(P∣∣Q)=Ex∼p​logq(x)p(x)​KL散度是非对称的,即KL(P∣∣Q)≠KL(Q∣∣P)KL(P||Q)\\neq KL(Q||P)KL(P∣∣Q)​=KL(Q∣∣P)关于更多有关KL散度可以参考-博客 所以上式可以修改为 为了得到最小的G,只需要使 KL(Pdata∣∣Pdata+Pg2)KL(P_{data}||\\frac{P_{data}+P_g}{2})KL(Pdata​∣∣2Pdata​+Pg​​) 和 KL(Pg∣∣Pdata+Pg2)KL(P_g||\\frac{P_{data}+P_g}{2})KL(Pg​∣∣2Pdata​+Pg​​)同时取最小值0,即Pdata=PgP_{data}=P_gPdata​=Pg​ 同时作者也提到了将两个KL散度合并为JS散度,这里就不做展开了,有兴趣的朋友可以了解一下C(G)=−log⁡4+2∗JSD(pdata∣∣pg)C(G) = -\\log4 + 2*JSD(p_{data}||p_g)C(G)=−log4+2∗JSD(pdata​∣∣pg​) 所以现在可以通过数学推导得出公式计算的合理性,即只有生成器生成的分布和真实图片分布相同时才会取得最小值,优化的方向没有问题 不过正如前文所说,GAN网络的训练的过程是十分困难的,因为需要兼顾D G两者的训练程度,极其不稳定. 尽管GAN论文存在一些问题,但并不妨碍这是一个很有创新性的工作,后期也有很多人对原始GAN网络进行改进.比如下一节将会介绍的DCGAN,WGAN等等","categories":[],"tags":[{"name":"GAN","slug":"GAN","permalink":"https://luzhixing12345.github.io/tags/GAN/"}]},{"title":"pytorch预训练模型下载地址","slug":"python/pytorch预训练模型下载地址","date":"2022-05-09T18:30:31.000Z","updated":"2023-01-08T05:18:54.823Z","comments":true,"path":"2022/05/10/python/pytorch预训练模型下载地址/","link":"","permalink":"https://luzhixing12345.github.io/2022/05/10/python/pytorch%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80/","excerpt":"","text":"转载pytorch预训练模型的下载地址以及解决下载速度慢的方法侵删 # Resnet: model_urls = &#123; &#x27;resnet18&#x27;: &#x27;https://download.pytorch.org/models/resnet18-5c106cde.pth&#x27;, &#x27;resnet34&#x27;: &#x27;https://download.pytorch.org/models/resnet34-333f7ec4.pth&#x27;, &#x27;resnet50&#x27;: &#x27;https://download.pytorch.org/models/resnet50-19c8e357.pth&#x27;, &#x27;resnet101&#x27;: &#x27;https://download.pytorch.org/models/resnet101-5d3b4d8f.pth&#x27;, &#x27;resnet152&#x27;: &#x27;https://download.pytorch.org/models/resnet152-b121ed2d.pth&#x27;, &#125; # inception: model_urls = &#123; # Inception v3 ported from TensorFlow &#x27;inception_v3_google&#x27;: &#x27;https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth&#x27;, &#125; # Densenet: model_urls = &#123; &#x27;densenet121&#x27;: &#x27;https://download.pytorch.org/models/densenet121-a639ec97.pth&#x27;, &#x27;densenet169&#x27;: &#x27;https://download.pytorch.org/models/densenet169-b2777c0a.pth&#x27;, &#x27;densenet201&#x27;: &#x27;https://download.pytorch.org/models/densenet201-c1103571.pth&#x27;, &#x27;densenet161&#x27;: &#x27;https://download.pytorch.org/models/densenet161-8d451a50.pth&#x27;, &#125; # Alexnet: model_urls = &#123; &#x27;alexnet&#x27;: &#x27;https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth&#x27;, &#125; # vggnet: model_urls = &#123; &#x27;vgg11&#x27;: &#x27;https://download.pytorch.org/models/vgg11-bbd30ac9.pth&#x27;, &#x27;vgg13&#x27;: &#x27;https://download.pytorch.org/models/vgg13-c768596a.pth&#x27;, &#x27;vgg16&#x27;: &#x27;https://download.pytorch.org/models/vgg16-397923af.pth&#x27;, &#x27;vgg19&#x27;: &#x27;https://download.pytorch.org/models/vgg19-dcbb9e9d.pth&#x27;, &#x27;vgg11_bn&#x27;: &#x27;https://download.pytorch.org/models/vgg11_bn-6002323d.pth&#x27;, &#x27;vgg13_bn&#x27;: &#x27;https://download.pytorch.org/models/vgg13_bn-abd245e5.pth&#x27;, &#x27;vgg16_bn&#x27;: &#x27;https://download.pytorch.org/models/vgg16_bn-6c64b313.pth&#x27;, &#x27;vgg19_bn&#x27;: &#x27;https://download.pytorch.org/models/vgg19_bn-c79401a0.pth&#x27;, &#125;","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://luzhixing12345.github.io/tags/python/"}]},{"title":"gitignore使用","slug":"git/gitignore使用","date":"2022-04-29T07:51:17.000Z","updated":"2022-04-29T08:09:38.185Z","comments":true,"path":"2022/04/29/git/gitignore使用/","link":"","permalink":"https://luzhixing12345.github.io/2022/04/29/git/gitignore%E4%BD%BF%E7%94%A8/","excerpt":"","text":"Github官方.gitigore规范 .gitignore文件用来剔除不希望git上传的文件,包括 编译的中间文件 不重要的文件 一些项目运行阶段生成的文件 一些大文件(超过git默认的100M) 如果使用了Commitizen作为代码规范commit,我的个人.gitignore配置如下 /node_modules/ .vscode CHANGELOG.md *.json 同时可以使用GitHub官方提供的不同语言的gitignore文件,创建仓库是可以直接选择gitignore文件 .gitignore文件通常需要根据具体的项目目录文件进行调整,需要自建.gitignore文件以定向剔除,也可以在多个文件夹下建立.gitignore 值得一提的是,gitignore中新加入的项并不会从已上传的仓库中删除,也就是说如果你已经上传了cpp文件后在gitignore中去除*.cpp,已上传的cpp并不会被删除.这是因为在暂存区拥有该文件的备份,使用git add命令如果文件未修改则直接使用备份,使gitignore生效的方法如下 稍微改动当前文件,空格/换行 清除暂存区的cached之后git add即可 git rm -r --cached . git add . ... GitHub并不支持上传空文件夹,这个其实算是git设计时的失误,原回答,可以使用gitignore或者readme占位 Can I add empty directories? --- 目前，Git索引（staging area）的设计只允许列出文件， 没有人有足够的能力进行更改以允许空目录，也没有人足够关心这种情况来纠正它。 在目录中添加文件时会自动添加目录。也就是说，目录不必添加到存储库中，也不需要单独跟踪。 你可以说“git add&lt;dir&gt;”，它会将文件添加到其中。 如果你真的需要一个目录存在于签出中，你应该在其中创建一个文件。 gitignore可以很好地实现这一目的（还有一个使用.NET framework的工具MarkEmptyDirs， 它允许您自动完成这项任务）；您可以将其留空，或填写不希望出现在目录中的文件名。 GitHub本身是不建议仓库体积很大的","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://luzhixing12345.github.io/tags/git/"}]},{"title":"git的branch和pull","slug":"git/git的branch和pull","date":"2022-04-29T07:47:52.000Z","updated":"2022-04-29T07:48:06.336Z","comments":true,"path":"2022/04/29/git/git的branch和pull/","link":"","permalink":"https://luzhixing12345.github.io/2022/04/29/git/git%E7%9A%84branch%E5%92%8Cpull/","excerpt":"","text":"git官方提供了十分详细的描述,有很多直观的图片描述,很容易理解 我将在这部分根据我的理解给出一些描述性的图片,git的图片很好我并没有打算超越,仅作为学习记录 git官方的分支介绍 Note: “origin” 并无特殊含义 远程仓库名字 “origin” 与分支名字 “master” 一样，在 Git 中并没有任何特别的含义一样。 同时 “master” 是当你运行 git init 时默认的起始分支名字，原因仅仅是它的广泛使用， “origin” 是当你运行 git clone 时默认的远程仓库名字。 如果你运行 git clone -o booyah，那么你默认的远程分支名字将会是 booyah/master。 pull | branch 这个过程我用一个实例来演示,希望有助于理解 首先我创建了一个新的GitHub仓库(git branch),新建了一个文件夹并将他们remote连接,创建README文件并且提交上去,其过程无二致 接着我补充了一些文件信息,创建text.txt,写入一句话,补充readme,作为第二次提交 截至目前,我已经在本地做了两次修改,并且全部提交到了GitHub上面,在GitHub中可以点击commit查看所有的提交记录 如果只有我一个人的话,我只需要每次写完代码commit,也可以多次commit保存记录选取最后一次push到GitHub,这样我的GitHub和本地仓库一定是统一的且是最新的 master分支不断前进,HEAD代表你目前所在分支也不断前进,同时你的本地仓库与远程仓库处于同一位置 但是如果是多人合作编写程序的话,这样面临的一个问题是可能是你在本地做了一些工作,但是已经有人提前把工作推送到GitHub上,这就导致远程仓库的master接受了新的push,但是你的本地依然维持原样,当你编写完毕想要push你的commit时发现有错误信息 我在GitHub中手动修改README文件并且提交 同时我也在本地修改README文件并且提交 这时产生了报错信息,即拒绝了我的提交,因为我的current branch is behind(我被落下了) bashluzhi@LZX MINGW64 /g/learner_lu/git-branch (master) $ git push origin master To github.com:learner-lu/git-branch.git ! [rejected] master -&gt; master (non-fast-forward) error: failed to push some refs to &#x27;github.com:learner-lu/git-branch.git&#x27; hint: Updates were rejected because the tip of your current branch is behind hint: its remote counterpart. Integrate the remote changes (e.g. hint: &#x27;git pull ...&#x27;) before pushing again. hint: See the &#x27;Note about fast-forwards&#x27; in &#x27;git push --help&#x27; for details. git的推荐信息是使用git pull 我们使用git pull拉取对应仓库的对应分支 bashgit pull origin master git pull命令是将远程仓库与本地仓库进行统一,这里会出现一个问题: 如果是别人新建的文件,那么直接会在我的本地仓库复制;但如果是对于一个文件我也做了修改他也做了修改,这时就会产生冲突,因为不清楚这里的修改怎么做,需要手动解决冲突 vscode插件提供了方便的比较视图,可以选择接受现在的,接受当前提交到GitHub中最新的,还是都接受.解决所有冲突之后就可以commit了 bashgit commit -am &quot;solve crash&quot; 这种先pull后push的方式可以有效避免代码不同步,严格的commit检验保证了所有人的代码再提交的那一刻一定是与远程仓库的代码同步的,最新的. 但是于此同时也带来了一个问题,那就是每次我都需要处理冲突的文件,进行手动的选择接受哪一种修改,这显然不是一个好的方式,如果我交上去的东西被别人pull下来修改了,然后他把他的push上去. 那我再pull的时候又会发现不同,这显然不利于团队开发. 我们倾向于选择一种方式分开不同的开发,比如合理的分工,模块化到不同的文件夹/文件编写代码,这样就不需要处理冲突. 因为如果你没有改动这个文件夹/文件,其他人的修改会直接覆盖/更新此文件而不需要处理冲突(Fast-forward) 显然git也想到了这一点,比起创建文件夹这种本办法,git采用了分支的这种思想 我们可以创建一个新的分支dev,并且移动到这个分支 bashgit branch dev git checkout dev 如果你在这个dev分支上做开发,比如新建了一些文件,改写了一些代码,提交了commit.这些操作都不会影响之前的master分支. 如果你现在选择移动到master分支 git checkout master,你会发现所有的dev中的修改全都不见了,仍然是创建dev时的样子,你可以继续在master中做开发. 当你master处理完毕后可以再回到dev分支,这时又回到了dev分支的状态,这种分支的切换对于处理不同任务等复杂的场景十分适合 注意: 切换分支前应commit所有修改项 对于多人开发时,可以创建多个分支以供不同contributer开发,最后再合理的时刻进行合并,或者更新主分支master fetch merge 常规情况使用pull操作即可强制更新本地仓库,还可以使用git fetch git merge来进行合并 pull与fetch的区别 简单来说就是git fetch不更新master只更新origin/master,然后使用git merge合并本地master和origin/master,产生新commit提交. bashgit fetch origin git merge origin/master git commit -am &quot;successfully merge&quot; git push origin master git pull就是直接合并了本地master和本地remote 两者的本质区别就是fetch只是将远程仓库替换本地的remote,并不会修改你当前的任何文件,你可以检查fetch的内容再决定要不要合并. 而pull则直接进行合并,需要你现在处理冲突,决定是否改变文件. 普遍推荐使用git fetch + git merge 而不是 git pull,当然对于小项目来说看起来git pull更方便一些,也没有什么大问题 rebase 变基 由dev变基到master bashgit checkout dev git rebase master 它的原理是首先找到这两个分支(dev master)最近共同祖先，然后对比当前分支(dev)相对于该祖先的历次提交，提取相应的修改并存为临时文件， 然后将当前分支指向目标基底 master, 最后以此将之前另存为临时文件的修改依序应用 rebase会确保在向远程分支推送时能保持提交历史的整洁.例如向某个其他人维护的项目贡献代码时。 在这种情况下，你首先在自己的分支里进行开发，当开发完成时你需要先将你的代码变基到 origin/master 上，然后再向主项目提交修改。 这样的话，该项目的维护者就不再需要进行整合工作，只需要快进合并便可。 一些其他变基过程 也可以直接使用pull + rebase的方式,快速拉取变基合并. 如果有冲突需要处理冲突,选择接受哪一种修改(见git.md). git rebase(master|REBASE 1/1) git push: failed to push some refs to bashgit pull --rebase origin master","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://luzhixing12345.github.io/tags/git/"}]},{"title":"git的SSH连接","slug":"git/git的SSH连接","date":"2022-04-29T07:44:25.000Z","updated":"2023-02-28T03:12:55.855Z","comments":true,"path":"2022/04/29/git/git的SSH连接/","link":"","permalink":"https://luzhixing12345.github.io/2022/04/29/git/git%E7%9A%84SSH%E8%BF%9E%E6%8E%A5/","excerpt":"","text":"不使用https连接,使用SSH连接(推荐) 以下案例中使用的邮箱是 luzhixing12345@163.com 你只需要替换为你自己的邮箱即可 创建SSH key ssh-keygen -t rsa -C &quot;luzhixing12345@163.com&quot; 默认路径保存,文件保存在 c:/user/luzhi/.ssh(Windows) 或者 ~/.ssh(GNU/Linux) 如果你需要创建多个SSH,比如远程连接多台服务器,Github+SSH,请手动设置不同的名字加以区分,比如 id_rsa_server,SSH私钥不能共用,一对一连接 不设置密码,跳过 然后会在上面的文件夹中生成id_rsa(私钥)和id_rsa.pub(公钥),私钥不要泄露! 打开Github-&gt;settings-&gt;SSH and GPG keys-&gt;new SSH key title随便起,将id_rsa.pub复制到下方 cat ~/.ssh/id_rsa.pub 确定后不久会收到Github的邮件 在git bash中输入,注意就是git@github.com不是你的邮箱,该操作是将你的邮箱与github建立连接 ssh -T git@github.com 如果在这里出错显示需要输入git@github.com的密码则需要额外配置一下config文件 在.ssh目录下新建一个config文件,目的是将SSH映射到443端口处. 配置完毕后再次重连 Host github.com User luzhixing12345@163.com Hostname ssh.github.com PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa Port 443 yes SSH协议采用由人工判断公钥的fingerprint是否可信的方式。当使用ssh命令连接服务器时，命令行会提示如下信息: The authenticity of host '168.30.9.213 (&lt;no hostip for proxy command&gt;) can’t be established. RSA key fingerprint is 23:42:c1:e4:3f:d2:cc:37:1d:89:cb:e7:5d:be:5d:53. Are you sure you want to continue connecting (yes/no)? 如果出现Hi “用户名”! You’ve successfully authenticated, but GitHub does not provide shell access则设置成功 之后使用ssh的地址git@github.com:xxx而不是https的地址https://github.com/xxx 可以使用 git remote 查看远程仓库,默认为空. 查看远程仓库绑定的地址 git remote -v 如果已经添加origin,可以使用如下命令删除 git remote rm origin 添加GitHub仓库地址,注意添加的是SSH的地址 git remote add origin git@github.com:learner-lu/git-learning.git 然后就可以自由的push啦 git push origin main 如果之前都可以很稳定的push,突然有一天报错ssl port22 timeout(tnnd坑死我了) 这时候一般都不是你的问题,可以重新尝试一下ssh -T git@github.com, 如果仍然连接失败,网上有些方法是说添加一个config文件,换成443端口,我本人亲测不好使 最后找了好久,发现是校园网… 换流量,就可以了… 其他解决方法(偶尔可以解决,偶尔出问题) 关掉代理(1) git config --global --unset https.https://github.com.proxy git config --global --unset http.https://github.com.proxy 关掉代理(2) git config --global --unset http.proxy git config --global --unset https.proxy UU加速器 | steam++ 见B站视频介绍 参考 SSH key配置 SSH key配置教程 SSH SSL HTTPS","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://luzhixing12345.github.io/tags/git/"}]},{"title":"git的commit用法","slug":"git/git的commit用法","date":"2022-04-29T07:43:43.000Z","updated":"2022-06-05T05:21:30.601Z","comments":true,"path":"2022/04/29/git/git的commit用法/","link":"","permalink":"https://luzhixing12345.github.io/2022/04/29/git/git%E7%9A%84commit%E7%94%A8%E6%B3%95/","excerpt":"","text":"实话说我认为有些没必要,或许不应该在这种小事上大费周章,或许有些吹毛求疵吧,但我还是希望养成一个好的习惯 node_modules的设计…有些臃肿,不是很喜欢 参考知乎文章 git commit 标准用法 [feat] : 新增功能(已实现) [dev] : 功能开发进展(进行中) [fix] : 修复 bug [docs] : 仅仅修改了文档，比如 README, CHANGELOG等等 [test] : 增加/修改测试用例，包括单元测试、集成测试等 [style] : 修改了空行、缩进格式、引用包排序等等（不改变代码逻辑） [perf] : 优化相关内容，比如提升性能、体验、算法等 [refactor] : 代码重构，「没有新功能或者bug修复」 [chore] : 改变构建流程、或者增加依赖库、工具等 [revert] : 回滚到上一个版本 [merge] : 代码合并 环境配置 配置 npm 安装nodejs,选择LTS(长期稳定支持的版本),下载完成后配置环境 配置 Commitizen 以格式化 commit message Commitizen安装 npm install -g commitizen 安装changelog,生成changelog的工具 npm install -g conventional-changelog conventional-changelog-cli 检验是否安装成功,出现 conventional-changelog-cli@2.2.2 npm ls -g -depth=0 至此安装过程结束,以下为每次新建项目后需要执行的操作 项目根目录下创建空的package.json,然后进入到项目目录,执行以下命令会生成对应的项目信息: npm init --yes 运行下面命令,使其支持 Angular 的 Commit message 格式 commitizen init cz-conventional-changelog --save --save-exact 进入到项目目录,执行以下命令生成 CHANGELOG.md 文件 conventional-changelog -p angular -i CHANGELOG.md -s 以后,凡是用到 git commit 命令的时候统一改为 git cz ,然后就会出现选项，生成符合格式的Commit Message 内容说明 feat: A new feature (新功能) ——————————**常用** fix: A bug fix (修复bug) ——————————**常用** docs: Documentation only changes (文档改变) ——————————**常用** style: Changes that do not affect the meaning of the code (代码格式变更) refactor: A code change that neither fixes a bug nor adds a feature (某个已有功能重构) perf: A code change that improves performance (性能优化) test: Adding missing tests or correcting existing tests (增加测试) build: Changes that affect the build system or external dependencies (改变build工具,webpack/npm) ci: Changes to our CI configuration files and scripts (更改ci configuration) chore: Other changes that don&#x27;t modify src or test files (一些不更改src或者test相关文件的提交) ——————————**常用** revert: Reverts a previous commit (撤销上一次commit) ? What is the scope of this change (e.g. component or file name): (press enter to skip) 说明此次修改的影响范围，可以根据自己的情况来进行填写 - all: 表示影响很大，如修改了整体依赖 - location: 表示影响小，修改了某个小的功能 - module: 表示会影响整个模块，如登录模块等 ? Write a short, imperative tense description of the change (max 94 chars): 简要描述修改内容 ? Provide a longer description of the change: (press enter to skip) 详细描述修改内容,可跳过 ? Are there any breaking changes? (y/N) 大改动 ? A BREAKING CHANGE commit requires a body. Please enter a longer description of the commit itself: ? Describe the breaking changes: ? Does this change affect any open issues? (y/N) 解决issue时 Add issue references (e.g. &quot;fix #123&quot;, &quot;re #123&quot;.):","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://luzhixing12345.github.io/tags/git/"}]},{"title":"git的使用","slug":"git/git的使用","date":"2022-04-29T07:38:45.000Z","updated":"2022-04-29T08:23:42.862Z","comments":true,"path":"2022/04/29/git/git的使用/","link":"","permalink":"https://luzhixing12345.github.io/2022/04/29/git/git%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"由于笔者水平有限,该文档并不是git的教学文档,仅为学习了git的用法之后的总结,希望能通过整理的方式加深印象,如果对git尚不熟悉,可以参考以下文章 Git入门级参考文章 git官方文档 知乎文章 知乎文章 github markdown git电子书 git的使用 git支持linux的部分命令,包括cat,mkdir,touch,vim,rm,cd等等,也有一些常用的命令和提交格式 git不支持完整的正则表达式语法(regex es),它只支持unix fnmatch(filename pattern matching),通常来说在命令行中使用正则语法容易出现误导，如demo.c等习惯性的写法,因此采用unix的匹配写法,具体为: *匹配任意字符,任意次数 ?匹配任意字符,一次 [seq] 匹配 seq 中出现的字符,一次 [!seq] 匹配不在 seq 中出现的字符,一次 如匹配 demo.cpp可使用如下任意一种写法,正则写法如 \\w*\\.\\w* 将不被识别 *.cpp | demo.* | demo.??? 当您使用 Git 和 GitHub 协作处理项目时，例如，如果您在 Windows 计算机上工作，并且您的合作者在 macOS 中进行了更改，则 Git 可能会产生意外的结果.您可以将 Git 配置为自动处理行尾，以便与使用不同操作系统的人员进行有效协作。 git config --global core.autocrlf true 关于 add 将文件从工作区 add 到暂存区 添加所有文件 git add . 添加所有 .c git add *.c 添加 FILEPATH 文件夹下所有的文件 git add FILEPATH/ 查看添加了哪些文件 git status 关于 rm 有时候添加错误的或未完成需要修改的文件到暂存区,需要从暂存区删除该文件 删除方式 注意,这里可以使用 fnmatch匹配文件名,但是如果某一匹配项不在暂存区而在工作区未被加入,则删除失败 例如 1.txt 在暂存区中, 2.txt 未加入暂存区,则使用 git rm --cached *.txt 会删除失败 git add 不会有这个问题,可以理解为把所有匹配项都加入暂存区,重复的再加一次 从暂存区删除该文件,物理文件不删除(推荐使用),放入垃圾桶 git rm --cached FILENAME 删除暂存区中的文件和物理文件,谨慎使用 git rm --f FILENAME 删除已提交的文件夹或文件 git rm -r --cached FOLDER git add . ... 误删文件恢复 git rm 需谨慎!!! 如果处于未提交状态 # 查看所有修改项 git reset # 将FILENAME文件恢复 git checkout FILENAME 如果已经commit,那么会有些麻烦,只能退回上个版本,然后把被删除文件再找回来 git reset HEAD^ git checkout (捡垃圾) 关于 commit 将暂存区的文件上传到仓库区 提交 -m参数是一个较为常用的参数,用于将提交信息与命令放在同一行 git commit -m &quot;COMMIT MESSAGE&quot; 通常来说用于描述的commit信息应该记录更新了什么内容等等,一般来说一行足以.如果需要很多文件信息也可以使用 bashgit commit 打开commit信息文本,书写详细内容,使用方式同vim 查看commit日志(Q退出) git log 单行查看commit日志,关键信息 git log --pretty=oneline 回退到上一个版本(--hard本地代码改变.谨慎使用) git reset --hard HEAD^ 回退到上N个版本 git reset --hard HEAD~N 通常来说使用 git reset --hard HEAD^来进行版本回退是因为有人错误的提交了commit,如提交到了不同的分支(branch)或者误修改了某些文件,但这种情况还是相对较少 这里提供两种可能会遇到的情况: 比如说你今天打算改一改代码,你可以先把所有文件git add然后git commit一次,然后开始修改,a.txt b.txt c.txt等文件,修改完之后你发现测试的结果不尽如人意,或者你觉得你的修改太愚蠢了太繁琐了想要重写,这时候就可以使用git reset --hard HEAD 来回到最后一次commit的位置,这样你在a/b/c.txt中的所有修改都会撤回(注意会改变本地文件,使用时请注意),就不需要你记住修改了什么文件再一次次ctrl+z回退了. 或者如果你改了某几个文件的代码,但是想撤回某一个文件的所有修改,可以使用 git checkout -- FILENAME来撤销修改 返回到某一个指定的版本 git reflog # 查看所有commit记录,根据commit内容搜索,找到前面对应的序号 git reset --hard 3f72bae # 同步到某一版本 关于 push 将仓库区的文件上传到GitHub 有时候会出现Failed to connect to github.com port 443 after xxx ms: Timed out的报错信息或者OpenSSL fail的报错,网上的解决方法很多,有时成功有时不成功,我搜集到的所有解决方法.目前使用SSH可以无压力的上传下载使用git Git保存的并不是文件的变化差异,而是文件不同时刻的快照. git add操作是将文件加入暂存区,Git会为每个对象计算校验和(SHA-1哈希算法),保存blob对象的快照 git commit操作会单独计算每一个目录的校验和,使用多个树对象来保存blob对象的校验和,最后再计算树对象的校验和,生成一个提交对象,包含树对象的指针和所有提交信息 每次提交都会包含一个指向上次提交对象的指针 首先与远程仓库建立连接,有两种方式 直接从URL克隆仓库,默认将 origin设置为该仓库的地址 bashgit clone URL 将本地文件夹与远程仓库连接,origin对应远程仓库的地址(需要新建GitHub仓库) bashgit remote add origin git@github.com:luzhixing12345/git-learning.git 可以使用git remote -v查看远程仓库的地址,一个本地仓库可以连接多个远程仓库 默认的分支是master,也就是说我们选择将我们目前commit的本地仓库提交到某一个远程仓库的某一个分支上,我们使用 bashgit push origin master 第一次提交的时候可以选择git push -u origin master追踪此分支,这样默认选择以后都提交到origin远程仓库的master分支,之后的提交可以省略参数 bashgit push 总结: 一套基本的git/GitHub的文件流如下 初次配置 bashgit init git add . git commit -m &quot;upload all the files&quot; git remote add origin git@github.com:luzhixing12345/git-learning.git git push -u origin master 之后的所有修改 bashgit add . git commit -m &quot;update git learning and fix docs bugs&quot; git push 以上的命令已经可以满足绝大多数个人的项目开发与维护了,但是往往还有一些其他的问题,比如多人合作编写代码,比如临时修复bug等任务 git设计了很好的分支系统和项目拉取合并的方式,这一部分也十分重要,但并不是必要掌握的 接下来会介绍branch | pull | fetch | merge.这一部分可以说是git使用时最常见的问题,涉及多人合作完成项目,分支的使用|合并 优质网站 GitHub文件代理加速下载服务 (GitHub 文件/Releases/archive/gist/raw.githubusercontent.com)","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://luzhixing12345.github.io/tags/git/"}]},{"title":"使用poetry发布python包","slug":"python/使用PYPI发布python包","date":"2022-04-29T03:37:58.000Z","updated":"2023-01-08T05:52:54.643Z","comments":true,"path":"2022/04/29/python/使用PYPI发布python包/","link":"","permalink":"https://luzhixing12345.github.io/2022/04/29/python/%E4%BD%BF%E7%94%A8PYPI%E5%8F%91%E5%B8%83python%E5%8C%85/","excerpt":"","text":"引言 熟悉python的朋友一定安装过很多第三方库,python的强大之处不仅在于简洁优雅,还有很好的社区环境,有许多无私的开源贡献者编写了许多实用高效的第三方库,比如matplotlib,numpy之类,只要你想要python实现的功能,几乎都可以搜索找到对应的python包,只需简单的pip安装,阅读相关文档了解其基本函数使用方法就可以迅速上手了,比起其他语言来说解决问题不可谓不快. 那么如果说我也希望为python的社区做出一些贡献,我能否开发一个python包用于实现一些功能呢? 当然是可以的,而且python社区十分欢迎你参与其中,为开源做出一份贡献. PYPI 那么如何去做呢? 显然在正常使用时如果我们编写了一个python的包(下假定该包名为lytorch),那么我们只需要在其同级目录下import lytorch即可使用,但是我们希望在所有位置都可以使用,在所有地方都可以使用,所有人都可以使用,那么显然我们需要将其移动到一个其他的位置,并且可以被引用到. PYPI是一个很好的平台,全称为Python Package Index,是一个开源的python包管理的网站,我们只需要将我们编写好的代码上传到PYPI上,接着通过pip install命令安装,这样包就被下载到 Lib/site-packages下了,使用import之时可以在sys.path中搜索到这个路径,找到lytorch的包,就可以成功的使用了. 准备与发布 首先注册一个PYPI账号-PYPI 注册成功之后回到主界面,右上角就是你的用户名,你将以这个身份进行登录 中间的搜索框中你可以找到所有发布在PYPI的包名,试试搜索 matplotlib pyautogui numpy 右上角进入个人project,目前没有任何项目.但是PYPI非常贴心的提供了很完整的教学文档,说明文档.如果你更倾向于阅读官方文档也可以移步至PYPI上传包 poetry 如今2023年了已经不是setup.py的年代了,许多便利的工具可以帮助我们迅速的开发,构建,发布.这里主要介绍一下我个人倾向的poetry https://python-poetry.org/ poetry的使用非常简单,首先安装 pip install poetry 接下来你可以在一个新目录创建 poetry new poetry-demo 也可以在当前目录下创建 poetry init 通常来说我推荐先创建一个GitHub仓库初始化一些信息,然后通过git clone把仓库拉取到本地,再使用poetry init初始化,这样poetry可以根据.git信息完成一部分初始化内容 初始化的部分包括 name: 包名 version: 版本 description: 描述信息 License: 开源协议 authors: 作者 dependenciese: 依赖 初始化之后可以得到 pyproject.toml 文件,我们可以在之后修改这个文件以增加相关信息 这里需要注意的是,包名需要选择一个独一无二的,和PYPI已有的项目包名都不相同的包名.你可以在PYPI中查询包名以确定是否已经存在,如果存在则需要重新想一个新名字,否则无法发布 依赖 接下来我们看一下依赖信息 dependencies 这里的依赖是指包的环境,比如下方的包的依赖指安装此包需要 python3.7, PyYAML6.0, MarkdownParser0.1.3 例如你的库依赖了numpy,你可以使用 poetry add numpy将其添加到你的包依赖中,当然你也可以手动添加 [tool.poetry.dependencies] python = &quot;^3.7&quot; PyYAML = &quot;^6.0&quot; MarkdownParser = &quot;^0.1.3&quot; 除此之外简要说明一下后面的版本号:版本号分为三个部分: 主版本号.次版本号.修复版本号 主版本号是一个大版本的更迭,一般意味着通用稳定的一个大版本,API的大型调整,架构的变化等等. 次版本号是一个相对更小的,稳定的版本,通常为修复了一些bug之后暂时维持稳定的一个状态版本 修复版本号就是遇到bug,修复bug,改进代码增加功能的一些版本发布和更新 日常在开发的时候在依赖中常常使用 ^ ~ ^: 指匹配最新的大版本依赖包，比如^1.2.3会匹配所有1.x.x的包，包括1.3.0，但是不包括2.0.0 ~: 指匹配最近的小版本依赖包，比如~1.2.3会匹配所有1.2.x版本，但是不包括1.3.0 *: 安装最新版本的依赖包 建议使用~来标记版本号，这样可以保证项目不会出现大的问题，也能保证包中的小bug可以得到修复 构建与发布 这里以笔者的一个库: zood 为例 你需要在同级目录下创建一个文件夹zood, 这个文件夹不必须与zood同名,也可以叫做其他的名字(比如zoood).这里的区别是下载使用的 pip install zood 是你的包名,但是使用的时候import 比如zoood是你的这个文件夹的名字 这个文件夹必须含有一个 __init__.py 文件用于提供对外的引用接口,不在其中显示导出的是无法被外部引用到的. zood目录内部的所有目录也是同理,每一级目录如果想要被外部作为库来引用,都需要创建 __init__.py 并在其中import对应的接口 构建使用 poetry build 发布你的python包需要首先获取API token, 前往 https://pypi.org/manage/account/ 创建一个 API token 使用如下命令替换 my-token 以配置密钥 poetry config pypi-token.pypi &lt;my-token&gt; 发布 poetry publish 接下来你就可以在PYPI上看到你的包了,所有人都可以下载使用!这很令人兴奋不是么? 命令行 poetry也提供了非常简单的命令行调用方式, 只需要在 pyproject.toml 中添加 [tool.poetry.scripts] zood = &#x27;zood.main:main&#x27; 这里表示当在命令行中输入 zood 的时候,会调用 zood.main 的 main 函数","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://luzhixing12345.github.io/tags/python/"}]},{"title":"注意事项","slug":"网站/注意事项","date":"2022-04-24T17:32:40.000Z","updated":"2022-11-08T05:37:48.736Z","comments":true,"path":"2022/04/25/网站/注意事项/","link":"","permalink":"https://luzhixing12345.github.io/2022/04/25/%E7%BD%91%E7%AB%99/%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/","excerpt":"","text":"关于测试 建议本地调试完毕再上传,无需多commit hexo clean hexo g hexo serser 支持markdown mermaid渲染 部分主题的渲染的效果并不理想,我建议使用图片. 本主题可以 npm install --save hexo-filter-mermaid-diagrams 在 _config.melody.yml 中加入 mermaid: enable: true 在文章的开头加入 &lt;script src=&quot;https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js&quot;&gt;&lt;/script&gt; &lt;script&gt;mermaid.initialize(&#123;startOnLoad:true&#125;);&lt;/script&gt; 一些常用符号 β\\betaβ α\\alphaα ε\\varepsilonε Fluid 主题的 Tag 这里的绝对不能错! 错了在hexo g -d阶段会报一个 err: Template render error: (unknown path) 的错误信息,而且不会提示你哪个文件错了,你要自己找,很难受,一定要注意前后符号的对应 &#123;% note success %&#125; success &#123;% endnote %&#125; &#123;% note danger %&#125; danger &#123;% endnote %&#125; &#123;% note warning %&#125; warning &#123;% endnote %&#125; &#123;% note info %&#125; info &#123;% endnote %&#125; &#123;% note info %&#125; light &#123;% endnote %&#125; Fulid主题的按钮 &#123;% btn url, text, title %&#125; text 组图 &#123;% gi 5 3-2 %&#125; ![](https://raw.githubusercontent.com/learner-lu/picbed/master/logo.png) ![](https://raw.githubusercontent.com/learner-lu/picbed/master/logo.png) ![](https://raw.githubusercontent.com/learner-lu/picbed/master/logo.png) ![](https://raw.githubusercontent.com/learner-lu/picbed/master/logo.png) ![](https://raw.githubusercontent.com/learner-lu/picbed/master/logo.png) &#123;% endgi %&#125; 嵌入视频/音频 markdown-插入HTML 本主题fluid是支持使用iframe插入视频的,通常来说网站上的其他视频都会给嵌入代码. 以嵌入B站视频举例,分享 -&gt; 嵌入代码 -&gt; 复制 复制嵌入代码这里有时候经常没复制到剪切板,要留意一下确定复制正确了 但是这里会有一个比较坑的点,iframe并不是自适应网页宽度 下面是一个比较好的模板,替换其中的src资源链接就可以了,支持全屏 &lt;iframe width=100% height=450 src=&quot;&quot; allowfullscreen scrolling=&quot;auto&quot; border=&quot;0&quot; frameborder=&quot;no&quot; framespacing=&quot;0&quot;&gt; &lt;/iframe&gt; mermaid graph LR a --> b b --> c &#123;% mermaid %&#125; graph LR a --&gt; b b --&gt; c &#123;% endmermaid %&#125; 这里不知道为什么好像传统的mermaid的解析方式有点小问题,还是要用`","categories":[],"tags":[{"name":"博客","slug":"博客","permalink":"https://luzhixing12345.github.io/tags/%E5%8D%9A%E5%AE%A2/"}]},{"title":"搭建个人博客","slug":"网站/搭建个人博客","date":"2022-04-23T21:18:28.000Z","updated":"2022-11-08T05:37:44.459Z","comments":true,"path":"2022/04/24/网站/搭建个人博客/","link":"","permalink":"https://luzhixing12345.github.io/2022/04/24/%E7%BD%91%E7%AB%99/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"构建一个个人网站需要什么? 一台服务器 一个公网IP 网页的源代码 但是如果是对于新手来说显然并不适合从零开始构建,租服务器需要钱,网页源代码编写需要了解前端的知识,这无疑需要一段时间的学习 好在目前有很多现成的网站搭建方法和教程供小白使用,我也是从零开始构建的这个网站,整体的框架都已经搭建好了只需要在上面补充你需要的内容即可,省去了很多麻烦 Github可以快速利用 Jekyll 来构建网页, 不过这个博客并没有采用这种方式,而是使用了 hexo 来构建网站,也十分快捷方便. Hexo是一款基于Node.js的静态博客框架，依赖少易于安装使用，可以方便的生成静态网页托管在GitHub和Coding上，是搭建博客的首选框架 准备阶段 git nodejs LTS版本 hexo npm install -g hexo-cli SSH 连接 GitHub 如果尚未安装可以参考博客构建教程,这篇文章非常详细,这里不再赘述 博客初始化 下载hexo npm install -g hexo-cli 初始化 hexo init myblog 进入文件夹并安装依赖 cd myblog npm install 生成静态文章 hexo g 启动服务 hexo server 打开浏览器,输入 localhost:4000 查看初始化的文章 可是现在也只能在我的主机上访问这个静态页面,其他人并不能看到,我希望文章内容能被更多人看到. 虽然已经创建了一个基本的博客主页,但显然现在并不能满足我们的需求,因为可能需要写很多文章,一个页面有些单调. 我们也希望能使用一个看起来更美观一些的界面,计算机专业文档的编写习惯于使用markdown格式,现在的博客markdown格式的有些难看 文章我们也希望能够井井有条,最好能更加有层次结构,分目录分模块 最好还能像 CSDN 知乎 博客园 那种专业的网站那样,可以有一些更好更有趣的功能 博客进阶 首先解决第一个问题,如何让其他人访问我的博客 很显然我们需要一个服务器提供一个公网IP,最好还能有一个属于自己的域名,这样其他人就可以直接搜索 www.kamilu.com就能直接访问到我的博客了,但这种方式并不划算. 首先租服务器需要钱,购买域名也需要钱,开始的几年是比较便宜的,但后面时间越长价格逐年攀升,如果只是新手的话完全没有必要花这个冤枉钱,计算机精神讲的就是一个开源免费无广告 Github 提供了 pages 模块可以方便我们完成这一过程, 新建一个仓库,命名为 &lt;username&gt;.github.io,这个仓库就可以提供一个公网IP以供其他人访问 接下来将刚刚的博客部署到GitHub,配置 _config.yml 文件,在结尾加入 yaml是两个空格缩进,branch可以使用master分支也可以是main分支,这个没什么影响,我的这个博客main分支用于README文件介绍了,将内容全部放在了master分支中了 deploy: type: git repo: https://github.com/YourgithubName/YourgithubName.github.io.git branch: master 安装 deplot-git npm install hexo-deployer-git --save 清除之前生成的内容 hexo clean 重新渲染生成静态网页 hexo generate 将网页内容部署到GitHub仓库上,GitHub会自动解析内容并更新 hexo deploy 后面两步可以简写合并为一步 hexo g -d 成功上传之后可以在GitHub仓库的 Actions 中查看状态, 当黄色圆圈变为绿色时表示已经部署完毕，接着就可以直接访问 &lt;username&gt;.github.io 查看你的博客了,这和之前使用 hexo server 部署到本机 localhost:4000上的完全一致,并且其他人也可以通过&lt;username&gt;.github.io访问你的博客 &lt;username&gt;.github.io 内容有时候没有更新是因为缓存的原因,需要强制 F5 刷新一下 这么多文件我也不知道该干什么啊? 这都是干什么用的啊? 这里简单分析一下整个 hexo 文件夹的结构: package.json: package用于包管理,记录了所有的下载项,使用 npm install 下载的内容都会记录在这里,例如我使用的主题 melody _config.yml:这个文件很重要,是整个项目的配置文件,记录了配置信息. 之前我们添加的 deploy-git 插件就是把相关配置信息添加到了这里 source: 这个文件夹是所有的源文件,里面有一个 _posts 文件夹为所有展示的文件,类似于 public. hexo new &lt;filename&gt; 这一步会在 _posts 下创建一个新的markdown文件,文件名为&lt;filename&gt; public: 如果你比较细心的话你会发现, public的内容就是我们上传到GitHub上的内容,在本地执行 hexo clean 时也会删除这个文件夹,并在 hexo g -d 后重新生成,你可以把它理解为hexo将你的配置信息和功能模块编译,结果保存在 public node_modules: 这里就是所有通过npm下载的包的位置 不想使用现在的界面,怎么更换一个好看一些的主题呢? hexo 提供了主题平台,可以在上面筛选你想要的主题,不过并不是每一个主题的作者都很详细的写了如何配置如何替换现在的主题,这会给新手带来一定的困扰. 我目前使用的主题是fluid,使用文档说明文档可以说是相当的详细了.我看好的是它可以直接支持 mermaid 的markdown书写,这个我很喜欢 这里顺便记录一下其他的我比较喜欢的主题: quiet 简约扁平化 melody 我的上一个主题,也非常好.这个主题干净简洁,功能丰富,作者开发经验丰富.我很喜欢这个主题,并且作者提供了一份非常详尽的使用文档,清晰明了易于上手. 如果你并不喜欢这个主题或者希望选用其他主题,那么首先你能找到这个作者的主题的Github地址.具体方法就是一般主题的作者都会在该主题下留一个GitHub的Icon,点击该图标就可以看到作者的主页,进去找到这个项目地址,查看README文件跟着作者的说明走即可. 有的厉害的主题直接提供了 npm install 下载,有的则是需要 git clone,效果相同. 生效办法就是修改你目前文件中的 _config.yml 中的 theme: 选项为作者的这个名字,然后在修改一些地方的基本信息,具体要看该主题的说明文档 怎么加一些特殊的功能呢? 比如评论,点赞等等.这要看这个主题的作者是否做了该部分,如果没有做的话那估计要自己写了~ melody主题完成了该部分且使用起来相当简单,详见其说明文档 相关参考 valine添加评论 hexo完整搭建博客 图标网站","categories":[],"tags":[{"name":"博客","slug":"博客","permalink":"https://luzhixing12345.github.io/tags/%E5%8D%9A%E5%AE%A2/"}]}],"categories":[],"tags":[{"name":"形式化验证","slug":"形式化验证","permalink":"https://luzhixing12345.github.io/tags/%E5%BD%A2%E5%BC%8F%E5%8C%96%E9%AA%8C%E8%AF%81/"},{"name":"python","slug":"python","permalink":"https://luzhixing12345.github.io/tags/python/"},{"name":"体系结构","slug":"体系结构","permalink":"https://luzhixing12345.github.io/tags/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"},{"name":"环境配置","slug":"环境配置","permalink":"https://luzhixing12345.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"},{"name":"服务器","slug":"服务器","permalink":"https://luzhixing12345.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"杂","slug":"杂","permalink":"https://luzhixing12345.github.io/tags/%E6%9D%82/"},{"name":"CSAPP","slug":"CSAPP","permalink":"https://luzhixing12345.github.io/tags/CSAPP/"},{"name":"博客","slug":"博客","permalink":"https://luzhixing12345.github.io/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"git","slug":"git","permalink":"https://luzhixing12345.github.io/tags/git/"},{"name":"GAN","slug":"GAN","permalink":"https://luzhixing12345.github.io/tags/GAN/"}]}